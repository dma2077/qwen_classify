#!/usr/bin/env python3
"""
å®‰å…¨æµ‹è¯•PyTorch Profiler
ä¸“é—¨å¤„ç†NoneTypeé”™è¯¯å’Œevents()é—®é¢˜
"""

import torch
import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def test_profiler_safe():
    """å®‰å…¨æµ‹è¯•profiler"""
    
    print("ğŸ§ª å®‰å…¨æµ‹è¯•PyTorch Profiler...")
    print("=" * 50)
    
    # æ£€æŸ¥PyTorchç‰ˆæœ¬
    print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
    print(f"CUDAå¯ç”¨: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"CUDAç‰ˆæœ¬: {torch.version.cuda}")
        print(f"GPUæ•°é‡: {torch.cuda.device_count()}")
        print(f"å½“å‰GPU: {torch.cuda.get_device_name(0)}")
    
    # æ£€æŸ¥CUDAæ˜¯å¦å¯ç”¨
    if not torch.cuda.is_available():
        print("âŒ CUDAä¸å¯ç”¨ï¼Œè·³è¿‡æµ‹è¯•")
        return
    
    device = torch.device('cuda:0')
    
    # åˆ›å»ºä¸€ä¸ªç®€å•çš„æµ‹è¯•æ¨¡å‹
    class SimpleTestModel(torch.nn.Module):
        def __init__(self):
            super().__init__()
            self.linear1 = torch.nn.Linear(512, 256)
            self.linear2 = torch.nn.Linear(256, 101)
            self.relu = torch.nn.ReLU()
            
        def forward(self, input_ids, attention_mask, pixel_values, labels):
            # æ¨¡æ‹Ÿå¤šæ¨¡æ€è¾“å…¥å¤„ç†
            batch_size = input_ids.size(0)
            seq_len = input_ids.size(1)
            
            # å¤„ç†æ–‡æœ¬è¾“å…¥
            text_features = torch.randn(batch_size, seq_len, 512, device=input_ids.device)
            text_output = self.linear1(text_features)
            text_output = self.relu(text_output)
            
            # å¤„ç†å›¾åƒè¾“å…¥
            image_features = torch.randn(batch_size, 3, 224, 224, device=pixel_values.device)
            image_output = torch.mean(image_features.view(batch_size, -1), dim=1, keepdim=True)
            image_output = image_output.expand(-1, seq_len, -1)
            
            # èåˆç‰¹å¾
            combined = text_output + image_output
            logits = self.linear2(combined)
            
            # è®¡ç®—æŸå¤±
            loss = torch.nn.functional.cross_entropy(logits.view(-1, 101), labels.view(-1))
            
            # è¿”å›ä¸€ä¸ªç±»ä¼¼transformersè¾“å‡ºçš„å¯¹è±¡ï¼ˆä¸åŒ…å«last_hidden_stateï¼‰
            class Outputs:
                def __init__(self, loss, logits):
                    self.loss = loss
                    self.logits = logits
                    # ä¸åŒ…å«last_hidden_stateï¼Œæ¨¡æ‹Ÿä½ çš„æ¨¡å‹è¾“å‡º
            
            return Outputs(loss, logits)
    
    # åˆ›å»ºæ¨¡å‹
    model = SimpleTestModel().to(device)
    print(f"âœ… åˆ›å»ºæµ‹è¯•æ¨¡å‹: {sum(p.numel() for p in model.parameters()):,} å‚æ•°")
    
    # åˆ›å»ºæµ‹è¯•batchï¼ˆåŒ…å«attention_maskï¼‰
    batch_size = 8
    seq_length = 512
    
    test_batch = {
        'input_ids': torch.randint(0, 1000, (batch_size, seq_length), device=device),
        'attention_mask': torch.ones(batch_size, seq_length, device=device),  # å…¨1çš„attention_mask
        'pixel_values': torch.randn(batch_size, 3, 224, 224, device=device),
        'labels': torch.randint(0, 101, (batch_size,), device=device)
    }
    
    print(f"âœ… åˆ›å»ºæµ‹è¯•batch: batch_size={batch_size}, seq_length={seq_length}")
    
    # æµ‹è¯•1: æœ€åŸºç¡€çš„profileræµ‹è¯•
    print("\nğŸ“Š æµ‹è¯•1: æœ€åŸºç¡€profileræµ‹è¯•")
    try:
        with torch.profiler.profile(
            activities=[torch.profiler.ProfilerActivity.CUDA],
            record_shapes=True,
            profile_memory=False
        ) as prof:
            with torch.no_grad():
                _ = model(**test_batch)
        
        print("âœ… Profilerä¸Šä¸‹æ–‡ç®¡ç†å™¨æ­£å¸¸å·¥ä½œ")
        
        # å®‰å…¨åœ°è·å–events
        try:
            events = prof.events()
            if events is not None:
                print(f"âœ… prof.events()æˆåŠŸï¼Œè·å–åˆ° {len(events)} ä¸ªäº‹ä»¶")
                
                # æ£€æŸ¥äº‹ä»¶ç±»å‹
                event_types = set()
                for event in events:
                    if hasattr(event, 'name'):
                        event_types.add(type(event).__name__)
                
                print(f"  äº‹ä»¶ç±»å‹: {event_types}")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰FLOPså±æ€§
                flops_events = [e for e in events if hasattr(e, 'flops')]
                print(f"  åŒ…å«flopså±æ€§çš„äº‹ä»¶: {len(flops_events)}")
                
                if flops_events:
                    flops_with_values = [e for e in flops_events if e.flops > 0]
                    print(f"  æœ‰FLOPså€¼çš„äº‹ä»¶: {len(flops_with_values)}")
                    
                    if flops_with_values:
                        total_flops = sum(e.flops for e in flops_with_values)
                        print(f"  æ€»FLOPs: {total_flops:.2e}")
                    else:
                        print("  æ‰€æœ‰FLOPsäº‹ä»¶çš„å€¼éƒ½ä¸º0")
                else:
                    print("  æ²¡æœ‰æ‰¾åˆ°åŒ…å«flopså±æ€§çš„äº‹ä»¶")
                    
            else:
                print("âŒ prof.events()è¿”å›None")
                
        except Exception as events_error:
            print(f"âŒ è·å–prof.events()å¤±è´¥: {events_error}")
            import traceback
            traceback.print_exc()
            
    except Exception as e:
        print(f"âŒ åŸºç¡€profileræµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    
    # æµ‹è¯•2: å®‰å…¨çš„eventsè·å–å‡½æ•°
    print("\nğŸ“Š æµ‹è¯•2: å®‰å…¨çš„eventsè·å–å‡½æ•°")
    def safe_get_events(prof):
        """å®‰å…¨åœ°è·å–profiler events"""
        try:
            events = prof.events()
            if events is not None:
                return events, len(events)
            else:
                return None, 0
        except Exception as e:
            print(f"  è·å–eventså¼‚å¸¸: {e}")
            return None, 0
    
    try:
        with torch.profiler.profile(
            activities=[torch.profiler.ProfilerActivity.CUDA],
            record_shapes=True,
            profile_memory=False
        ) as prof:
            with torch.no_grad():
                _ = model(**test_batch)
        
        events, count = safe_get_events(prof)
        if events is not None:
            print(f"âœ… å®‰å…¨è·å–eventsæˆåŠŸ: {count} ä¸ªäº‹ä»¶")
        else:
            print("âŒ å®‰å…¨è·å–eventså¤±è´¥")
            
    except Exception as e:
        print(f"âŒ å®‰å…¨eventsè·å–æµ‹è¯•å¤±è´¥: {e}")
    
    # æµ‹è¯•3: æµ‹è¯•æˆ‘ä»¬çš„ä¿®å¤å‡½æ•°
    print("\nğŸ“Š æµ‹è¯•3: æµ‹è¯•ä¿®å¤åçš„å‡½æ•°")
    try:
        from training.utils.monitor import profile_model_flops
        total_flops = profile_model_flops(model, test_batch)
        print(f"âœ… ä¿®å¤åçš„FLOPsæµ‹é‡: {total_flops:.2e}")
    except Exception as e:
        print(f"âŒ ä¿®å¤åçš„FLOPsæµ‹é‡å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    
    # æµ‹è¯•4: æµ‹è¯•ä¼°ç®—æ–¹æ³•
    print("\nğŸ“Š æµ‹è¯•4: æµ‹è¯•ä¼°ç®—æ–¹æ³•")
    try:
        from training.utils.monitor import _estimate_flops_fallback
        estimated_flops = _estimate_flops_fallback(model, test_batch, seq_length)
        print(f"âœ… ä¼°ç®—æ–¹æ³•: {estimated_flops:.2e}")
    except Exception as e:
        print(f"âŒ ä¼°ç®—æ–¹æ³•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    
    print("\nâœ… å®‰å…¨Profileræµ‹è¯•å®Œæˆ")

if __name__ == "__main__":
    test_profiler_safe() 