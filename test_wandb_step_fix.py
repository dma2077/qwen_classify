#!/usr/bin/env python3
"""
æµ‹è¯•WandB stepä¿®å¤
éªŒè¯stepå†²çªé—®é¢˜æ˜¯å¦å·²è§£å†³
"""

import torch
import sys
import os
import time

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def test_wandb_step_fix():
    """æµ‹è¯•WandB stepä¿®å¤"""
    
    print("ğŸ§ª æµ‹è¯•WandB stepä¿®å¤...")
    print("=" * 50)
    
    # æ£€æŸ¥WandBæ˜¯å¦å¯ç”¨
    try:
        import wandb
        print(f"âœ… WandBå¯ç”¨: {wandb.__version__}")
    except ImportError:
        print("âŒ WandBä¸å¯ç”¨ï¼Œè·³è¿‡æµ‹è¯•")
        return
    
    # æ£€æŸ¥CUDAæ˜¯å¦å¯ç”¨
    if not torch.cuda.is_available():
        print("âŒ CUDAä¸å¯ç”¨ï¼Œè·³è¿‡æµ‹è¯•")
        return
    
    device = torch.device('cuda:0')
    
    # åˆ›å»ºä¸€ä¸ªç®€å•çš„æµ‹è¯•æ¨¡å‹
    class SimpleModel(torch.nn.Module):
        def __init__(self):
            super().__init__()
            self.linear1 = torch.nn.Linear(512, 256)
            self.linear2 = torch.nn.Linear(256, 101)
            self.relu = torch.nn.ReLU()
            
        def forward(self, input_ids, attention_mask, pixel_values, labels):
            batch_size = input_ids.size(0)
            seq_len = input_ids.size(1)
            
            # ç®€å•çš„æ–‡æœ¬å¤„ç†
            text_features = torch.randn(batch_size, seq_len, 512, device=input_ids.device)
            text_output = self.linear1(text_features)
            text_output = self.relu(text_output)
            
            # ç®€å•çš„å›¾åƒå¤„ç†
            image_features = torch.randn(batch_size, 256, device=pixel_values.device)
            image_output = image_features.unsqueeze(1).expand(-1, seq_len, -1)
            
            # èåˆç‰¹å¾
            combined = text_output + image_output
            logits = self.linear2(combined)
            
            # ç®€åŒ–çš„æŸå¤±è®¡ç®—
            first_token_logits = logits[:, 0, :]
            loss = torch.nn.functional.cross_entropy(first_token_logits, labels)
            
            class Outputs:
                def __init__(self, loss, logits):
                    self.loss = loss
                    self.logits = logits
            
            return Outputs(loss, logits)
    
    # åˆ›å»ºæ¨¡å‹
    model = SimpleModel().to(device)
    print(f"âœ… åˆ›å»ºæµ‹è¯•æ¨¡å‹: {sum(p.numel() for p in model.parameters()):,} å‚æ•°")
    
    # åˆ›å»ºæµ‹è¯•batch
    batch_size = 8
    seq_length = 512
    
    test_batch = {
        'input_ids': torch.randint(0, 1000, (batch_size, seq_length), device=device),
        'attention_mask': torch.ones(batch_size, seq_length, device=device),
        'pixel_values': torch.randn(batch_size, 3, 224, 224, device=device),
        'labels': torch.randint(0, 101, (batch_size,), device=device)
    }
    
    print(f"âœ… åˆ›å»ºæµ‹è¯•batch: batch_size={batch_size}, seq_length={seq_length}")
    
    # æµ‹è¯•1: æµ‹è¯•stepå€’é€€æ£€æµ‹
    print("\nğŸ“Š æµ‹è¯•1: æµ‹è¯•stepå€’é€€æ£€æµ‹")
    try:
        from training.utils.monitor import TrainingMonitor
        
        # åˆ›å»ºé…ç½®
        config = {
            'wandb': {
                'enabled': True,
                'project': 'test_step_fix',
                'run_name': 'test_run'
            },
            'output_dir': './test_output'
        }
        
        # åˆ›å»ºmonitor
        monitor = TrainingMonitor('./test_output', config)
        
        # æµ‹è¯•æ­£å¸¸çš„stepè®°å½•
        print("  æµ‹è¯•æ­£å¸¸stepè®°å½•...")
        training_data = {
            "training/loss": 0.5,
            "training/lr": 1e-4,
            "step": 100
        }
        monitor.log_metrics(training_data, step=100, commit=True)
        print("  âœ… æ­£å¸¸stepè®°å½•æˆåŠŸ")
        
        # æµ‹è¯•stepå€’é€€
        print("  æµ‹è¯•stepå€’é€€...")
        training_data = {
            "training/loss": 0.4,
            "training/lr": 1e-4,
            "step": 50  # å€’é€€çš„step
        }
        monitor.log_metrics(training_data, step=50, commit=True)
        print("  âœ… stepå€’é€€æ£€æµ‹æˆåŠŸ")
        
    except Exception as e:
        print(f"âŒ stepå€’é€€æ£€æµ‹æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    
    # æµ‹è¯•2: æµ‹è¯•é‡å¤stepå­—æ®µå¤„ç†
    print("\nğŸ“Š æµ‹è¯•2: æµ‹è¯•é‡å¤stepå­—æ®µå¤„ç†")
    try:
        # æµ‹è¯•åŒ…å«é‡å¤stepå­—æ®µçš„æ•°æ®
        training_data = {
            "training/loss": 0.3,
            "training/lr": 1e-4,
            "step": 200,  # é‡å¤çš„stepå­—æ®µ
            "perf/mfu": 0.8
        }
        monitor.log_metrics(training_data, step=200, commit=True)
        print("  âœ… é‡å¤stepå­—æ®µå¤„ç†æˆåŠŸ")
        
    except Exception as e:
        print(f"âŒ é‡å¤stepå­—æ®µå¤„ç†æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    
    # æµ‹è¯•3: æµ‹è¯•è¿ç»­stepè®°å½•
    print("\nğŸ“Š æµ‹è¯•3: æµ‹è¯•è¿ç»­stepè®°å½•")
    try:
        # æµ‹è¯•è¿ç»­è®°å½•å¤šä¸ªstep
        for step in range(300, 310):
            training_data = {
                "training/loss": 0.5 - step * 0.001,
                "training/lr": 1e-4,
                "perf/mfu": 0.8 + step * 0.001
            }
            monitor.log_metrics(training_data, step=step, commit=True)
            time.sleep(0.1)  # çŸ­æš‚å»¶è¿Ÿ
        
        print("  âœ… è¿ç»­stepè®°å½•æˆåŠŸ")
        
    except Exception as e:
        print(f"âŒ è¿ç»­stepè®°å½•æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    
    # æµ‹è¯•4: æµ‹è¯•evalæŒ‡æ ‡è®°å½•
    print("\nğŸ“Š æµ‹è¯•4: æµ‹è¯•evalæŒ‡æ ‡è®°å½•")
    try:
        # æµ‹è¯•evalæŒ‡æ ‡è®°å½•
        eval_data = {
            "eval/overall_loss": 0.3,
            "eval/overall_accuracy": 0.85,
            "eval/overall_samples": 1000,
            "eval/overall_correct": 850
        }
        monitor.log_metrics(eval_data, step=400, commit=True)
        print("  âœ… evalæŒ‡æ ‡è®°å½•æˆåŠŸ")
        
    except Exception as e:
        print(f"âŒ evalæŒ‡æ ‡è®°å½•æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    
    # æ¸…ç†
    try:
        if hasattr(monitor, 'use_wandb') and monitor.use_wandb:
            import wandb
            if wandb.run is not None:
                wandb.finish()
                print("  âœ… WandBè¿è¡Œå·²ç»“æŸ")
    except Exception as e:
        print(f"âš ï¸  æ¸…ç†WandBå¤±è´¥: {e}")
    
    print("\nâœ… WandB stepä¿®å¤æµ‹è¯•å®Œæˆ")

if __name__ == "__main__":
    test_wandb_step_fix() 