#!/usr/bin/env python3
"""
æµ‹è¯•trainingå’ŒevalæŒ‡æ ‡åŒæ—¶è®°å½•åˆ°WandB
"""

import os
import sys
import time
import json
import yaml

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def test_combined_metrics_logging():
    """æµ‹è¯•åˆå¹¶æŒ‡æ ‡è®°å½•"""
    
    print("ğŸ§ª å¼€å§‹æµ‹è¯•åˆå¹¶æŒ‡æ ‡è®°å½•...")
    
    # æ¨¡æ‹Ÿé…ç½®
    config = {
        'output_dir': './test_output',
        'wandb': {
            'project': 'test_metrics',
            'name': 'test_combined_metrics',
            'enabled': True
        },
        'monitor': {
            'freq': {
                'log_freq': 1,
                'eval_log_freq': 1,
                'perf_log_freq': 1,
                'flops_profile_freq': 10
            }
        }
    }
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(config['output_dir'], exist_ok=True)
    
    # åˆå§‹åŒ–monitor
    from training.utils.monitor import TrainingMonitor
    monitor = TrainingMonitor(config['output_dir'], config)
    
    # æ¨¡æ‹Ÿè®­ç»ƒå’Œevalæ•°æ®
    for step in range(1, 11):
        print(f"\nğŸ“Š æ­¥éª¤ {step}:")
        
        # æ¨¡æ‹Ÿtrainingæ•°æ®
        training_data = {
            "training/loss": 0.1 + step * 0.01,
            "training/lr": 1e-4,
            "training/epoch": 0.1,
            "training/grad_norm": 1.0 + step * 0.1,
        }
        
        # æ¨¡æ‹Ÿevalæ•°æ®ï¼ˆæ¯5æ­¥è¯„ä¼°ä¸€æ¬¡ï¼‰
        eval_data = {}
        if step % 5 == 0:
            eval_data = {
                "eval/overall_loss": 0.2 + step * 0.01,
                "eval/overall_accuracy": 0.8 - step * 0.01,
                "eval/overall_samples": 1000,
                "eval/overall_correct": 800 - step * 10,
            }
            print(f"   ğŸ“ˆ åŒ…å«evalæŒ‡æ ‡: {list(eval_data.keys())}")
        else:
            print(f"   ğŸ“ˆ ä»…åŒ…å«trainingæŒ‡æ ‡")
        
        # åˆå¹¶æ•°æ®
        combined_data = {**training_data, **eval_data}
        combined_data["step"] = step
        
        # è®°å½•åˆ°WandB
        monitor.log_metrics(combined_data, step, commit=True)
        
        print(f"   âœ… å·²è®°å½• {len(combined_data)} ä¸ªæŒ‡æ ‡")
        print(f"   ğŸ“Š æŒ‡æ ‡keys: {list(combined_data.keys())}")
        
        time.sleep(1)  # é¿å…WandB APIé™åˆ¶
    
    print("\nğŸ‰ æµ‹è¯•å®Œæˆï¼")
    print("è¯·æ£€æŸ¥WandBç•Œé¢ï¼Œåº”è¯¥èƒ½çœ‹åˆ°:")
    print("  - training/loss, training/lr, training/epoch, training/grad_norm")
    print("  - eval/overall_loss, eval/overall_accuracy (æ¯5æ­¥)")
    print("  - æ‰€æœ‰æŒ‡æ ‡éƒ½ä½¿ç”¨ç›¸åŒçš„stepè½´")

if __name__ == "__main__":
    test_combined_metrics_logging() 