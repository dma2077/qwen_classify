#!/usr/bin/env python3
"""
å…¨é¢æµ‹è¯•æ‰€æœ‰æŒ‡æ ‡åœ¨WandBä¸­çš„æ˜¾ç¤º
éªŒè¯trainingã€evalã€perfç­‰æ‰€æœ‰æŒ‡æ ‡ç»„æ˜¯å¦æ­£å¸¸æ˜¾ç¤º
"""

import os
import sys
import time
import torch
import yaml
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from training.utils.monitor import TrainingMonitor
from training.utils.config_utils import prepare_config

def test_all_metrics_display():
    """æµ‹è¯•æ‰€æœ‰æŒ‡æ ‡åœ¨WandBä¸­çš„æ˜¾ç¤º"""
    
    print("ğŸ§ª å¼€å§‹å…¨é¢æµ‹è¯•æ‰€æœ‰æŒ‡æ ‡æ˜¾ç¤º...")
    
    # åˆ›å»ºæµ‹è¯•é…ç½®
    test_config = {
        'model': {
            'pretrained_name': 'Qwen/Qwen2.5-VL-7B-Instruct',
            'num_labels': 10
        },
        'training': {
            'epochs': 1,
            'lr': 1e-5,
            'output_dir': './test_outputs/all_metrics_test',
            'logging_steps': 1,
            'eval_steps': 5,
            'save_steps': 10
        },
        'monitor': {
            'freq': {
                'training_log_freq': 1,
                'perf_log_freq': 2,
                'gpu_log_freq': 3,
                'flops_profile_freq': 4,
                'local_save_freq': 5
            }
        },
        'wandb': {
            'enabled': True,
            'project': 'qwen-classify-test',
            'run_name': 'all_metrics_display_test',
            'tags': ['test', 'metrics', 'display'],
            'notes': 'å…¨é¢æµ‹è¯•æ‰€æœ‰æŒ‡æ ‡æ˜¾ç¤ºåŠŸèƒ½'
        }
    }
    
    # å‡†å¤‡é…ç½®
    config = prepare_config(test_config)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = config['training']['output_dir']
    os.makedirs(output_dir, exist_ok=True)
    
    # åˆå§‹åŒ–ç›‘æ§å™¨
    monitor = TrainingMonitor(
        output_dir=output_dir,
        config=config,
        flops_profile_freq=4
    )
    
    # åˆ›å»ºè™šæ‹Ÿæ¨¡å‹å¼•ç”¨ï¼ˆç”¨äºMFUè®¡ç®—ï¼‰
    class DummyModel:
        def __init__(self):
            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        def parameters(self):
            return [torch.randn(1000, 1000, device=self.device)]
        
        def eval(self):
            pass
        
        def __call__(self, **kwargs):
            return torch.randn(2, 10)  # æ¨¡æ‹Ÿè¾“å‡º
    
    dummy_model = DummyModel()
    monitor.set_model_ref(dummy_model)
    
    print("âœ… ç›‘æ§å™¨åˆå§‹åŒ–å®Œæˆ")
    
    # å¼€å§‹è®­ç»ƒç›‘æ§
    monitor.start_training()
    
    # æ¨¡æ‹Ÿè®­ç»ƒæ­¥éª¤
    print("\nğŸ“Š æ¨¡æ‹Ÿè®­ç»ƒæ­¥éª¤...")
    for step in range(1, 21):  # 20æ­¥
        epoch = step // 10
        loss = 2.0 - (step * 0.05)  # æ¨¡æ‹ŸæŸå¤±ä¸‹é™
        grad_norm = 1.0 + (step * 0.01)  # æ¨¡æ‹Ÿæ¢¯åº¦èŒƒæ•°
        lr = 1e-5 * (0.9 ** (step // 5))  # æ¨¡æ‹Ÿå­¦ä¹ ç‡è¡°å‡
        
        # åˆ›å»ºè™šæ‹Ÿattention_mask
        attention_mask = torch.ones(2, 512)  # batch_size=2, seq_len=512
        
        # æ¨¡æ‹Ÿå®æ—¶FLOPsæµ‹é‡
        real_time_flops = 1e12 + (step * 1e10)  # æ¨¡æ‹ŸFLOPså˜åŒ–
        
        # è®°å½•è®­ç»ƒæ­¥éª¤
        is_eval_step = (step % 5 == 0)
        monitor.log_step(
            step=step,
            epoch=epoch,
            loss=loss,
            grad_norm=grad_norm,
            learning_rate=lr,
            attention_mask=attention_mask,
            real_time_flops=real_time_flops,
            skip_wandb=is_eval_step  # evalæ­¥éª¤è·³è¿‡wandbè®°å½•
        )
        
        # å¦‚æœæ˜¯è¯„ä¼°æ­¥éª¤ï¼Œè®°å½•è¯„ä¼°æŒ‡æ ‡
        if is_eval_step:
            eval_loss = loss * 0.8  # è¯„ä¼°æŸå¤±é€šå¸¸æ¯”è®­ç»ƒæŸå¤±ä½
            eval_accuracy = 0.5 + (step * 0.02)  # æ¨¡æ‹Ÿå‡†ç¡®ç‡æå‡
            
            # è®°å½•è¯„ä¼°æŒ‡æ ‡
            eval_data = {
                "eval/overall_loss": eval_loss,
                "eval/overall_accuracy": eval_accuracy,
                "eval/step": step
            }
            
            # åˆå¹¶è®­ç»ƒå’Œè¯„ä¼°æŒ‡æ ‡
            training_data = {
                "training/loss": loss,
                "training/lr": lr,
                "training/epoch": epoch,
                "training/grad_norm": grad_norm,
            }
            
            # æ·»åŠ æ€§èƒ½æŒ‡æ ‡ï¼ˆå¦‚æœåº”è¯¥è®°å½•ï¼‰
            if step % monitor.freq['perf_log_freq'] == 0:
                training_data.update({
                    "perf/step_time": 0.1 + (step * 0.01),
                    "perf/steps_per_second": 10.0 - (step * 0.1),
                    "perf/mfu": 0.3 + (step * 0.01),
                    "perf/mfu_percent": (0.3 + (step * 0.01)) * 100,
                    "perf/tokens_per_second": 1000 + (step * 50),
                    "perf/samples_per_second": 20 + (step * 1),
                    "perf/actual_flops": real_time_flops,
                    "perf/actual_seq_length": 512,
                    "perf/flops_per_second": real_time_flops / 0.1,
                })
            
            # æ·»åŠ GPUæŒ‡æ ‡ï¼ˆå¦‚æœåº”è¯¥è®°å½•ï¼‰
            if step % monitor.freq['gpu_log_freq'] == 0:
                training_data.update({
                    "perf/gpu_memory_allocated_gb": 8.0 + (step * 0.1),
                    "perf/gpu_memory_reserved_gb": 10.0 + (step * 0.1),
                    "perf/gpu_memory_utilization_percent": 60.0 + (step * 1.0),
                })
            
            # åˆå¹¶æ‰€æœ‰æŒ‡æ ‡
            combined_data = {**training_data, **eval_data}
            combined_data["step"] = step
            
            # è®°å½•åˆ°WandB
            monitor.log_metrics(combined_data, step, commit=True)
            
            print(f"âœ… æ­¥éª¤ {step}: å·²è®°å½• {len(combined_data)} ä¸ªæŒ‡æ ‡")
            print(f"   è®­ç»ƒæŒ‡æ ‡: {list(training_data.keys())}")
            print(f"   è¯„ä¼°æŒ‡æ ‡: {list(eval_data.keys())}")
        
        time.sleep(0.1)  # çŸ­æš‚å»¶è¿Ÿï¼Œé¿å…WandB APIé™åˆ¶
    
    # è®°å½•epochç»Ÿè®¡
    monitor.log_epoch(epoch=1, avg_loss=1.5, elapsed_time=10.0, current_step=20)
    
    # è®°å½•æœ€ç»ˆè¯„ä¼°
    final_eval_data = {
        "eval/final_overall_loss": 1.2,
        "eval/final_overall_accuracy": 0.85,
        "eval/final_evaluation": 1.0
    }
    monitor.log_metrics(final_eval_data, 20, commit=True)
    
    # ç»“æŸè®­ç»ƒ
    monitor.finish_training()
    
    print("\nğŸ‰ æµ‹è¯•å®Œæˆï¼")
    print("ğŸ“Š è¯·æ£€æŸ¥WandBç•Œé¢ï¼Œç¡®è®¤ä»¥ä¸‹æŒ‡æ ‡ç»„æ˜¯å¦æ­£å¸¸æ˜¾ç¤ºï¼š")
    print("   â€¢ training/* - è®­ç»ƒæŒ‡æ ‡")
    print("   â€¢ eval/* - è¯„ä¼°æŒ‡æ ‡") 
    print("   â€¢ perf/* - æ€§èƒ½æŒ‡æ ‡")
    print("   â€¢ æ‰€æœ‰æŒ‡æ ‡éƒ½åº”è¯¥æœ‰ç»Ÿä¸€çš„'step'ä½œä¸ºxè½´")
    
    return True

if __name__ == "__main__":
    try:
        test_all_metrics_display()
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1) 