#!/usr/bin/env python3
"""
æµ‹è¯•è¯„ä¼°é€Ÿåº¦å’Œé…ç½®ä¼ é€’
"""

import os
import sys
import json
import yaml
import torch
import time
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.dirname(os.path.abspath(__file__))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from data.dataloader import create_dataloaders
from models.qwen2_5_vl_classify import Qwen2_5_VLForImageClassification

def test_eval_speed():
    """æµ‹è¯•è¯„ä¼°é€Ÿåº¦"""
    print("ğŸ” æµ‹è¯•è¯„ä¼°é€Ÿåº¦å’Œé…ç½®ä¼ é€’")
    print("="*60)
    
    # åŠ è½½é…ç½®
    config_path = "configs/food101_cosine_hold.yaml"
    deepspeed_config_path = "configs/ds_minimal.json"
    
    print(f"ğŸ“‹ åŠ è½½é…ç½®æ–‡ä»¶:")
    print(f"  â€¢ YAMLé…ç½®: {config_path}")
    print(f"  â€¢ DeepSpeedé…ç½®: {deepspeed_config_path}")
    
    # åŠ è½½YAMLé…ç½®
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    # åŠ è½½DeepSpeedé…ç½®
    with open(deepspeed_config_path, 'r') as f:
        deepspeed_config = json.load(f)
    
    # å°†DeepSpeedé…ç½®æ·»åŠ åˆ°configä¸­
    config['deepspeed'] = deepspeed_config_path
    
    print(f"\nğŸ“Š DeepSpeedé…ç½®:")
    print(f"  â€¢ train_batch_size: {deepspeed_config.get('train_batch_size')}")
    print(f"  â€¢ train_micro_batch_size_per_gpu: {deepspeed_config.get('train_micro_batch_size_per_gpu')}")
    print(f"  â€¢ gradient_accumulation_steps: {deepspeed_config.get('gradient_accumulation_steps')}")
    
    print(f"\nğŸ“Š è¯„ä¼°é…ç½®:")
    dataset_configs = config.get('datasets', {}).get('dataset_configs', {})
    for dataset_name, dataset_config in dataset_configs.items():
        eval_ratio = dataset_config.get('eval_ratio', 1.0)
        print(f"  â€¢ {dataset_name}: eval_ratio={eval_ratio}")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    print(f"\nğŸ”§ åˆ›å»ºæ•°æ®åŠ è½½å™¨...")
    start_time = time.time()
    
    try:
        train_loader, val_loader = create_dataloaders(config)
        load_time = time.time() - start_time
        
        print(f"âœ… æ•°æ®åŠ è½½å™¨åˆ›å»ºæˆåŠŸ (è€—æ—¶: {load_time:.2f}s)")
        print(f"  â€¢ è®­ç»ƒé›†: {len(train_loader.dataset):,} æ ·æœ¬")
        print(f"  â€¢ éªŒè¯é›†: {len(val_loader.dataset):,} æ ·æœ¬")
        print(f"  â€¢ éªŒè¯æ‰¹æ¬¡æ•°: {len(val_loader)}")
        print(f"  â€¢ æ‰¹æ¬¡å¤§å°: {val_loader.batch_size}")
        
        # è®¡ç®—é¢„æœŸçš„è¯„ä¼°æ—¶é—´
        estimated_batches = len(val_loader)
        estimated_time_per_batch = 2.0  # å‡è®¾æ¯æ‰¹æ¬¡2ç§’ï¼ˆä¿å®ˆä¼°è®¡ï¼‰
        estimated_total_time = estimated_batches * estimated_time_per_batch
        
        print(f"\nâ±ï¸ è¯„ä¼°æ—¶é—´ä¼°ç®—:")
        print(f"  â€¢ é¢„è®¡æ‰¹æ¬¡æ•°: {estimated_batches}")
        print(f"  â€¢ é¢„è®¡æ¯æ‰¹æ¬¡æ—¶é—´: {estimated_time_per_batch}s")
        print(f"  â€¢ é¢„è®¡æ€»è¯„ä¼°æ—¶é—´: {estimated_total_time:.1f}s ({estimated_total_time/60:.1f}åˆ†é’Ÿ)")
        
        # æµ‹è¯•ä¸€ä¸ªæ‰¹æ¬¡çš„å¤„ç†æ—¶é—´
        print(f"\nğŸ§ª æµ‹è¯•å•æ‰¹æ¬¡å¤„ç†æ—¶é—´...")
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        # åˆ›å»ºæ¨¡å‹ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼Œåªç”¨äºæµ‹è¯•ï¼‰
        model = Qwen2_5_VLForImageClassification(
            pretrained_model_name=config['model']['pretrained_name'],
            num_labels=config['model']['num_labels']
        )
        model.to(device)
        model.eval()
        
        # æµ‹è¯•å‡ ä¸ªæ‰¹æ¬¡
        batch_times = []
        for i, batch in enumerate(val_loader):
            if i >= 3:  # åªæµ‹è¯•å‰3ä¸ªæ‰¹æ¬¡
                break
                
            start_batch = time.time()
            
            # ç§»åŠ¨æ•°æ®åˆ°è®¾å¤‡
            inputs = batch["input_ids"].to(device)
            attention_mask = batch["attention_mask"].to(device)
            pixel_values = batch["pixel_values"].to(device)
            labels = batch["labels"].to(device)
            
            # å‰å‘ä¼ æ’­
            with torch.no_grad():
                outputs = model(
                    input_ids=inputs,
                    attention_mask=attention_mask,
                    pixel_values=pixel_values,
                    labels=labels
                )
            
            batch_time = time.time() - start_batch
            batch_times.append(batch_time)
            
            print(f"  â€¢ æ‰¹æ¬¡ {i+1}: {batch_time:.2f}s")
        
        if batch_times:
            avg_batch_time = sum(batch_times) / len(batch_times)
            print(f"  â€¢ å¹³å‡æ‰¹æ¬¡æ—¶é—´: {avg_batch_time:.2f}s")
            
            # é‡æ–°è®¡ç®—æ€»è¯„ä¼°æ—¶é—´
            real_estimated_time = len(val_loader) * avg_batch_time
            print(f"  â€¢ å®é™…é¢„è®¡æ€»è¯„ä¼°æ—¶é—´: {real_estimated_time:.1f}s ({real_estimated_time/60:.1f}åˆ†é’Ÿ)")
        
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å™¨åˆ›å»ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_eval_speed() 