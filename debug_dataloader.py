#!/usr/bin/env python3
"""
æ•°æ®åŠ è½½å™¨è°ƒè¯•è„šæœ¬ - ç”¨äºæ’æŸ¥è®­ç»ƒå¡ä½é—®é¢˜
"""

import os
import sys
import yaml
import time
import torch

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.dirname(os.path.abspath(__file__))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

def debug_dataloader():
    """è°ƒè¯•æ•°æ®åŠ è½½å™¨"""
    print("ğŸ” å¼€å§‹è°ƒè¯•æ•°æ®åŠ è½½å™¨...")
    
    # è®¾ç½®ç¯å¢ƒå˜é‡
    os.environ['NCCL_NTHREADS'] = '64'
    
    # åŠ è½½é…ç½®
    config_file = "configs/fast_eval_config.yaml"  # ä½¿ç”¨å¿«é€Ÿé…ç½®
    print(f"ğŸ“‹ åŠ è½½é…ç½®æ–‡ä»¶: {config_file}")
    
    with open(config_file, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    # å‡†å¤‡é…ç½®
    from training.utils.config_utils import prepare_config
    config = prepare_config(config)
    
    print("âœ… é…ç½®åŠ è½½å®Œæˆ")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    print("ğŸ“¦ åˆ›å»ºæ•°æ®åŠ è½½å™¨...")
    from data.dataloader import create_dataloaders
    
    start_time = time.time()
    train_loader, val_loader = create_dataloaders(config)
    dataloader_time = time.time() - start_time
    
    print(f"âœ… æ•°æ®åŠ è½½å™¨åˆ›å»ºå®Œæˆ (è€—æ—¶: {dataloader_time:.2f}s)")
    print(f"ğŸ“Š è®­ç»ƒæ•°æ®é›†å¤§å°: {len(train_loader.dataset)}")
    print(f"ğŸ“Š éªŒè¯æ•°æ®é›†å¤§å°: {len(val_loader.dataset)}")
    print(f"ğŸ“Š è®­ç»ƒæ‰¹æ¬¡æ•°: {len(train_loader)}")
    
    # æµ‹è¯•è·å–ç¬¬ä¸€ä¸ªbatch
    print("ğŸ”¥ æµ‹è¯•è·å–ç¬¬ä¸€ä¸ªè®­ç»ƒbatch...")
    start_time = time.time()
    
    try:
        # è®¾ç½®è¶…æ—¶ä¿æŠ¤
        import signal
        
        def timeout_handler(signum, frame):
            print("âš ï¸ è·å–batchè¶…æ—¶ï¼")
            raise TimeoutError("è·å–batchè¶…æ—¶")
        
        signal.signal(signal.SIGALRM, timeout_handler)
        signal.alarm(30)  # 30ç§’è¶…æ—¶
        
        first_batch = next(iter(train_loader))
        signal.alarm(0)  # å–æ¶ˆè¶…æ—¶
        
        batch_time = time.time() - start_time
        print(f"âœ… æˆåŠŸè·å–ç¬¬ä¸€ä¸ªbatch (è€—æ—¶: {batch_time:.2f}s)")
        
        # æ£€æŸ¥batchå†…å®¹
        print("ğŸ“‹ Batchå†…å®¹:")
        for key, value in first_batch.items():
            if isinstance(value, torch.Tensor):
                print(f"  â€¢ {key}: {value.shape} ({value.dtype})")
            else:
                print(f"  â€¢ {key}: {type(value)} (é•¿åº¦: {len(value) if hasattr(value, '__len__') else 'N/A'})")
                
    except TimeoutError:
        print("âŒ è·å–ç¬¬ä¸€ä¸ªbatchè¶…æ—¶")
        return False
    except Exception as e:
        print(f"âŒ è·å–ç¬¬ä¸€ä¸ªbatchå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # æµ‹è¯•è·å–å¤šä¸ªbatch
    print("ğŸ”¥ æµ‹è¯•è·å–å‰3ä¸ªbatch...")
    start_time = time.time()
    
    try:
        for i, batch in enumerate(train_loader):
            if i >= 3:
                break
            print(f"  âœ… æˆåŠŸè·å–batch {i+1}")
            
        multi_batch_time = time.time() - start_time
        print(f"âœ… æˆåŠŸè·å–å‰3ä¸ªbatch (è€—æ—¶: {multi_batch_time:.2f}s)")
        
    except Exception as e:
        print(f"âŒ è·å–å¤šä¸ªbatchå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    print("ğŸ‰ æ•°æ®åŠ è½½å™¨æµ‹è¯•å®Œæˆï¼Œæ²¡æœ‰å‘ç°é—®é¢˜ï¼")
    return True

if __name__ == "__main__":
    debug_dataloader() 