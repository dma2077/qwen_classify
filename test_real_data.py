import torch
import os
from PIL import Image
from transformers import AutoProcessor
from models.qwen2_5_vl_classify import Qwen2_5_VLForImageClassification

def test_real_multimodal_data():
    """ä½¿ç”¨çœŸå®çš„å¤šæ¨¡æ€æ•°æ®æµ‹è¯•tokené•¿åº¦å’Œpooling"""
    
    print("="*80)
    print("ğŸ” ä½¿ç”¨çœŸå®æ•°æ®æµ‹è¯•Qwen2.5-VL Tokené•¿åº¦å’ŒPooling")
    print("="*80)
    
    # 1. è®¾ç½®è·¯å¾„
    model_path = "/llm_reco/dehua/model/Qwen2.5-VL-7B-Instruct"
    local_path = "/llm_reco/dehua/data/food_data/food-101/images/apple_pie/2928660.jpg"
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(local_path):
        print(f"âŒ å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {local_path}")
        return
    
    # 2. å‡†å¤‡çœŸå®æ•°æ®ï¼ˆä¸¤ä¸ªæ ·æœ¬çš„batchï¼‰
    print("ğŸ“Š å‡†å¤‡çœŸå®æµ‹è¯•æ•°æ®...")
    try:
        # åŠ è½½å›¾ç‰‡
        image = Image.open(local_path).convert("RGB")
        print(f"âœ… å›¾ç‰‡åŠ è½½æˆåŠŸ: {image.size}")
        
        # æ„å»ºç¬¬ä¸€ä¸ªæ ·æœ¬çš„messages
        messages1 = [
            {
                "role": "user",
                "content": [
                    {"type": "image", "image": local_path},
                    {"type": "text", "text": "What is shown in this image?"},
                ],
            },
        ]
        
        # æ„å»ºç¬¬äºŒä¸ªæ ·æœ¬çš„messagesï¼ˆæ–‡æœ¬æ›´é•¿ï¼‰
        messages2 = [
            {
                "role": "user",
                "content": [
                    {"type": "image", "image": local_path},
                    {"type": "text", "text": "What is shown in this image Please give your answer briefly?"},
                ],
            },
        ]
        
        print("âœ… ä¸¤ä¸ªæ ·æœ¬çš„Messagesæ„å»ºæˆåŠŸ")
        print(f"ğŸ“ æ ·æœ¬1æ–‡æœ¬: 'What is shown in this image?'")
        print(f"ğŸ“ æ ·æœ¬2æ–‡æœ¬: 'What is shown in this image Please give your answer briefly?'")
        
    except Exception as e:
        print(f"âŒ æ•°æ®å‡†å¤‡å¤±è´¥: {e}")
        return
    
    # 3. åŠ è½½processor
    print("\nğŸ“¦ åŠ è½½processor...")
    try:
        processor = AutoProcessor.from_pretrained(model_path)
        print("âœ… ProcessoråŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âŒ ProcessoråŠ è½½å¤±è´¥: {e}")
        return
    
    # 4. æŒ‰ç…§collator.pyçš„æ–¹å¼å¤„ç†æ•°æ®
    print("\nğŸ”„ æŒ‰ç…§collator.pyæ–¹å¼å¤„ç†æ•°æ®...")
    try:
        # æ¨¡æ‹Ÿbatchæ•°æ®ï¼ˆä¸¤ä¸ªæ ·æœ¬ï¼‰
        batch = [
            {
                "image": image,
                "messages": messages1,
                "label": 0  # å‡è®¾æ ‡ç­¾ï¼šapple_pie
            },
            {
                "image": image,  # ä½¿ç”¨ç›¸åŒå›¾ç‰‡
                "messages": messages2,
                "label": 1  # å‡è®¾æ ‡ç­¾ï¼šä¸åŒç±»åˆ«
            }
        ]
        
        # æå–æ•°æ®
        images = [item["image"] for item in batch]
        msgs = [item["messages"] for item in batch]
        labels = torch.tensor([item["label"] for item in batch], dtype=torch.long)
        
        print(f"ğŸ“‹ Batchä¿¡æ¯:")
        print(f"  â€¢ Images: {len(images)}")
        print(f"  â€¢ Messages: {len(msgs)}")
        print(f"  â€¢ Labels: {labels}")
        
        # 1) è½¬æ¢ä¸ºchatæ¨¡æ¿
        text_list = []
        for i, m in enumerate(msgs):
            text = processor.apply_chat_template(
                conversation=m,
                tokenize=False,
                add_generation_prompt=True
            )
            text_list.append(text)
            print(f"\nğŸ“ æ ·æœ¬{i+1}ç”Ÿæˆçš„chatæ¨¡æ¿:")
            print(f"æ–‡æœ¬é•¿åº¦: {len(text)} å­—ç¬¦")
            print(f"æ–‡æœ¬å†…å®¹:\n{text}")
        
        # 2) ä½¿ç”¨processorå¤„ç†å¤šæ¨¡æ€è¾“å…¥
        enc = processor(
            text=text_list,
            images=images,
            return_tensors="pt",
            padding=True,
            truncation=True,
            max_length=2048
        )
        
        # æ·»åŠ labels
        enc["labels"] = labels
        
        print("âœ… æ•°æ®å¤„ç†æˆåŠŸ")
        
    except Exception as e:
        print(f"âŒ æ•°æ®å¤„ç†å¤±è´¥: {e}")
        return
    
    # 5. åˆ†æå¤„ç†åçš„æ•°æ®
    print(f"\nğŸ“‹ å¤„ç†åæ•°æ®åˆ†æ:")
    print("-" * 60)
    
    input_ids = enc['input_ids']
    attention_mask = enc['attention_mask']
    pixel_values = enc['pixel_values']
    
    print(f"ğŸ”¤ input_idså½¢çŠ¶: {input_ids.shape}")
    print(f"ğŸ¯ attention_maskå½¢çŠ¶: {attention_mask.shape}")
    print(f"ğŸ–¼ï¸  pixel_valueså½¢çŠ¶: {pixel_values.shape}")
    
    # æ£€æŸ¥image_grid_thw
    if 'image_grid_thw' in enc:
        image_grid_thw = enc['image_grid_thw']
        print(f"ğŸ“ image_grid_thwå½¢çŠ¶: {image_grid_thw.shape}")
        print(f"ğŸ“ image_grid_thwå€¼: {image_grid_thw}")
        
        # è®¡ç®—visual tokensæ•°é‡
        visual_tokens = image_grid_thw[0, 0] * image_grid_thw[0, 1] * image_grid_thw[0, 2]
        print(f"ğŸ‘ï¸  è®¡ç®—çš„visual tokensæ•°é‡: {visual_tokens}")
    else:
        print("âš ï¸  æ²¡æœ‰æ‰¾åˆ°image_grid_thw")
        visual_tokens = None
    
    # 6. åˆ†æåºåˆ—é•¿åº¦
    print(f"\nğŸ“ åºåˆ—é•¿åº¦è¯¦ç»†åˆ†æ:")
    print("-" * 60)
    
    batch_size = input_ids.size(0)
    text_length = input_ids.size(1)
    attention_length = attention_mask.size(1)
    
    print(f"ğŸ“¦ Batchå¤§å°: {batch_size}")
    print(f"ğŸ“ æ–‡æœ¬tokensé•¿åº¦ (input_ids): {text_length}")
    print(f"ğŸ¯ attention_maskæ€»é•¿åº¦: {attention_length}")
    
    # åˆ†ææ¯ä¸ªæ ·æœ¬çš„æœ‰æ•ˆtokens
    for i in range(batch_size):
        valid_tokens = attention_mask[i].sum().item()
        print(f"âœ… æ ·æœ¬{i+1}æœ‰æ•ˆtokensæ•°é‡: {valid_tokens}")
        print(f"ğŸ” æ ·æœ¬{i+1}æ¨æ–­çš„visual tokens: {valid_tokens - text_length}")
        
        if visual_tokens is not None:
            print(f"ğŸ“ æ ·æœ¬{i+1} image_grid_thwè®¡ç®—çš„visual tokens: {visual_tokens}")
            print(f"ğŸ”„ æ ·æœ¬{i+1} ä¸¤ç§æ–¹æ³•çš„å·®å¼‚: {abs(visual_tokens - (valid_tokens - text_length))}")
        print()
    
    # 7. åˆ†æattention_maskæ¨¡å¼
    print(f"\nğŸ¯ Attention Maskæ¨¡å¼åˆ†æ:")
    print("-" * 60)
    
    for i in range(batch_size):
        print(f"ğŸ“‹ æ ·æœ¬{i+1}çš„Attention Maskæ¨¡å¼:")
        
        mask_values = attention_mask[i].tolist()
        
        # æ‰¾åˆ°ç¬¬ä¸€ä¸ªå’Œæœ€åä¸€ä¸ªæœ‰æ•ˆä½ç½®
        valid_indices = attention_mask[i].nonzero().flatten()
        first_valid = valid_indices[0].item()
        last_valid = valid_indices[-1].item()
        
        print(f"  ğŸ¯ ç¬¬ä¸€ä¸ªæœ‰æ•ˆä½ç½®: {first_valid}")
        print(f"  ğŸ¯ æœ€åä¸€ä¸ªæœ‰æ•ˆä½ç½®: {last_valid}")
        print(f"  ğŸ¯ æœ‰æ•ˆèŒƒå›´: [{first_valid}, {last_valid}]")
        
        # æ˜¾ç¤ºå…³é”®ä½ç½®çš„attentionå€¼
        print(f"  ğŸ” å‰10ä¸ªä½ç½®: {mask_values[:10]}")
        print(f"  ğŸ” å10ä¸ªä½ç½®: {mask_values[-10:]}")
        
        # æ˜¾ç¤ºæ–‡æœ¬å¼€å§‹ä½ç½®ï¼ˆä¼°ç®—ï¼‰
        sample_valid_tokens = attention_mask[i].sum().item()
        if sample_valid_tokens > text_length:
            text_start_in_full_seq = sample_valid_tokens - text_length
            print(f"  ğŸ” ä¼°ç®—æ–‡æœ¬å¼€å§‹ä½ç½®: {text_start_in_full_seq}")
        
        print()
    
    # 8. æµ‹è¯•poolingä½ç½®è®¡ç®—
    print(f"\nğŸ¯ Poolingä½ç½®è®¡ç®—:")
    print("-" * 60)
    
    # è·å–pad_token_id
    if hasattr(processor, 'tokenizer') and hasattr(processor.tokenizer, 'pad_token_id'):
        pad_token_id = processor.tokenizer.pad_token_id
    else:
        pad_token_id = 0  # å‡è®¾å€¼
    
    # æ—§æ–¹æ³•ï¼ˆé”™è¯¯çš„ï¼‰
    old_mask = input_ids.ne(pad_token_id)
    old_last_positions = old_mask.sum(dim=1) - 1
    
    # æ–°æ–¹æ³•ï¼ˆæ­£ç¡®çš„ï¼‰
    valid_lengths = attention_mask.sum(dim=1)
    new_last_positions = valid_lengths - 1
    new_last_positions = torch.clamp(new_last_positions, min=0, max=attention_mask.size(1)-1)
    
    # åˆ†ææ¯ä¸ªæ ·æœ¬çš„poolingä½ç½®
    for i in range(batch_size):
        print(f"ğŸ“‹ æ ·æœ¬{i+1}çš„Poolingä½ç½®:")
        
        old_pos = old_last_positions[i].item()
        new_pos = new_last_positions[i].item()
        
        print(f"  âŒ æ—§æ–¹æ³• (åŸºäºinput_ids):")
        print(f"    â€¢ Poolingä½ç½®: {old_pos}")
        print(f"    â€¢ è¯¥ä½ç½®çš„attentionå€¼: {attention_mask[i, old_pos].item()}")
        
        print(f"  âœ… æ–°æ–¹æ³• (åŸºäºattention_mask):")
        print(f"    â€¢ Poolingä½ç½®: {new_pos}")
        print(f"    â€¢ è¯¥ä½ç½®çš„attentionå€¼: {attention_mask[i, new_pos].item()}")
        
        print(f"  ğŸ“Š å·®å¼‚åˆ†æ:")
        print(f"    â€¢ ä½ç½®å·®å¼‚: {new_pos - old_pos} tokens")
        print(f"    â€¢ æ—§æ–¹æ³•è·³è¿‡çš„tokens: {new_pos - old_pos}")
        print()
    
    # 9. éªŒè¯poolingä½ç½®çš„æ­£ç¡®æ€§
    print(f"\nğŸ” Poolingä½ç½®éªŒè¯:")
    print("-" * 60)
    
    print(f"ğŸ“ æ–°æ–¹æ³•poolingä½ç½®({new_pos})å‘¨å›´çš„attentionå€¼:")
    for offset in [-2, -1, 0, 1, 2]:
        pos = new_pos + offset
        if 0 <= pos < attention_mask.size(1):
            print(f"  â€¢ ä½ç½® {pos}: attention = {attention_mask[0, pos].item()}")
        else:
            print(f"  â€¢ ä½ç½® {pos}: è¶Šç•Œ")
    
    # æ£€æŸ¥æ˜¯å¦çœŸçš„æ˜¯æœ€åæœ‰æ•ˆä½ç½®
    is_last_valid = (new_pos == last_valid)
    print(f"âœ… æ˜¯å¦ä¸ºæœ€åæœ‰æ•ˆä½ç½®: {is_last_valid}")
    
    # 10. å¦‚æœå¯èƒ½ï¼Œæµ‹è¯•æ¨¡å‹å‰å‘ä¼ æ’­
    print(f"\nğŸš€ å°è¯•æ¨¡å‹å‰å‘ä¼ æ’­æµ‹è¯•:")
    print("-" * 60)
    
    try:
        print("âš ï¸  æ³¨æ„: åŠ è½½7Bæ¨¡å‹éœ€è¦å¤§é‡å†…å­˜ï¼Œå¦‚æœå†…å­˜ä¸è¶³ä¼šå¤±è´¥")
        
        # å¯ä»¥é€‰æ‹©åªåŠ è½½æ¨¡å‹çš„ä¸€éƒ¨åˆ†æ¥æµ‹è¯•
        # è¿™é‡Œæˆ‘ä»¬åªæµ‹è¯•æ•°æ®æµï¼Œä¸åŠ è½½å®Œæ•´æ¨¡å‹
        print("ğŸ”„ è·³è¿‡æ¨¡å‹åŠ è½½ï¼Œä»…éªŒè¯æ•°æ®æµ...")
        
        # æ¨¡æ‹Ÿæ¨¡å‹è¾“å‡ºçš„hidden_stateså½¢çŠ¶
        batch_size, seq_len, hidden_dim = 1, attention_length, 768
        mock_hidden_states = torch.randn(batch_size, seq_len, hidden_dim)
        
        # ä½¿ç”¨æ–°çš„poolingæ–¹æ³•æå–ç‰¹å¾
        pooled = mock_hidden_states[torch.arange(batch_size), new_last_positions]
        print(f"âœ… æ¨¡æ‹Ÿpooledç‰¹å¾å½¢çŠ¶: {pooled.shape}")
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
    
    # 11. æ€»ç»“
    print(f"\nğŸ“‹ æµ‹è¯•æ€»ç»“:")
    print("="*80)
    print(f"âœ… ä½¿ç”¨çœŸå®æ•°æ®: {local_path}")
    print(f"âœ… å›¾ç‰‡å°ºå¯¸: {image.size}")
    print(f"âœ… æ–‡æœ¬é•¿åº¦: {len(text_list[0])} å­—ç¬¦")
    print(f"âœ… æ–‡æœ¬tokens: {text_length}")
    print(f"âœ… æ€»åºåˆ—é•¿åº¦: {attention_length}")
    print(f"âœ… æœ‰æ•ˆtokens: {valid_tokens}")
    print(f"âœ… Visual tokens: {valid_tokens - text_length}")
    if visual_tokens is not None:
        print(f"âœ… image_grid_thwè®¡ç®—çš„visual tokens: {visual_tokens}")
    print(f"âœ… ä¿®å¤å‰poolingä½ç½®: {old_pos}")
    print(f"âœ… ä¿®å¤åpoolingä½ç½®: {new_pos}")
    print(f"âœ… ä¿®å¤æ•ˆæœ: æ­£ç¡®å¤„ç†äº† {new_pos - old_pos} ä¸ªvisual tokens")
    print(f"âœ… ç°åœ¨ä½¿ç”¨æ­£ç¡®çš„åºåˆ—æœ«å°¾ä½ç½®è¿›è¡Œpooling")
    print("="*80)

if __name__ == "__main__":
    test_real_multimodal_data() 