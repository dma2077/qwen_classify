#!/usr/bin/env python3
"""
æµ‹è¯•MFUç¦ç”¨åçš„æ€§èƒ½æ”¹è¿›
"""

import os
import sys
import time
import yaml
import torch

# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ['NCCL_NTHREADS'] = '64'

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.dirname(os.path.abspath(__file__))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

def test_trainer_initialization():
    """æµ‹è¯•è®­ç»ƒå™¨åˆå§‹åŒ–æ—¶é—´"""
    print("ğŸš€ æµ‹è¯•è®­ç»ƒå™¨åˆå§‹åŒ–ï¼ˆMFUç¦ç”¨ï¼‰...")
    
    # åŠ è½½é…ç½®
    config_file = "configs/fast_eval_config.yaml"
    with open(config_file, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    # å‡†å¤‡é…ç½®
    from training.utils.config_utils import prepare_config
    config = prepare_config(config)
    
    # æµ‹è¯•è®­ç»ƒå™¨åˆå§‹åŒ–æ—¶é—´
    start_time = time.time()
    
    try:
        from training.deepspeed_trainer import DeepSpeedTrainer
        trainer = DeepSpeedTrainer(config)
        
        init_time = time.time() - start_time
        print(f"âœ… è®­ç»ƒå™¨åˆå§‹åŒ–å®Œæˆ: {init_time:.2f}s")
        
        # æ£€æŸ¥MFUç»Ÿè®¡å™¨æ˜¯å¦è¢«ç¦ç”¨
        if hasattr(trainer, 'mfu_stats') and trainer.mfu_stats is None:
            print("âœ… MFUç»Ÿè®¡å™¨å·²æˆåŠŸç¦ç”¨")
            return True
        else:
            print("âš ï¸ MFUç»Ÿè®¡å™¨ä»ç„¶å­˜åœ¨")
            return False
            
    except Exception as e:
        print(f"âŒ è®­ç»ƒå™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_batch_processing_speed():
    """æµ‹è¯•æ‰¹æ¬¡å¤„ç†é€Ÿåº¦"""
    print("\nğŸ”¥ æµ‹è¯•æ‰¹æ¬¡å¤„ç†é€Ÿåº¦ï¼ˆMFUç¦ç”¨ï¼‰...")
    
    # åŠ è½½é…ç½®
    config_file = "configs/fast_eval_config.yaml"
    with open(config_file, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    # å‡†å¤‡é…ç½®
    from training.utils.config_utils import prepare_config
    config = prepare_config(config)
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    from data.dataloader import create_dataloaders
    train_loader, val_loader = create_dataloaders(config)
    
    # åˆ›å»ºæ¨¡å‹
    from models.qwen2_5_vl_classify import Qwen25VLClassify
    model = Qwen25VLClassify(config['model'])
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = model.to(device)
    model.train()
    
    # æµ‹è¯•æ‰¹æ¬¡å¤„ç†æ—¶é—´
    print("æµ‹è¯•çº¯å‰å‘ä¼ æ’­æ—¶é—´...")
    
    batch_times = []
    for i, batch in enumerate(train_loader):
        if i >= 3:  # åªæµ‹è¯•å‰3ä¸ªbatch
            break
        
        batch_start = time.time()
        
        # æ•°æ®å‡†å¤‡
        inputs = batch["input_ids"].to(device, non_blocking=True)
        attention_mask = batch["attention_mask"].to(device, non_blocking=True)
        pixel_values = batch["pixel_values"].to(device, non_blocking=True)
        labels = batch["labels"].to(device, non_blocking=True)
        
        forward_kwargs = {
            "input_ids": inputs,
            "attention_mask": attention_mask,
            "pixel_values": pixel_values,
            "labels": labels
        }
        
        if "image_grid_thw" in batch:
            forward_kwargs["image_grid_thw"] = batch["image_grid_thw"].to(device, non_blocking=True)
        
        # å‰å‘ä¼ æ’­
        with torch.no_grad():
            outputs = model(**forward_kwargs)
            loss = outputs.loss
        
        batch_time = time.time() - batch_start
        batch_times.append(batch_time)
        
        print(f"  Batch {i+1}: {batch_time:.3f}s (loss: {loss.item():.4f})")
    
    avg_batch_time = sum(batch_times) / len(batch_times)
    print(f"ğŸ“Š å¹³å‡batchå¤„ç†æ—¶é—´: {avg_batch_time:.3f}s")
    
    # è¯„ä¼°æ€§èƒ½æ”¹è¿›
    if avg_batch_time < 5.0:
        print("âœ… æ‰¹æ¬¡å¤„ç†é€Ÿåº¦ä¼˜ç§€")
        return True
    elif avg_batch_time < 10.0:
        print("ğŸ”¶ æ‰¹æ¬¡å¤„ç†é€Ÿåº¦è‰¯å¥½")
        return True
    else:
        print("âš ï¸ æ‰¹æ¬¡å¤„ç†é€Ÿåº¦ä»éœ€ä¼˜åŒ–")
        return False

def test_training_loop_overhead():
    """æµ‹è¯•è®­ç»ƒå¾ªç¯å¼€é”€"""
    print("\nğŸ”¥ æµ‹è¯•è®­ç»ƒå¾ªç¯å¼€é”€...")
    
    # æ¨¡æ‹Ÿè®­ç»ƒæ­¥éª¤å¼€é”€ï¼ˆä¸åŒ…å«å®é™…æ¨¡å‹è®¡ç®—ï¼‰
    print("æµ‹è¯•è®­ç»ƒè¾…åŠ©å‡½æ•°å¼€é”€...")
    
    # æ¨¡æ‹Ÿä¸€äº›è®­ç»ƒä¸­çš„æ“ä½œ
    step_times = []
    
    for i in range(10):
        step_start = time.time()
        
        # æ¨¡æ‹Ÿä¸€äº›è½»é‡çº§æ“ä½œ
        dummy_tensor = torch.randn(8, 512).cuda() if torch.cuda.is_available() else torch.randn(8, 512)
        _ = dummy_tensor.sum()
        
        # æ¨¡æ‹Ÿæ¢¯åº¦èŒƒæ•°è®¡ç®—
        grad_norm = torch.tensor(1.0).cuda() if torch.cuda.is_available() else torch.tensor(1.0)
        grad_norm_value = grad_norm if grad_norm is not None else 0.0
        
        # æ¨¡æ‹Ÿå­¦ä¹ ç‡è·å–
        current_lr = 1e-5
        
        step_time = time.time() - step_start
        step_times.append(step_time)
        
        if i < 3:
            print(f"  Step {i+1} overhead: {step_time:.6f}s")
    
    avg_overhead = sum(step_times) / len(step_times)
    print(f"ğŸ“Š å¹³å‡æ­¥éª¤å¼€é”€: {avg_overhead:.6f}s")
    
    if avg_overhead < 0.01:  # å°äº10ms
        print("âœ… è®­ç»ƒå¼€é”€å¾ˆä½")
        return True
    else:
        print("âš ï¸ è®­ç»ƒå¼€é”€è¾ƒé«˜")
        return False

if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹MFUç¦ç”¨æ€§èƒ½æµ‹è¯•")
    print("=" * 60)
    
    # æµ‹è¯•1: è®­ç»ƒå™¨åˆå§‹åŒ–
    init_ok = test_trainer_initialization()
    
    # æµ‹è¯•2: æ‰¹æ¬¡å¤„ç†é€Ÿåº¦
    batch_ok = test_batch_processing_speed()
    
    # æµ‹è¯•3: è®­ç»ƒå¾ªç¯å¼€é”€
    overhead_ok = test_training_loop_overhead()
    
    print("\n" + "=" * 60)
    print("ğŸ“Š MFUç¦ç”¨æµ‹è¯•ç»“æœæ€»ç»“:")
    print(f"  â€¢ è®­ç»ƒå™¨åˆå§‹åŒ–: {'âœ… æ­£å¸¸' if init_ok else 'âŒ å¼‚å¸¸'}")
    print(f"  â€¢ æ‰¹æ¬¡å¤„ç†é€Ÿåº¦: {'âœ… è‰¯å¥½' if batch_ok else 'âš ï¸ éœ€è¦ä¼˜åŒ–'}")
    print(f"  â€¢ è®­ç»ƒå¾ªç¯å¼€é”€: {'âœ… å¾ˆä½' if overhead_ok else 'âš ï¸ è¾ƒé«˜'}")
    
    if init_ok and batch_ok and overhead_ok:
        print("ğŸ‰ MFUç¦ç”¨æˆåŠŸï¼Œæ€§èƒ½åº”è¯¥æœ‰æ˜¾è‘—æå‡ï¼")
        sys.exit(0)
    else:
        print("âš ï¸ æŸäº›æ–¹é¢ä»éœ€è¦ä¼˜åŒ–")
        sys.exit(1) 