# å®Œæ•´çš„Qwen2.5-VLå›¾åƒåˆ†ç±»è®­ç»ƒé…ç½®
# åŒ…å«FlashAttentionã€DeepSpeedã€WandBç›‘æ§ã€æ€§èƒ½ä¼˜åŒ–

# æ¨¡å‹é…ç½®
model:
  pretrained_name: "Qwen/Qwen2.5-VL-7B-Instruct"
  num_labels: 101  # Food101æ•°æ®é›†

# è®­ç»ƒé…ç½®
training:
  num_epochs: 10
  output_dir: "./outputs/complete_training"
  
  # ğŸ”¥ æ€§èƒ½ä¼˜åŒ–é…ç½®
  gradient_checkpointing: false         # ä¸å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ï¼Œä¼˜å…ˆè®¡ç®—é€Ÿåº¦
  memory_efficient_attention: true      # å¯ç”¨FlashAttention
  amp: false                           # ä¸å¯ç”¨AMPï¼ŒDeepSpeedå·²å¯ç”¨bf16
  dataloader_pin_memory: true          # å¯ç”¨pin_memory
  dataloader_num_workers: 16           # æ•°æ®åŠ è½½å™¨workeræ•°é‡ï¼ˆæ ¹æ®CPUæ ¸å¿ƒæ•°è°ƒæ•´ï¼‰
  dataloader_prefetch_factor: 2        # é¢„å–å› å­
  
  # å­¦ä¹ ç‡é…ç½®
  learning_rate: 1e-5
  weight_decay: 0.01
  warmup_steps: 100
  max_grad_norm: 1.0
  
  # æ‰¹æ¬¡é…ç½®
  batch_size: 8
  gradient_accumulation_steps: 4
  
  # æ—¥å¿—å’Œä¿å­˜é…ç½®
  logging_steps: 10
  eval_steps: 50
  save_steps: 200
  
  # æœ€ä½³æ¨¡å‹è¿½è¸ª
  best_model_tracking:
    enabled: true
    metric: "overall_accuracy"
    mode: "max"
    save_best_only: true
  
  # è¯„ä¼°é…ç½®
  evaluation:
    partial_eval_during_training: true
    full_eval_at_end: true
    eval_best_model_only: true

# æ•°æ®é…ç½®
data:
  train_jsonl: "data/food101/train.jsonl"
  val_jsonl: "data/food101/val.jsonl"
  max_length: 512
  image_size: 224

# æŸå¤±å‡½æ•°é…ç½®
loss:
  type: "cross_entropy"
  # å¯é€‰ï¼šlabel_smoothing
  # type: "label_smoothing"
  # smoothing: 0.1
  # temperature: 1.0

# å¤šæ•°æ®é›†é…ç½®ï¼ˆå¦‚æœä½¿ç”¨ï¼‰
datasets:
  dataset_configs:
    food101:
      num_classes: 101
      eval_ratio: 0.2
      description: "Food101 dataset"
  enable_logits_masking: true
  shuffle_datasets: true

# WandBé…ç½®
wandb:
  enabled: true
  project: "qwen-classification-complete"
  run_name: "complete_training_run"
  tags: ["complete", "flash_attention", "optimized"]
  notes: "Complete training with FlashAttention and all optimizations"
  log_dataset_metrics: true

# ç›‘æ§é…ç½®
monitor:
  use_wandb: true
  all_freq:
    training_log_freq: 10
    eval_log_freq: 50
    perf_log_freq: 10      # æ€§èƒ½æŒ‡æ ‡è®°å½•é¢‘ç‡
    gpu_log_freq: 20       # GPUç›‘æ§é¢‘ç‡
  flops_profile_freq: 50   # FLOPsåˆ†æé¢‘ç‡
  local_save_freq: 100     # æœ¬åœ°æ—¥å¿—ä¿å­˜é¢‘ç‡

# DeepSpeedé…ç½®
deepspeed: "configs/ds_config_zero2.json"

# ä¼˜åŒ–å™¨é…ç½®
optimizer:
  type: "AdamW"
  weight_decay: 0.01
  betas: [0.9, 0.999]
  eps: 1e-8

# å­¦ä¹ ç‡è°ƒåº¦å™¨é…ç½®
lr_scheduler:
  type: "cosine"
  warmup_steps: 100
  num_training_steps: 1000  # å°†åœ¨è¿è¡Œæ—¶è‡ªåŠ¨è®¡ç®— 