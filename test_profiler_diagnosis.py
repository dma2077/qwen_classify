#!/usr/bin/env python3
"""
PyTorch Profilerè¯Šæ–­è„šæœ¬
ä¸“é—¨è¯Šæ–­'NoneType' object is not iterableé”™è¯¯
"""

import torch
import sys
import os
import traceback

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def test_profiler_diagnosis():
    """è¯Šæ–­profileré—®é¢˜"""
    
    print("ğŸ” PyTorch Profilerè¯Šæ–­...")
    print("=" * 50)
    
    # æ£€æŸ¥PyTorchç‰ˆæœ¬
    print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
    print(f"CUDAå¯ç”¨: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"CUDAç‰ˆæœ¬: {torch.version.cuda}")
        print(f"GPUæ•°é‡: {torch.cuda.device_count()}")
        print(f"å½“å‰GPU: {torch.cuda.get_device_name(0)}")
    
    # æ£€æŸ¥CUDAæ˜¯å¦å¯ç”¨
    if not torch.cuda.is_available():
        print("âŒ CUDAä¸å¯ç”¨ï¼Œè·³è¿‡æµ‹è¯•")
        return
    
    device = torch.device('cuda:0')
    
    # åˆ›å»ºä¸€ä¸ªç®€å•çš„æµ‹è¯•æ¨¡å‹
    class SimpleModel(torch.nn.Module):
        def __init__(self):
            super().__init__()
            self.linear1 = torch.nn.Linear(512, 256)
            self.linear2 = torch.nn.Linear(256, 101)
            self.relu = torch.nn.ReLU()
            
        def forward(self, input_ids, attention_mask, pixel_values, labels):
            batch_size = input_ids.size(0)
            seq_len = input_ids.size(1)
            
            # ç®€å•çš„æ–‡æœ¬å¤„ç†
            text_features = torch.randn(batch_size, seq_len, 512, device=input_ids.device)
            text_output = self.linear1(text_features)
            text_output = self.relu(text_output)
            
            # ç®€å•çš„å›¾åƒå¤„ç†
            image_features = torch.randn(batch_size, 256, device=pixel_values.device)
            image_output = image_features.unsqueeze(1).expand(-1, seq_len, -1)
            
            # èåˆç‰¹å¾
            combined = text_output + image_output
            logits = self.linear2(combined)
            
            # ç®€åŒ–çš„æŸå¤±è®¡ç®—
            first_token_logits = logits[:, 0, :]
            loss = torch.nn.functional.cross_entropy(first_token_logits, labels)
            
            class Outputs:
                def __init__(self, loss, logits):
                    self.loss = loss
                    self.logits = logits
            
            return Outputs(loss, logits)
    
    # åˆ›å»ºæ¨¡å‹
    model = SimpleModel().to(device)
    print(f"âœ… åˆ›å»ºæµ‹è¯•æ¨¡å‹: {sum(p.numel() for p in model.parameters()):,} å‚æ•°")
    
    # åˆ›å»ºæµ‹è¯•batch
    batch_size = 8
    seq_length = 512
    
    test_batch = {
        'input_ids': torch.randint(0, 1000, (batch_size, seq_length), device=device),
        'attention_mask': torch.ones(batch_size, seq_length, device=device),
        'pixel_values': torch.randn(batch_size, 3, 224, 224, device=device),
        'labels': torch.randint(0, 101, (batch_size,), device=device)
    }
    
    print(f"âœ… åˆ›å»ºæµ‹è¯•batch: batch_size={batch_size}, seq_length={seq_length}")
    
    # æµ‹è¯•1: åŸºç¡€profileråŠŸèƒ½
    print("\nğŸ“Š æµ‹è¯•1: åŸºç¡€profileråŠŸèƒ½")
    try:
        with torch.profiler.profile(
            activities=[torch.profiler.ProfilerActivity.CUDA],
            record_shapes=True,
            profile_memory=False
        ) as prof:
            with torch.no_grad():
                _ = model(**test_batch)
        
        print("âœ… Profilerä¸Šä¸‹æ–‡ç®¡ç†å™¨æ­£å¸¸å·¥ä½œ")
        
        # è¯¦ç»†æ£€æŸ¥events
        print("ğŸ” æ£€æŸ¥prof.events()...")
        try:
            events = prof.events()
            print(f"  eventsç±»å‹: {type(events)}")
            print(f"  eventsæ˜¯å¦ä¸ºNone: {events is None}")
            
            if events is not None:
                try:
                    events_length = len(events)
                    print(f"  eventsé•¿åº¦: {events_length}")
                    
                    if events_length > 0:
                        print("  âœ… eventsä¸ä¸ºç©ºï¼Œå°è¯•è¿­ä»£...")
                        
                        # å°è¯•è½¬æ¢ä¸ºlist
                        try:
                            events_list = list(events)
                            print(f"  âœ… æˆåŠŸè½¬æ¢ä¸ºlistï¼Œé•¿åº¦: {len(events_list)}")
                            
                            # å°è¯•è¿­ä»£
                            event_count = 0
                            for event in events_list:
                                event_count += 1
                                if event_count <= 3:  # åªæ£€æŸ¥å‰3ä¸ªäº‹ä»¶
                                    print(f"    Event {event_count}: {type(event)}")
                                    if hasattr(event, 'name'):
                                        print(f"      name: {event.name}")
                                    if hasattr(event, 'flops'):
                                        print(f"      flops: {event.flops}")
                                if event_count >= 10:  # åªæ£€æŸ¥å‰10ä¸ªäº‹ä»¶
                                    break
                            
                            print(f"  âœ… æˆåŠŸè¿­ä»£ {event_count} ä¸ªäº‹ä»¶")
                            
                        except Exception as list_error:
                            print(f"  âŒ è½¬æ¢ä¸ºlistå¤±è´¥: {list_error}")
                            traceback.print_exc()
                    else:
                        print("  âš ï¸  eventsä¸ºç©º")
                except Exception as len_error:
                    print(f"  âŒ è·å–eventsé•¿åº¦å¤±è´¥: {len_error}")
                    traceback.print_exc()
            else:
                print("  âŒ eventsä¸ºNone")
                
        except Exception as events_error:
            print(f"  âŒ è·å–prof.events()å¤±è´¥: {events_error}")
            traceback.print_exc()
            
    except Exception as e:
        print(f"âŒ åŸºç¡€profileræµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
    
    # æµ‹è¯•2: æµ‹è¯•æˆ‘ä»¬çš„ä¿®å¤å‡½æ•°
    print("\nğŸ“Š æµ‹è¯•2: æµ‹è¯•ä¿®å¤åçš„å‡½æ•°")
    try:
        from training.utils.monitor import _profile_forward_flops
        forward_flops = _profile_forward_flops(model, test_batch)
        print(f"âœ… å‰å‘ä¼ æ’­FLOPsæµ‹é‡: {forward_flops:.2e}")
    except Exception as e:
        print(f"âŒ å‰å‘ä¼ æ’­FLOPsæµ‹é‡å¤±è´¥: {e}")
        traceback.print_exc()
    
    # æµ‹è¯•3: æµ‹è¯•åå‘ä¼ æ’­
    print("\nğŸ“Š æµ‹è¯•3: æµ‹è¯•åå‘ä¼ æ’­")
    try:
        from training.utils.monitor import _profile_backward_flops
        backward_flops = _profile_backward_flops(model, test_batch)
        print(f"âœ… åå‘ä¼ æ’­FLOPsæµ‹é‡: {backward_flops:.2e}")
    except Exception as e:
        print(f"âŒ åå‘ä¼ æ’­FLOPsæµ‹é‡å¤±è´¥: {e}")
        traceback.print_exc()
    
    # æµ‹è¯•4: æµ‹è¯•å®Œæ•´FLOPsæµ‹é‡
    print("\nğŸ“Š æµ‹è¯•4: æµ‹è¯•å®Œæ•´FLOPsæµ‹é‡")
    try:
        from training.utils.monitor import profile_model_flops
        total_flops = profile_model_flops(model, test_batch)
        print(f"âœ… å®Œæ•´FLOPsæµ‹é‡: {total_flops:.2e}")
    except Exception as e:
        print(f"âŒ å®Œæ•´FLOPsæµ‹é‡å¤±è´¥: {e}")
        traceback.print_exc()
    
    # æµ‹è¯•5: æµ‹è¯•ä¼°ç®—æ–¹æ³•
    print("\nğŸ“Š æµ‹è¯•5: æµ‹è¯•ä¼°ç®—æ–¹æ³•")
    try:
        from training.utils.monitor import _estimate_flops_fallback
        estimated_flops = _estimate_flops_fallback(model, test_batch, seq_length)
        print(f"âœ… ä¼°ç®—æ–¹æ³•: {estimated_flops:.2e}")
    except Exception as e:
        print(f"âŒ ä¼°ç®—æ–¹æ³•å¤±è´¥: {e}")
        traceback.print_exc()
    
    print("\nâœ… Profilerè¯Šæ–­å®Œæˆ")
    print("\nğŸ“‹ è¯Šæ–­æ€»ç»“:")
    print("  1. æ£€æŸ¥äº†prof.events()çš„ç±»å‹å’Œå†…å®¹")
    print("  2. æµ‹è¯•äº†eventsçš„è¿­ä»£å’Œè½¬æ¢")
    print("  3. éªŒè¯äº†ä¿®å¤åçš„FLOPsæµ‹é‡å‡½æ•°")
    print("  4. æµ‹è¯•äº†å¤‡é€‰çš„ä¼°ç®—æ–¹æ³•")

if __name__ == "__main__":
    test_profiler_diagnosis() 