#!/usr/bin/env python3
"""
è¯Šæ–­è„šæœ¬ï¼šæ£€æŸ¥å¤šæ•°æ®é›†è®­ç»ƒä¸­Lossä¸ºinfçš„é—®é¢˜
"""

import os
import sys
import torch
import numpy as np
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

def diagnose_dataset_labels(config_path):
    """è¯Šæ–­æ•°æ®é›†æ ‡ç­¾æ˜¯å¦æ­£ç¡®"""
    
    print("ğŸ” å¼€å§‹è¯Šæ–­æ•°æ®é›†æ ‡ç­¾æ˜ å°„...")
    print("=" * 80)
    
    import yaml
    with open(config_path, 'r') as f:
        config = yaml.safe_load(f)
    
    dataset_configs = config.get('datasets', {}).get('dataset_configs', {})
    if not dataset_configs:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°å¤šæ•°æ®é›†é…ç½®")
        return False
    
    print("ğŸ“‹ æ•°æ®é›†é…ç½®:")
    for dataset_name, dataset_config in dataset_configs.items():
        num_classes = dataset_config.get('num_classes', 'N/A')
        print(f"  â€¢ {dataset_name}: {num_classes} classes")
    
    # æ£€æŸ¥æ•°æ®æ–‡ä»¶
    data_config = config.get('data', {})
    
    if 'val_jsonl_list' in data_config:
        jsonl_files = data_config['val_jsonl_list']
    elif 'val_jsonl' in data_config:
        jsonl_files = [data_config['val_jsonl']]
    else:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°éªŒè¯æ•°æ®æ–‡ä»¶é…ç½®")
        return False
    
    print("\nğŸ” æ£€æŸ¥æ•°æ®æ–‡ä»¶ä¸­çš„æ ‡ç­¾èŒƒå›´...")
    
    import json
    dataset_label_stats = {}
    
    for jsonl_file in jsonl_files:
        if not os.path.exists(jsonl_file):
            print(f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: {jsonl_file}")
            continue
            
        print(f"\nğŸ“‚ åˆ†ææ–‡ä»¶: {jsonl_file}")
        
        with open(jsonl_file, 'r') as f:
            line_count = 0
            for line in f:
                try:
                    line_count += 1
                    item = json.loads(line.strip())
                    
                    label = int(item.get('label', -1))
                    dataset_name = item.get('dataset_name', 'unknown')
                    
                    if dataset_name not in dataset_label_stats:
                        dataset_label_stats[dataset_name] = {
                            'min_label': float('inf'),
                            'max_label': -1,
                            'labels': set(),
                            'count': 0
                        }
                    
                    stats = dataset_label_stats[dataset_name]
                    stats['min_label'] = min(stats['min_label'], label)
                    stats['max_label'] = max(stats['max_label'], label)
                    stats['labels'].add(label)
                    stats['count'] += 1
                    
                    if line_count <= 5:  # æ˜¾ç¤ºå‰5è¡Œç¤ºä¾‹
                        print(f"  ç¤ºä¾‹ {line_count}: dataset={dataset_name}, label={label}")
                        
                except Exception as e:
                    print(f"  âŒ è§£æç¬¬{line_count}è¡Œå‡ºé”™: {e}")
                    
                if line_count >= 1000:  # åªæ£€æŸ¥å‰1000è¡Œ
                    print(f"  â„¹ï¸ å·²æ£€æŸ¥å‰{line_count}è¡Œ...")
                    break
    
    print("\nğŸ“Š æ ‡ç­¾ç»Ÿè®¡ç»“æœ:")
    print("=" * 80)
    
    has_issues = False
    
    for dataset_name, stats in dataset_label_stats.items():
        expected_classes = dataset_configs.get(dataset_name, {}).get('num_classes')
        min_label = stats['min_label']
        max_label = stats['max_label']
        unique_labels = len(stats['labels'])
        
        print(f"\nğŸ” {dataset_name}:")
        print(f"  â€¢ é…ç½®çš„ç±»åˆ«æ•°: {expected_classes}")
        print(f"  â€¢ å®é™…æ ‡ç­¾èŒƒå›´: {min_label} - {max_label}")
        print(f"  â€¢ å”¯ä¸€æ ‡ç­¾æ•°é‡: {unique_labels}")
        print(f"  â€¢ æ ·æœ¬æ•°é‡: {stats['count']}")
        
        # æ£€æŸ¥é—®é¢˜
        issues = []
        
        if expected_classes is not None:
            if max_label >= expected_classes:
                issues.append(f"æœ€å¤§æ ‡ç­¾{max_label}è¶…å‡ºç±»åˆ«èŒƒå›´[0, {expected_classes-1}]")
                has_issues = True
                
            if min_label < 0:
                issues.append(f"å‘ç°è´Ÿæ ‡ç­¾{min_label}")
                has_issues = True
                
            if unique_labels != expected_classes:
                issues.append(f"å”¯ä¸€æ ‡ç­¾æ•°{unique_labels}ä¸é…ç½®çš„ç±»åˆ«æ•°{expected_classes}ä¸åŒ¹é…")
        
        if issues:
            print(f"  âŒ å‘ç°é—®é¢˜:")
            for issue in issues:
                print(f"    - {issue}")
        else:
            print(f"  âœ… æ ‡ç­¾æ˜ å°„æ­£å¸¸")
    
    return not has_issues

def diagnose_logits_masking(config_path):
    """è¯Šæ–­logits maskingé€»è¾‘"""
    
    print("\nğŸ” è¯Šæ–­logits maskingé€»è¾‘...")
    print("=" * 80)
    
    try:
        from models.qwen2_5_vl_classify import Qwen2_5_VLForImageClassification
        import yaml
        
        with open(config_path, 'r') as f:
            config = yaml.safe_load(f)
        
        dataset_configs = config.get('datasets', {}).get('dataset_configs', {})
        enable_logits_masking = config.get('datasets', {}).get('enable_logits_masking', True)
        
        print(f"ğŸ“‹ Logits maskingé…ç½®:")
        print(f"  â€¢ å¯ç”¨çŠ¶æ€: {enable_logits_masking}")
        print(f"  â€¢ æ•°æ®é›†æ•°é‡: {len(dataset_configs)}")
        
        # åˆ›å»ºæµ‹è¯•æ¨¡å‹ï¼ˆä¸åŠ è½½æƒé‡ï¼‰
        print("\nğŸ§ª åˆ›å»ºæµ‹è¯•ç”¨çš„æ¨¡å‹å®ä¾‹...")
        
        # åˆ›å»ºæœ€å°é…ç½®ç”¨äºæµ‹è¯•
        test_config = {
            'model': {
                'pretrained_name': config['model']['pretrained_name'],
                'num_labels': config['model']['num_labels']
            },
            'loss': {'type': 'cross_entropy'},
            'datasets': config.get('datasets', {})
        }
        
        # æ¨¡æ‹Ÿlogits maskingé€»è¾‘ï¼ˆä¸éœ€è¦å®é™…åŠ è½½æ¨¡å‹ï¼‰
        print("ğŸ§ª æ¨¡æ‹Ÿlogits maskingè¿‡ç¨‹...")
        
        num_labels = config['model']['num_labels']
        batch_size = 4
        
        # åˆ›å»ºæµ‹è¯•logits
        test_logits = torch.randn(batch_size, num_labels)
        print(f"  â€¢ åŸå§‹logitså½¢çŠ¶: {test_logits.shape}")
        print(f"  â€¢ åŸå§‹logitsèŒƒå›´: [{test_logits.min():.3f}, {test_logits.max():.3f}]")
        
        # æ¨¡æ‹Ÿä¸åŒæ•°æ®é›†çš„masking
        for dataset_name, dataset_config in dataset_configs.items():
            num_classes = dataset_config.get('num_classes')
            if num_classes is None:
                continue
                
            print(f"\n  ğŸ” æµ‹è¯• {dataset_name} (classes: {num_classes}):")
            
            # åº”ç”¨masking
            test_masked = test_logits.clone()
            if enable_logits_masking and num_classes < num_labels:
                test_masked[:, num_classes:] = float('-inf')
                
                # æ£€æŸ¥ç»“æœ
                valid_range = test_masked[:, :num_classes]
                masked_range = test_masked[:, num_classes:]
                
                print(f"    â€¢ æœ‰æ•ˆlogitsèŒƒå›´[0:{num_classes}]: [{valid_range.min():.3f}, {valid_range.max():.3f}]")
                print(f"    â€¢ è¢«maskçš„logits[{num_classes}:]: {masked_range[0][:5].tolist()}")
                
                # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰æœ‰æ•ˆlogitséƒ½æ˜¯-inf
                if torch.all(torch.isinf(valid_range)):
                    print(f"    âŒ è­¦å‘Š: æ‰€æœ‰æœ‰æ•ˆä½ç½®éƒ½æ˜¯-inf!")
                else:
                    print(f"    âœ… æœ‰æ•ˆä½ç½®åŒ…å«æ­£å¸¸å€¼")
                    
                # æµ‹è¯•softmaxç»“æœ
                try:
                    softmax_result = torch.softmax(test_masked, dim=-1)
                    if torch.any(torch.isnan(softmax_result)) or torch.any(torch.isinf(softmax_result)):
                        print(f"    âŒ Softmaxäº§ç”Ÿäº†NaNæˆ–Inf")
                    else:
                        print(f"    âœ… Softmaxç»“æœæ­£å¸¸")
                except Exception as e:
                    print(f"    âŒ Softmaxè®¡ç®—å¤±è´¥: {e}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Logits maskingè¯Šæ–­å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def diagnose_loss_computation():
    """è¯Šæ–­æŸå¤±è®¡ç®—ä¸­çš„æ•°å€¼é—®é¢˜"""
    
    print("\nğŸ” è¯Šæ–­æŸå¤±è®¡ç®—æ•°å€¼ç¨³å®šæ€§...")
    print("=" * 80)
    
    # æµ‹è¯•å„ç§æç«¯æƒ…å†µ
    test_cases = [
        ("æ­£å¸¸æƒ…å†µ", torch.randn(4, 101), torch.randint(0, 101, (4,))),
        ("logitsæœ‰-inf", torch.cat([torch.randn(4, 50), torch.full((4, 51), float('-inf'))], dim=1), torch.randint(0, 50, (4,))),
        ("logitså…¨ä¸º-inf", torch.full((4, 101), float('-inf')), torch.randint(0, 101, (4,))),
        ("logitså¾ˆå¤§å€¼", torch.randn(4, 101) * 100, torch.randint(0, 101, (4,))),
        ("æ ‡ç­¾è¶Šç•Œ", torch.randn(4, 101), torch.tensor([0, 50, 99, 150])),  # 150è¶…å‡ºèŒƒå›´
    ]
    
    for case_name, logits, labels in test_cases:
        print(f"\nğŸ§ª æµ‹è¯•: {case_name}")
        print(f"  â€¢ logitså½¢çŠ¶: {logits.shape}")
        print(f"  â€¢ logitsèŒƒå›´: [{logits.min():.3f}, {logits.max():.3f}]")
        print(f"  â€¢ labels: {labels.tolist()}")
        
        try:
            # æ ‡å‡†CrossEntropy
            loss = torch.nn.functional.cross_entropy(logits, labels, reduction='mean')
            print(f"  â€¢ CrossEntropy Loss: {loss.item():.6f}")
            
            if torch.isnan(loss) or torch.isinf(loss):
                print(f"    âŒ æŸå¤±ä¸ºNaNæˆ–Inf!")
            else:
                print(f"    âœ… æŸå¤±è®¡ç®—æ­£å¸¸")
                
        except Exception as e:
            print(f"    âŒ æŸå¤±è®¡ç®—å¤±è´¥: {e}")

def create_fixed_config(original_config_path, output_path):
    """åˆ›å»ºä¿®å¤åçš„é…ç½®æ–‡ä»¶"""
    
    print(f"\nğŸ”§ åˆ›å»ºä¿®å¤åçš„é…ç½®æ–‡ä»¶...")
    print("=" * 80)
    
    import yaml
    
    with open(original_config_path, 'r') as f:
        config = yaml.safe_load(f)
    
    # ä¿®å¤å»ºè®®
    fixes_applied = []
    
    # 1. é™ä½å­¦ä¹ ç‡
    if config.get('training', {}).get('lr', 1e-5) > 1e-6:
        config['training']['lr'] = 1e-6
        fixes_applied.append("é™ä½å­¦ä¹ ç‡åˆ°1e-6")
    
    # 2. æ·»åŠ æ¢¯åº¦è£å‰ª
    if 'max_grad_norm' not in config.get('training', {}):
        config['training']['max_grad_norm'] = 1.0
        fixes_applied.append("æ·»åŠ æ¢¯åº¦è£å‰ª (max_grad_norm=1.0)")
    
    # 3. æš‚æ—¶ç¦ç”¨logits masking
    if config.get('datasets', {}).get('enable_logits_masking', True):
        config['datasets']['enable_logits_masking'] = False
        fixes_applied.append("æš‚æ—¶ç¦ç”¨logits masking")
    
    # 4. ä½¿ç”¨æ›´ç¨³å®šçš„æŸå¤±å‡½æ•°
    if config.get('loss', {}).get('type') != 'cross_entropy':
        config['loss'] = {'type': 'cross_entropy'}
        fixes_applied.append("ä½¿ç”¨æ ‡å‡†CrossEntropyæŸå¤±")
    
    # 5. æ·»åŠ æ•°å€¼ç¨³å®šæ€§é…ç½®
    if 'numerical_stability' not in config:
        config['numerical_stability'] = {
            'check_inf_loss': True,
            'clip_logits': True,
            'logits_clip_value': 10.0
        }
        fixes_applied.append("æ·»åŠ æ•°å€¼ç¨³å®šæ€§æ£€æŸ¥")
    
    # ä¿å­˜ä¿®å¤åçš„é…ç½®
    with open(output_path, 'w') as f:
        yaml.dump(config, f, default_flow_style=False, allow_unicode=True)
    
    print(f"âœ… ä¿®å¤åçš„é…ç½®å·²ä¿å­˜åˆ°: {output_path}")
    print(f"ğŸ”§ åº”ç”¨çš„ä¿®å¤:")
    for fix in fixes_applied:
        print(f"  â€¢ {fix}")
    
    return output_path

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python scripts/diagnose_inf_loss.py <config_file.yaml>")
        sys.exit(1)
    
    config_path = sys.argv[1]
    
    if not os.path.exists(config_path):
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        sys.exit(1)
    
    print("ğŸš€ å¼€å§‹è¯Šæ–­å¤šæ•°æ®é›†è®­ç»ƒçš„Loss=infé—®é¢˜")
    print("è¿™ä¸ªè„šæœ¬å°†æ£€æŸ¥:")
    print("1. æ•°æ®é›†æ ‡ç­¾æ˜ å°„æ˜¯å¦æ­£ç¡®")
    print("2. Logits maskingé€»è¾‘æ˜¯å¦æœ‰é—®é¢˜") 
    print("3. æŸå¤±è®¡ç®—çš„æ•°å€¼ç¨³å®šæ€§")
    print("4. ç”Ÿæˆä¿®å¤åçš„é…ç½®æ–‡ä»¶")
    print("")
    
    # è¿è¡Œè¯Šæ–­
    label_ok = diagnose_dataset_labels(config_path)
    masking_ok = diagnose_logits_masking(config_path)
    diagnose_loss_computation()
    
    # åˆ›å»ºä¿®å¤é…ç½®
    fixed_config_path = config_path.replace('.yaml', '_fixed.yaml')
    create_fixed_config(config_path, fixed_config_path)
    
    print("\n" + "=" * 80)
    print("ğŸ“‹ è¯Šæ–­ç»“æœæ±‡æ€»:")
    print(f"  â€¢ æ ‡ç­¾æ˜ å°„æ£€æŸ¥: {'âœ… æ­£å¸¸' if label_ok else 'âŒ æœ‰é—®é¢˜'}")
    print(f"  â€¢ Logits maskingæ£€æŸ¥: {'âœ… æ­£å¸¸' if masking_ok else 'âŒ æœ‰é—®é¢˜'}")
    print(f"  â€¢ ä¿®å¤é…ç½®æ–‡ä»¶: {fixed_config_path}")
    
    if not label_ok or not masking_ok:
        print("\nâš ï¸ å‘ç°é—®é¢˜ï¼å»ºè®®:")
        print("1. ä½¿ç”¨ä¿®å¤åçš„é…ç½®æ–‡ä»¶é‡æ–°è®­ç»ƒ")
        print("2. æ£€æŸ¥æ•°æ®æ–‡ä»¶ä¸­çš„æ ‡ç­¾æ˜¯å¦æ­£ç¡®")
        print("3. è€ƒè™‘æš‚æ—¶ç¦ç”¨logits masking")
        print("4. é™ä½å­¦ä¹ ç‡å¹¶æ·»åŠ æ¢¯åº¦è£å‰ª")
    else:
        print("\nâœ… åŸºç¡€æ£€æŸ¥é€šè¿‡ï¼Œä½†ä»å»ºè®®ä½¿ç”¨ä¿®å¤åçš„é…ç½®ä»¥æé«˜ç¨³å®šæ€§") 