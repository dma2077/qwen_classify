#!/usr/bin/env python3
"""
æµ‹è¯•è„šæœ¬ï¼šéªŒè¯ eval_ratio åŠŸèƒ½æ˜¯å¦æ­£ç¡®å·¥ä½œ
"""

import os
import sys
import yaml
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from data.dataloader import create_dataloaders

def test_eval_ratio():
    """æµ‹è¯•eval_ratioåŠŸèƒ½"""
    
    print("ğŸ§ª å¼€å§‹æµ‹è¯• eval_ratio åŠŸèƒ½")
    print("=" * 60)
    
    # åˆ›å»ºæµ‹è¯•é…ç½®
    test_config = {
        'model': {
            'pretrained_name': "/llm_reco/dehua/model/Qwen2.5-VL-7B-Instruct",
            'num_labels': 101
        },
        'datasets': {
            'dataset_configs': {
                'food101': {
                    'num_classes': 101,
                    'description': "Food-101 dataset",
                    'eval_ratio': 0.01  # åªä½¿ç”¨1%çš„æ•°æ®è¿›è¡Œè¯„ä¼°
                }
            },
            'enable_logits_masking': False,
            'shuffle_datasets': False
        },
        'data': {
            'train_jsonl': "/llm_reco/dehua/code/qwen_classify/data/dataset_food_label/food101_train.jsonl",
            'val_jsonl': "/llm_reco/dehua/code/qwen_classify/data/dataset_food_label/food101_test.jsonl"
        },
        'training': {
            'num_workers': 0,  # è®¾ç½®ä¸º0é¿å…å¤šè¿›ç¨‹é—®é¢˜
            'evaluation': {
                'partial_eval_during_training': True,
                'full_eval_at_end': True,
                'eval_best_model_only': True
            }
        },
        'deepspeed': {
            'train_micro_batch_size_per_gpu': 1,
            'train_batch_size': 4
        }
    }
    
    print("ğŸ“‹ æµ‹è¯•é…ç½®:")
    print(f"  â€¢ eval_ratio: {test_config['datasets']['dataset_configs']['food101']['eval_ratio']}")
    print(f"  â€¢ partial_eval_during_training: {test_config['training']['evaluation']['partial_eval_during_training']}")
    print("")
    
    try:
        # æ£€æŸ¥æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        train_file = test_config['data']['train_jsonl']
        val_file = test_config['data']['val_jsonl']
        
        if not os.path.exists(train_file):
            print(f"âŒ è®­ç»ƒæ–‡ä»¶ä¸å­˜åœ¨: {train_file}")
            return False
            
        if not os.path.exists(val_file):
            print(f"âŒ éªŒè¯æ–‡ä»¶ä¸å­˜åœ¨: {val_file}")
            return False
        
        print("âœ… æ•°æ®æ–‡ä»¶æ£€æŸ¥é€šè¿‡")
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        print("ğŸ”„ åˆ›å»ºæ•°æ®åŠ è½½å™¨...")
        train_loader, val_loader = create_dataloaders(test_config)
        
        print(f"âœ… æ•°æ®åŠ è½½å™¨åˆ›å»ºæˆåŠŸ")
        print(f"ğŸ“Š è®­ç»ƒé›†å¤§å°: {len(train_loader.dataset):,} samples")
        print(f"ğŸ“Š éªŒè¯é›†å¤§å°: {len(val_loader.dataset):,} samples")
        
        # æ£€æŸ¥éªŒè¯é›†æ˜¯å¦è¢«æ­£ç¡®é‡‡æ ·
        # è¯»å–åŸå§‹éªŒè¯æ–‡ä»¶çš„è¡Œæ•°
        with open(val_file, 'r') as f:
            original_val_count = sum(1 for _ in f)
        
        expected_val_count = int(original_val_count * test_config['datasets']['dataset_configs']['food101']['eval_ratio'])
        actual_val_count = len(val_loader.dataset)
        
        print("")
        print("ğŸ” éªŒè¯ eval_ratio åŠŸèƒ½:")
        print(f"  â€¢ åŸå§‹éªŒè¯é›†æ ·æœ¬æ•°: {original_val_count:,}")
        print(f"  â€¢ eval_ratio: {test_config['datasets']['dataset_configs']['food101']['eval_ratio']}")
        print(f"  â€¢ æœŸæœ›é‡‡æ ·åæ ·æœ¬æ•°: {expected_val_count:,}")
        print(f"  â€¢ å®é™…é‡‡æ ·åæ ·æœ¬æ•°: {actual_val_count:,}")
        
        # å…è®¸ä¸€å®šçš„è¯¯å·®èŒƒå›´ï¼ˆå› ä¸ºéšæœºé‡‡æ ·ï¼‰
        error_margin = max(1, int(expected_val_count * 0.1))  # 10%çš„è¯¯å·®èŒƒå›´
        
        if abs(actual_val_count - expected_val_count) <= error_margin:
            print("âœ… eval_ratio åŠŸèƒ½å·¥ä½œæ­£å¸¸ï¼")
            reduction_ratio = (1 - actual_val_count / original_val_count) * 100
            print(f"ğŸ“ˆ è¯„ä¼°æ•°æ®å‡å°‘äº† {reduction_ratio:.1f}%ï¼Œè¿™å°†æ˜¾è‘—æå‡è®­ç»ƒé€Ÿåº¦")
            return True
        else:
            print("âŒ eval_ratio åŠŸèƒ½å¼‚å¸¸ï¼")
            print(f"   æœŸæœ›èŒƒå›´: {expected_val_count - error_margin} - {expected_val_count + error_margin}")
            print(f"   å®é™…å€¼: {actual_val_count}")
            return False
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_no_eval_ratio():
    """æµ‹è¯•ä¸ä½¿ç”¨eval_ratioçš„æƒ…å†µ"""
    
    print("\n" + "=" * 60)
    print("ğŸ§ª æµ‹è¯•å¯¹æ¯”ï¼šä¸ä½¿ç”¨ eval_ratio")
    print("=" * 60)
    
    # åˆ›å»ºå¯¹æ¯”é…ç½®ï¼ˆä¸ä½¿ç”¨eval_ratioï¼‰
    test_config = {
        'model': {
            'pretrained_name': "/llm_reco/dehua/model/Qwen2.5-VL-7B-Instruct",
            'num_labels': 101
        },
        'datasets': {
            'dataset_configs': {
                'food101': {
                    'num_classes': 101,
                    'description': "Food-101 dataset",
                    'eval_ratio': 1.0  # ä½¿ç”¨100%çš„æ•°æ®
                }
            },
            'enable_logits_masking': False,
            'shuffle_datasets': False
        },
        'data': {
            'train_jsonl': "/llm_reco/dehua/code/qwen_classify/data/dataset_food_label/food101_train.jsonl",
            'val_jsonl': "/llm_reco/dehua/code/qwen_classify/data/dataset_food_label/food101_test.jsonl"
        },
        'training': {
            'num_workers': 0,
            'evaluation': {
                'partial_eval_during_training': True,
                'full_eval_at_end': True,
                'eval_best_model_only': True
            }
        },
        'deepspeed': {
            'train_micro_batch_size_per_gpu': 1,
            'train_batch_size': 4
        }
    }
    
    try:
        train_loader, val_loader = create_dataloaders(test_config)
        
        # è¯»å–åŸå§‹éªŒè¯æ–‡ä»¶çš„è¡Œæ•°
        val_file = test_config['data']['val_jsonl']
        with open(val_file, 'r') as f:
            original_val_count = sum(1 for _ in f)
        
        actual_val_count = len(val_loader.dataset)
        
        print(f"ğŸ“Š ä¸ä½¿ç”¨ eval_ratio æ—¶:")
        print(f"  â€¢ åŸå§‹éªŒè¯é›†æ ·æœ¬æ•°: {original_val_count:,}")
        print(f"  â€¢ å®é™…ä½¿ç”¨æ ·æœ¬æ•°: {actual_val_count:,}")
        
        if actual_val_count == original_val_count:
            print("âœ… ä¸ä½¿ç”¨ eval_ratio æ—¶æ­£å¸¸ä½¿ç”¨å…¨éƒ¨æ•°æ®")
            return True
        else:
            print(f"âŒ æœŸæœ›ä½¿ç”¨å…¨éƒ¨æ•°æ®ï¼Œä½†å®é™…åªä½¿ç”¨äº† {actual_val_count}/{original_val_count}")
            return False
            
    except Exception as e:
        print(f"âŒ å¯¹æ¯”æµ‹è¯•å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹ eval_ratio åŠŸèƒ½æµ‹è¯•")
    print("è¿™ä¸ªæµ‹è¯•å°†éªŒè¯ä¿®å¤åçš„ eval_ratio åŠŸèƒ½æ˜¯å¦æ­£ç¡®å·¥ä½œ")
    print("")
    
    # è¿è¡Œæµ‹è¯•
    test1_pass = test_eval_ratio()
    test2_pass = test_no_eval_ratio()
    
    print("\n" + "=" * 60)
    print("ğŸ“‹ æµ‹è¯•ç»“æœæ±‡æ€»:")
    print(f"  â€¢ eval_ratio åŠŸèƒ½æµ‹è¯•: {'âœ… é€šè¿‡' if test1_pass else 'âŒ å¤±è´¥'}")
    print(f"  â€¢ å¯¹æ¯”æµ‹è¯•ï¼ˆæ—  eval_ratioï¼‰: {'âœ… é€šè¿‡' if test2_pass else 'âŒ å¤±è´¥'}")
    
    if test1_pass and test2_pass:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼eval_ratio åŠŸèƒ½å·²ä¿®å¤å¹¶æ­£å¸¸å·¥ä½œ")
        print("ğŸ’¡ ç°åœ¨æ‚¨å¯ä»¥åœ¨å•æ•°æ®é›†æ¨¡å¼ä¸‹ä½¿ç”¨ eval_ratio æ¥åŠ é€Ÿè®­ç»ƒè¿‡ç¨‹")
    else:
        print("\nâŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä»£ç ä¿®æ”¹")
        sys.exit(1) 