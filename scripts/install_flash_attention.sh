#!/bin/bash

# FlashAttentionå®‰è£…è„šæœ¬ - è§£å†³GLIBCç‰ˆæœ¬é—®é¢˜

echo "ğŸ”§ å®‰è£…FlashAttention..."

# æ–¹æ¡ˆ1: ä½¿ç”¨condaå®‰è£…ï¼ˆæ¨èï¼Œè§£å†³GLIBCé—®é¢˜ï¼‰
echo "ğŸ“¦ å°è¯•ä½¿ç”¨condaå®‰è£…flash-attn..."
conda install -c conda-forge flash-attn -y

# å¦‚æœcondaå®‰è£…å¤±è´¥ï¼Œå°è¯•å…¶ä»–æ–¹æ¡ˆ
if [ $? -ne 0 ]; then
    echo "âš ï¸ condaå®‰è£…å¤±è´¥ï¼Œå°è¯•pipå®‰è£…..."
    
    # æ–¹æ¡ˆ2: ä½¿ç”¨pipå®‰è£…é¢„ç¼–è¯‘ç‰ˆæœ¬
    pip install flash-attn --no-build-isolation --index-url https://download.pytorch.org/whl/cu121
    
    # å¦‚æœè¿˜æ˜¯å¤±è´¥ï¼Œå°è¯•æ–¹æ¡ˆ3
    if [ $? -ne 0 ]; then
        echo "âš ï¸ pipå®‰è£…å¤±è´¥ï¼Œå°è¯•å®‰è£…è¾ƒæ—§ç‰ˆæœ¬..."
        pip install flash-attn==2.3.6 --no-build-isolation
    fi
fi

# éªŒè¯å®‰è£…
echo "ğŸ” éªŒè¯FlashAttentionå®‰è£…..."
python -c "import flash_attn; print('âœ… FlashAttentionå®‰è£…æˆåŠŸ!')" || {
    echo "âŒ FlashAttentionå®‰è£…å¤±è´¥"
    echo "ğŸ’¡ å»ºè®®æ‰‹åŠ¨å®‰è£…:"
    echo "   1. conda install -c conda-forge flash-attn"
    echo "   2. æˆ–è€…: pip install flash-attn==2.3.6 --no-build-isolation"
    exit 1
}

echo "ğŸ‰ FlashAttentionå®‰è£…å®Œæˆ!" 