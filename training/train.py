#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Qwen2.5-VLé£Ÿç‰©åˆ†ç±»å¤šGPUè®­ç»ƒè„šæœ¬
"""

import os
import sys
import argparse
import yaml
import torch
import deepspeed

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from data.dataloader import create_dataloaders
from models.qwen2_5_vl_classify import Qwen2_5_VLForImageClassification
from optimizer.optimizer import create_optimizer
from training.deepspeed_trainer import DeepSpeedTrainer
from training.lr_scheduler import create_lr_scheduler

def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description="Qwen2.5-VLé£Ÿç‰©åˆ†ç±»å¤šGPUè®­ç»ƒ")
    parser.add_argument("--config", type=str, required=True, help="é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--local_rank", type=int, default=-1, help="æœ¬åœ°è¿›ç¨‹æ’å")
    parser.add_argument("--resume_from", type=str, help="æ¢å¤è®­ç»ƒçš„æ£€æŸ¥ç‚¹è·¯å¾„")
    
    # æ”¯æŒDeepSpeedå‚æ•° (åŒ…å« --deepspeed_config)
    parser = deepspeed.add_config_arguments(parser)
    return parser.parse_args()

def load_config(config_path):
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    return config

def setup_model(config):
    """è®¾ç½®æ¨¡å‹"""
    # è·å–æŸå¤±å‡½æ•°é…ç½®
    loss_config = config.get('loss', {'type': 'cross_entropy'})
    
    # æ‰“å°æŸå¤±å‡½æ•°ä¿¡æ¯ï¼ˆåªåœ¨ä¸»è¿›ç¨‹ï¼‰
    try:
        import torch.distributed as dist
        is_distributed = dist.is_available() and dist.is_initialized()
        if is_distributed:
            current_rank = dist.get_rank()
        else:
            current_rank = 0
        should_print = not is_distributed or current_rank == 0
    except:
        should_print = True
    
    if should_print:
        print(f"ğŸ¯ ä½¿ç”¨æŸå¤±å‡½æ•°: {loss_config.get('type', 'cross_entropy')}")
        if loss_config.get('type') != 'cross_entropy':
            print(f"  æŸå¤±å‡½æ•°å‚æ•°: {loss_config}")
    
    model = Qwen2_5_VLForImageClassification(
        pretrained_model_name=config['model']['pretrained_name'],
        num_labels=config['model']['num_labels'],
        loss_config=loss_config
    )
    
    # å¦‚æœæœ‰é¢„è®­ç»ƒæ£€æŸ¥ç‚¹ï¼ŒåŠ è½½å®ƒ
    if config.get('pretrained_checkpoint'):
        print(f"åŠ è½½é¢„è®­ç»ƒæ£€æŸ¥ç‚¹: {config['pretrained_checkpoint']}")
        checkpoint = torch.load(config['pretrained_checkpoint'], map_location='cpu')
        model.load_state_dict(checkpoint['model_state_dict'], strict=False)
    
    return model

def print_training_info(config, train_loader, val_loader):
    """æ‰“å°è®­ç»ƒä¿¡æ¯"""
    # è·å–DeepSpeedé…ç½®
    deepspeed_config = config.get('deepspeed', {})
    if isinstance(deepspeed_config, str):
        import json
        with open(deepspeed_config, 'r') as f:
            deepspeed_config = json.load(f)
    
    gradient_accumulation_steps = deepspeed_config.get('gradient_accumulation_steps', 1)
    micro_batch_size = deepspeed_config.get('train_micro_batch_size_per_gpu', 1)
    train_batch_size = deepspeed_config.get('train_batch_size', 32)
    
    # è®¡ç®—æœ‰æ•ˆæ­¥æ•°
    dataloader_steps_per_epoch = len(train_loader)
    effective_steps_per_epoch = dataloader_steps_per_epoch // gradient_accumulation_steps
    total_effective_steps = effective_steps_per_epoch * config['training']['num_epochs']
    
    print("=" * 60)
    print("ğŸš€ Qwen2.5-VLé£Ÿç‰©åˆ†ç±»å¤šGPUè®­ç»ƒ")
    print("=" * 60)
    print(f"ğŸ“Š è®­ç»ƒæ•°æ®é›†å¤§å°: {len(train_loader.dataset):,}")
    print(f"ğŸ“Š éªŒè¯æ•°æ®é›†å¤§å°: {len(val_loader.dataset):,}")
    print(f"ğŸ¯ ç±»åˆ«æ•°é‡: {config['model']['num_labels']}")
    print(f"ğŸ”„ è®­ç»ƒè½®æ•°: {config['training']['num_epochs']}")
    print()
    print("ğŸ“¦ æ‰¹æ¬¡é…ç½®:")
    print(f"  â€¢ æ¯GPUå¾®æ‰¹æ¬¡å¤§å°: {micro_batch_size}")
    print(f"  â€¢ æ¢¯åº¦ç´¯ç§¯æ­¥æ•°: {gradient_accumulation_steps}")
    print(f"  â€¢ æœ‰æ•ˆæ‰¹æ¬¡å¤§å°: {train_batch_size}")
    print()
    print("ğŸ“ˆ æ­¥æ•°ç»Ÿè®¡:")
    print(f"  â€¢ DataLoaderæ­¥æ•°æ¯epoch: {dataloader_steps_per_epoch:,}")
    print(f"  â€¢ æœ‰æ•ˆè®­ç»ƒæ­¥æ•°æ¯epoch: {effective_steps_per_epoch:,}")
    print(f"  â€¢ æ€»æœ‰æ•ˆè®­ç»ƒæ­¥æ•°: {total_effective_steps:,}")
    print()
    print("ğŸ“ è®­ç»ƒé…ç½®:")
    print(f"  â€¢ æ—¥å¿—æ­¥æ•°: {config['logging_steps']}")
    print(f"  â€¢ ä¿å­˜æ­¥æ•°: {config['save_steps']}")
    print(f"  â€¢ è¯„ä¼°æ­¥æ•°: {config['eval_steps']}")
    print(f"  â€¢ è¾“å‡ºç›®å½•: {config['output_dir']}")
    print("=" * 60)

def main():
    """ä¸»å‡½æ•°"""
    args = parse_args()
    
    # åˆå§‹åŒ–åˆ†å¸ƒå¼ç¯å¢ƒ (DeepSpeedä¼šå¤„ç†è¿™ä¸ª)
    deepspeed.init_distributed()
    
    # åŠ è½½é…ç½®
    config = load_config(args.config)
    
    # è®¾ç½®DeepSpeedé…ç½®æ–‡ä»¶è·¯å¾„
    config['deepspeed'] = args.deepspeed_config
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = config['training']['output_dir']
    os.makedirs(output_dir, exist_ok=True)
    
    # ä¸ºäº†å…¼å®¹æ€§ï¼Œå°†output_diræå‡åˆ°æ ¹å±‚çº§
    config['output_dir'] = output_dir
    
    # æå‰å‡†å¤‡é…ç½®å‚æ•°ï¼ˆå‚æ•°æ˜ å°„ç­‰ï¼‰
    from training.utils.config_utils import prepare_config
    config = prepare_config(config)
    
    # è®¾ç½®æ¨¡å‹
    model = setup_model(config)
    
    # è®¾ç½®æ•°æ®åŠ è½½å™¨ï¼ˆç°åœ¨åˆ†å¸ƒå¼ç¯å¢ƒå·²ç»åˆå§‹åŒ–ï¼‰
    train_loader, val_loader = create_dataloaders(config)
    
    # åˆ›å»ºè®­ç»ƒå™¨ï¼ˆè¿™é‡Œä¼šè°ƒç”¨prepare_configï¼‰
    trainer = DeepSpeedTrainer(config)
    
    # æ‰“å°è®­ç»ƒä¿¡æ¯ï¼ˆåœ¨prepare_configä¹‹åï¼‰
    if args.local_rank <= 0:
        print_training_info(config, train_loader, val_loader)
    
    # è®¾ç½®ä¼˜åŒ–å™¨
    optimizer = create_optimizer(model, config)
    
    # è®¾ç½®å­¦ä¹ ç‡è°ƒåº¦å™¨
    lr_scheduler = create_lr_scheduler(optimizer, config, len(train_loader))
    
    # è®¾ç½®è®­ç»ƒå™¨
    trainer.setup_model(model, train_loader, val_loader, optimizer, lr_scheduler)
    
    # å¦‚æœéœ€è¦æ¢å¤è®­ç»ƒ
    if args.resume_from:
        print(f"æ¢å¤è®­ç»ƒä»: {args.resume_from}")
        trainer.load_checkpoint(args.resume_from)
    
    # å¼€å§‹è®­ç»ƒ
    trainer.train()

if __name__ == "__main__":
    main() 