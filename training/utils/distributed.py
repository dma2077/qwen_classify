import os
import torch
import torch.distributed as dist

class DistributedContext:
    """ç®¡ç†åˆ†å¸ƒå¼è®­ç»ƒçš„ä¸Šä¸‹æ–‡"""
    
    def __init__(self):
        self.world_size = int(os.environ.get('WORLD_SIZE', 1))
        self.rank = int(os.environ.get('RANK', 0))
        self.local_rank = int(os.environ.get('LOCAL_RANK', 0))
        self.is_main_process = self.rank == 0
        
        # è®¾ç½®CUDAè®¾å¤‡
        if torch.cuda.is_available():
            torch.cuda.set_device(self.local_rank)
            self.device = torch.device(f'cuda:{self.local_rank}')
        else:
            self.device = torch.device('cpu')
    
    def print_info(self):
        """æ‰“å°åˆ†å¸ƒå¼è®­ç»ƒä¿¡æ¯"""
        # ç®€åŒ–è¾“å‡ºï¼Œåªåœ¨éœ€è¦æ—¶æ˜¾ç¤º
        pass
    
    def barrier(self):
        """åŒæ­¥æ‰€æœ‰è¿›ç¨‹"""
        if self.world_size > 1:
            dist.barrier()
    
    def print_main(self, message):
        """åªæœ‰ä¸»è¿›ç¨‹æ‰“å°æ¶ˆæ¯"""
        if self.is_main_process:
            print(message)

def safe_all_reduce(tensor, op=dist.ReduceOp.SUM):
    """
    ç®€åŒ–çš„all_reduceæ“ä½œ - ç§»é™¤å¤æ‚çš„è¶…æ—¶å¤„ç†ï¼Œå› ä¸ºå·²ä¿®å¤æ ¹æœ¬åŸå› 
    """
    if not (dist.is_available() and dist.is_initialized()):
        return True  # éåˆ†å¸ƒå¼ç¯å¢ƒï¼Œç›´æ¥è¿”å›æˆåŠŸ
    
    try:
        dist.all_reduce(tensor, op=op)
        return True
    except Exception as e:
        print(f"âŒ all_reduceæ“ä½œå¤±è´¥: {e}")
        return False

def safe_barrier(timeout=300):
    """
    æ”¹è¿›çš„barrieræ“ä½œï¼Œæ·»åŠ æ›´å¥½çš„è¶…æ—¶å’Œé”™è¯¯å¤„ç†
    """
    if not (dist.is_available() and dist.is_initialized()):
        return True
    
    try:
        # ğŸ”¥ æ”¹è¿›ï¼šä½¿ç”¨æ›´æ™ºèƒ½çš„barrierç­–ç•¥
        import threading
        import time
        
        # åˆ›å»ºä¸€ä¸ªæ ‡å¿—æ¥è·Ÿè¸ªbarrieræ˜¯å¦å®Œæˆ
        barrier_completed = threading.Event()
        barrier_error = None
        
        def barrier_worker():
            nonlocal barrier_error
            try:
                dist.barrier()
                barrier_completed.set()
            except Exception as e:
                barrier_error = e
                barrier_completed.set()
        
        # åœ¨å•ç‹¬çº¿ç¨‹ä¸­æ‰§è¡Œbarrier
        worker_thread = threading.Thread(target=barrier_worker)
        worker_thread.daemon = True
        worker_thread.start()
        
        # ç­‰å¾…barrierå®Œæˆæˆ–è¶…æ—¶
        if barrier_completed.wait(timeout=timeout):
            if barrier_error is None:
                return True
            else:
                print(f"âŒ barrieræ“ä½œå¤±è´¥: {barrier_error}")
                return False
        else:
            print(f"âŒ barrieræ“ä½œè¶…æ—¶ ({timeout}ç§’)")
            return False
            
    except Exception as e:
        print(f"âŒ barrieræ“ä½œå¼‚å¸¸: {e}")
        return False

def batch_all_reduce(tensors, op=dist.ReduceOp.SUM):
    """
    ç®€åŒ–çš„æ‰¹é‡all_reduceæ“ä½œ - ç§»é™¤å¤æ‚çš„åˆ†å—é€»è¾‘
    """
    if not (dist.is_available() and dist.is_initialized()):
        return True  # éåˆ†å¸ƒå¼ç¯å¢ƒï¼Œç›´æ¥è¿”å›æˆåŠŸ
    
    if not tensors:
        return True
    
    try:
        for tensor in tensors:
            dist.all_reduce(tensor, op=op)
        return True
    except Exception as e:
        print(f"âŒ æ‰¹é‡all_reduceæ“ä½œå¤±è´¥: {e}")
        return False

def setup_nccl_timeout_env():
    """è®¾ç½®NCCLç¯å¢ƒå˜é‡ä»¥æé«˜ç¨³å®šæ€§"""
    
    # ğŸ”¥ æ”¹è¿›ï¼šè®¾ç½®æ›´å…¨é¢çš„NCCLé…ç½®
    nccl_configs = {
        # åŸºç¡€è¶…æ—¶è®¾ç½®
        'NCCL_TIMEOUT': '300',  # 5åˆ†é’Ÿè¶…æ—¶ï¼Œä»10åˆ†é’Ÿå‡å°‘
        'NCCL_ASYNC_ERROR_HANDLING': '1',  # å¯ç”¨å¼‚æ­¥é”™è¯¯å¤„ç†
        
        # ğŸ”¥ æ–°å¢ï¼šè¿æ¥ç¨³å®šæ€§è®¾ç½®
        'NCCL_SOCKET_TIMEOUT': '30000',  # 30ç§’socketè¶…æ—¶
        'NCCL_CONNECT_TIMEOUT': '30000',  # 30ç§’è¿æ¥è¶…æ—¶
        'NCCL_HEARTBEAT_TIMEOUT': '30000',  # 30ç§’å¿ƒè·³è¶…æ—¶
        
        # ğŸ”¥ æ–°å¢ï¼šç½‘ç»œé‡è¯•è®¾ç½®
        'NCCL_RETRY_COUNT': '3',  # é‡è¯•3æ¬¡
        'NCCL_RETRY_TIMEOUT': '10000',  # é‡è¯•è¶…æ—¶10ç§’
        
        # ğŸ”¥ æ–°å¢ï¼šè¯„ä¼°æ—¶çš„ç‰¹æ®Šè®¾ç½®
        'NCCL_BUFFSIZE': '8388608',  # 8MBç¼“å†²åŒºï¼Œå‡å°‘å†…å­˜ä½¿ç”¨
        'NCCL_NTHREADS': '16',  # å‡å°‘çº¿ç¨‹æ•°
        
        # ğŸ”¥ æ–°å¢ï¼šè°ƒè¯•å’Œç¨³å®šæ€§
        'NCCL_DEBUG': 'WARN',  # åªæ˜¾ç¤ºè­¦å‘Šå’Œé”™è¯¯
        'NCCL_IB_DISABLE': '1',  # ç¦ç”¨InfiniBandï¼Œä½¿ç”¨TCP
        'NCCL_P2P_DISABLE': '1',  # ç¦ç”¨P2Pï¼Œæé«˜ç¨³å®šæ€§
    }
    
    # åªè®¾ç½®å°šæœªè®¾ç½®çš„ç¯å¢ƒå˜é‡
    for key, value in nccl_configs.items():
        if key not in os.environ:
            os.environ[key] = value
    
    # é™é»˜è®¾ç½®ï¼Œä¸è¾“å‡ºä¿¡æ¯
    pass 