import torch
import time
from typing import Dict, Tuple
from tqdm import tqdm
from collections import defaultdict
from .distributed import safe_all_reduce, safe_barrier

def evaluate_model(model, val_loader, device) -> Tuple[float, float]:
    """è¯„ä¼°æ¨¡å‹æ€§èƒ½ - åœ¨åˆ†å¸ƒå¼ç¯å¢ƒä¸‹æ­£ç¡®èšåˆæ‰€æœ‰GPUçš„ç»“æœ"""
    import torch.distributed as dist
    
    model.eval()
    total_loss = 0
    correct = 0
    total = 0
    
    # æ£€æŸ¥åˆ†å¸ƒå¼çŠ¶æ€
    is_distributed = dist.is_available() and dist.is_initialized()
    if is_distributed:
        current_rank = dist.get_rank()
    else:
        current_rank = 0
    
    # åªåœ¨ä¸»è¿›ç¨‹æ˜¾ç¤ºè¿›åº¦æ¡
    show_progress = not is_distributed or current_rank == 0
    eval_pbar = tqdm(val_loader, desc="Evaluating", leave=False, disable=not show_progress)
    
    batch_count = 0  # ç”¨äºè®¡ç®—å¹³å‡æŸå¤±
    
    with torch.no_grad():
        for batch_idx, batch in enumerate(eval_pbar):
            try:
                batch_count += 1
                
                # ç§»åŠ¨æ•°æ®åˆ°è®¾å¤‡
                inputs = batch["input_ids"].to(device)
                attention_mask = batch["attention_mask"].to(device)
                pixel_values = batch["pixel_values"].to(device)
                labels = batch["labels"].to(device)
                
                # å‰å‘ä¼ æ’­
                forward_kwargs = {
                    "input_ids": inputs,
                    "attention_mask": attention_mask,
                    "pixel_values": pixel_values,
                    "labels": labels
                }
                
                # æ£€æŸ¥å¹¶æ·»åŠ image_grid_thwå‚æ•°
                if "image_grid_thw" in batch:
                    forward_kwargs["image_grid_thw"] = batch["image_grid_thw"].to(device)
                
                outputs = model(**forward_kwargs)
                
                # è®¡ç®—æŸå¤±
                loss = outputs.loss
                total_loss += loss.item()
                
                # è®¡ç®—å‡†ç¡®ç‡
                predictions = torch.argmax(outputs.logits, dim=-1)
                correct += (predictions == labels).sum().item()
                total += labels.size(0)
                
                # æ¯10æ­¥æˆ–æœ€åä¸€æ­¥æ›´æ–°è¿›åº¦æ¡æ˜¾ç¤º
                if show_progress and (batch_idx % 10 == 0 or batch_idx == len(val_loader) - 1):
                    current_accuracy = correct / total if total > 0 else 0
                    current_avg_loss = total_loss / batch_count
                    eval_pbar.set_postfix({
                        'loss': f'{loss.item():.4f}',
                        'avg_loss': f'{current_avg_loss:.4f}',
                        'accuracy': f'{current_accuracy:.4f}',
                        'samples': f'{total}'
                    })
                
            except Exception as e:
                if show_progress:
                    print(f"âŒ è¯„ä¼°æ‰¹æ¬¡ {batch_idx} å‡ºé”™: {e}")
                    eval_pbar.set_postfix({'error': f'batch_{batch_idx}_failed'})
                continue
    
    # å…³é—­è¿›åº¦æ¡
    eval_pbar.close()
    
    # åœ¨åˆ†å¸ƒå¼ç¯å¢ƒä¸‹èšåˆæ‰€æœ‰GPUçš„ç»“æœ
    if is_distributed:
        # è½¬æ¢ä¸ºtensorè¿›è¡Œèšåˆ
        total_loss_tensor = torch.tensor(total_loss, dtype=torch.float32, device=device)
        correct_tensor = torch.tensor(correct, dtype=torch.long, device=device) 
        total_tensor = torch.tensor(total, dtype=torch.long, device=device)
        batch_count_tensor = torch.tensor(batch_count, dtype=torch.long, device=device)
        
        # èšåˆæ‰€æœ‰GPUçš„ç»“æœ
        if not safe_all_reduce(total_loss_tensor, op=dist.ReduceOp.SUM, timeout=180):
            print("âš ï¸  total_lossèšåˆå¤±è´¥ï¼Œä½¿ç”¨æœ¬åœ°ç»“æœ")
            avg_loss = total_loss / batch_count if batch_count > 0 else 0
            accuracy = correct / total if total > 0 else 0
            return avg_loss, accuracy
            
        if not safe_all_reduce(correct_tensor, op=dist.ReduceOp.SUM, timeout=180):
            print("âš ï¸  correctèšåˆå¤±è´¥ï¼Œä½¿ç”¨æœ¬åœ°ç»“æœ")
            avg_loss = total_loss / batch_count if batch_count > 0 else 0
            accuracy = correct / total if total > 0 else 0
            return avg_loss, accuracy
            
        if not safe_all_reduce(total_tensor, op=dist.ReduceOp.SUM, timeout=180):
            print("âš ï¸  totalèšåˆå¤±è´¥ï¼Œä½¿ç”¨æœ¬åœ°ç»“æœ")
            avg_loss = total_loss / batch_count if batch_count > 0 else 0
            accuracy = correct / total if total > 0 else 0
            return avg_loss, accuracy
            
        if not safe_all_reduce(batch_count_tensor, op=dist.ReduceOp.SUM, timeout=180):
            print("âš ï¸  batch_countèšåˆå¤±è´¥ï¼Œä½¿ç”¨æœ¬åœ°ç»“æœ")
            avg_loss = total_loss / batch_count if batch_count > 0 else 0
            accuracy = correct / total if total > 0 else 0
            return avg_loss, accuracy
        
        # è®¡ç®—å…¨å±€å¹³å‡å€¼
        global_avg_loss = total_loss_tensor.item() / batch_count_tensor.item() if batch_count_tensor.item() > 0 else 0
        global_accuracy = correct_tensor.item() / total_tensor.item() if total_tensor.item() > 0 else 0
        
        # åªåœ¨ä¸»è¿›ç¨‹æ‰“å°å…¨å±€ç»“æœ
        if current_rank == 0:
            print("\n" + "="*80)
            print("ğŸ“Š éªŒè¯é›†è¯„ä¼°ç»“æœ (å…¨å±€èšåˆ)")
            print("="*80)
            print(f"ğŸ“ˆ Average Loss:     {global_avg_loss:.6f}")
            print(f"ğŸ¯ Accuracy:         {global_accuracy:.4f} ({global_accuracy*100:.2f}%)")
            print(f"ğŸ“Š Total Samples:    {total_tensor.item():,}")
            print(f"âœ… Correct Samples:  {correct_tensor.item():,}")
            print(f"âŒ Wrong Samples:    {total_tensor.item() - correct_tensor.item():,}")
            print("="*80 + "\n")
        
        return global_avg_loss, global_accuracy
    else:
        # å•GPUæ¨¡å¼
        avg_loss = total_loss / batch_count if batch_count > 0 else 0
        accuracy = correct / total if total > 0 else 0
        print("\n" + "="*80)
        print("ğŸ“Š éªŒè¯é›†è¯„ä¼°ç»“æœ")
        print("="*80)
        print(f"ğŸ“ˆ Average Loss:     {avg_loss:.6f}")
        print(f"ğŸ¯ Accuracy:         {accuracy:.4f} ({accuracy*100:.2f}%)")
        print(f"ğŸ“Š Total Samples:    {total:,}")
        print(f"âœ… Correct Samples:  {correct:,}")
        print(f"âŒ Wrong Samples:    {total - correct:,}")
        print("="*80 + "\n")
        return avg_loss, accuracy

def evaluate_multi_dataset(model, val_loader, device, dataset_configs=None) -> Dict:
    """
    å¤šæ•°æ®é›†è¯„ä¼°å‡½æ•°ï¼Œæ”¯æŒæŒ‰æ•°æ®é›†åˆ†åˆ«ç»Ÿè®¡æŒ‡æ ‡
    
    Args:
        model: æ¨¡å‹
        val_loader: éªŒè¯æ•°æ®åŠ è½½å™¨
        device: è®¾å¤‡
        dataset_configs: æ•°æ®é›†é…ç½®å­—å…¸
        
    Returns:
        evaluation results dictionary containing overall and per-dataset metrics
    """
    import torch.distributed as dist
    
    model.eval()
    
    # æ£€æŸ¥åˆ†å¸ƒå¼çŠ¶æ€
    is_distributed = dist.is_available() and dist.is_initialized()
    if is_distributed:
        current_rank = dist.get_rank()
        world_size = dist.get_world_size()
    else:
        current_rank = 0
        world_size = 1
    
    # åªåœ¨ä¸»è¿›ç¨‹æ˜¾ç¤ºè¿›åº¦æ¡
    show_progress = not is_distributed or current_rank == 0
    eval_pbar = tqdm(val_loader, desc="Multi-Dataset Evaluation", leave=False, disable=not show_progress)
    
    # æ•´ä½“ç»Ÿè®¡
    total_loss = 0
    correct = 0
    total = 0
    batch_count = 0
    
    # æŒ‰æ•°æ®é›†ç»Ÿè®¡
    dataset_stats = defaultdict(lambda: {
        'total_loss': 0.0,
        'correct': 0,
        'total': 0,
        'batch_count': 0
    })
    
    with torch.no_grad():
        for batch_idx, batch in enumerate(eval_pbar):
            try:
                batch_count += 1
                
                # ç§»åŠ¨æ•°æ®åˆ°è®¾å¤‡
                inputs = batch["input_ids"].to(device)
                attention_mask = batch["attention_mask"].to(device)
                pixel_values = batch["pixel_values"].to(device)
                labels = batch["labels"].to(device)
                
                # è·å–æ•°æ®é›†ä¿¡æ¯
                dataset_names = batch.get("dataset_names", [])
                num_classes_list = batch.get("num_classes_list", [])
                
                # å‰å‘ä¼ æ’­
                forward_kwargs = {
                    "input_ids": inputs,
                    "attention_mask": attention_mask,
                    "pixel_values": pixel_values,
                    "labels": labels
                }
                
                # æ£€æŸ¥å¹¶æ·»åŠ image_grid_thwå‚æ•°
                if "image_grid_thw" in batch:
                    forward_kwargs["image_grid_thw"] = batch["image_grid_thw"].to(device)
                
                # æ·»åŠ å¤šæ•°æ®é›†æ”¯æŒçš„å‚æ•°
                if dataset_names:
                    forward_kwargs["dataset_names"] = dataset_names
                if num_classes_list:
                    forward_kwargs["num_classes_list"] = num_classes_list
                
                outputs = model(**forward_kwargs)
                
                # è®¡ç®—æŸå¤±å’Œé¢„æµ‹
                loss = outputs.loss
                predictions = torch.argmax(outputs.logits, dim=-1)
                
                # æ›´æ–°æ•´ä½“ç»Ÿè®¡
                total_loss += loss.item()
                correct += (predictions == labels).sum().item()
                total += labels.size(0)
                
                # æ›´æ–°å„æ•°æ®é›†ç»Ÿè®¡
                for i, dataset_name in enumerate(dataset_names):
                    if i >= len(labels) or i >= len(predictions):
                        continue
                        
                    label = labels[i].item()
                    pred = predictions[i].item()
                    
                    dataset_stats[dataset_name]['total_loss'] += loss.item() / len(dataset_names)
                    dataset_stats[dataset_name]['total'] += 1
                    dataset_stats[dataset_name]['batch_count'] += 1
                    
                    if pred == label:
                        dataset_stats[dataset_name]['correct'] += 1
                
                # æ¯10æ­¥æˆ–æœ€åä¸€æ­¥æ›´æ–°è¿›åº¦æ¡æ˜¾ç¤º
                if show_progress and (batch_idx % 10 == 0 or batch_idx == len(val_loader) - 1):
                    current_accuracy = correct / total if total > 0 else 0
                    current_avg_loss = total_loss / batch_count
                    eval_pbar.set_postfix({
                        'loss': f'{loss.item():.4f}',
                        'avg_loss': f'{current_avg_loss:.4f}',
                        'accuracy': f'{current_accuracy:.4f}',
                        'datasets': f'{len(dataset_stats)}'
                    })
                
            except Exception as e:
                if show_progress:
                    print(f"âŒ å¤šæ•°æ®é›†è¯„ä¼°æ‰¹æ¬¡ {batch_idx} å‡ºé”™: {e}")
                    eval_pbar.set_postfix({'error': f'batch_{batch_idx}_failed'})
                continue
    
    # å…³é—­è¿›åº¦æ¡
    eval_pbar.close()
    
    # åœ¨åˆ†å¸ƒå¼ç¯å¢ƒä¸‹èšåˆç»“æœ
    if is_distributed:
        try:
            if show_progress:
                print(f"ğŸ”„ å¼€å§‹åˆ†å¸ƒå¼è¯„ä¼°ç»“æœèšåˆ (world_size={world_size})...")
            
            # èšåˆæ•´ä½“ç»Ÿè®¡
            total_loss_tensor = torch.tensor(total_loss, dtype=torch.float32, device=device)
            correct_tensor = torch.tensor(correct, dtype=torch.long, device=device) 
            total_tensor = torch.tensor(total, dtype=torch.long, device=device)
            batch_count_tensor = torch.tensor(batch_count, dtype=torch.long, device=device)
            
            # ä½¿ç”¨è¾ƒçŸ­çš„è¶…æ—¶æ—¶é—´å¹¶æ·»åŠ é”™è¯¯å¤„ç†
            try:
                if not safe_all_reduce(total_loss_tensor, op=dist.ReduceOp.SUM, timeout=180):
                    raise Exception("total_lossèšåˆè¶…æ—¶")
                if not safe_all_reduce(correct_tensor, op=dist.ReduceOp.SUM, timeout=180):
                    raise Exception("correctèšåˆè¶…æ—¶")
                if not safe_all_reduce(total_tensor, op=dist.ReduceOp.SUM, timeout=180):
                    raise Exception("totalèšåˆè¶…æ—¶")
                if not safe_all_reduce(batch_count_tensor, op=dist.ReduceOp.SUM, timeout=180):
                    raise Exception("batch_countèšåˆè¶…æ—¶")
                
                if show_progress:
                    print("âœ… æ•´ä½“ç»Ÿè®¡èšåˆå®Œæˆ")
                    
            except Exception as e:
                if show_progress:
                    print(f"âŒ æ•´ä½“ç»Ÿè®¡èšåˆå¤±è´¥: {e}")
                    print("âš ï¸  å°†ä½¿ç”¨æœ¬åœ°ç»Ÿè®¡ç»“æœ")
                # ç»§ç»­ä½¿ç”¨æœ¬åœ°ç»“æœï¼Œä¸é€€å‡º
            
            # èšåˆæ•°æ®é›†ç‰¹å®šç»Ÿè®¡
            aggregated_dataset_stats = {}
            for dataset_name, stats in dataset_stats.items():
                try:
                    # ä¸ºæ¯ä¸ªæ•°æ®é›†åˆ›å»ºtensor
                    dataset_loss_tensor = torch.tensor(stats['total_loss'], dtype=torch.float32, device=device)
                    dataset_correct_tensor = torch.tensor(stats['correct'], dtype=torch.long, device=device)
                    dataset_total_tensor = torch.tensor(stats['total'], dtype=torch.long, device=device)
                    dataset_batch_count_tensor = torch.tensor(stats['batch_count'], dtype=torch.long, device=device)
                    
                    # èšåˆæ•°æ®é›†ç»Ÿè®¡
                    if not safe_all_reduce(dataset_loss_tensor, op=dist.ReduceOp.SUM, timeout=120):
                        raise Exception(f"{dataset_name}_lossèšåˆè¶…æ—¶")
                    if not safe_all_reduce(dataset_correct_tensor, op=dist.ReduceOp.SUM, timeout=120):
                        raise Exception(f"{dataset_name}_correctèšåˆè¶…æ—¶")
                    if not safe_all_reduce(dataset_total_tensor, op=dist.ReduceOp.SUM, timeout=120):
                        raise Exception(f"{dataset_name}_totalèšåˆè¶…æ—¶")
                    if not safe_all_reduce(dataset_batch_count_tensor, op=dist.ReduceOp.SUM, timeout=120):
                        raise Exception(f"{dataset_name}_batch_countèšåˆè¶…æ—¶")
                    
                    aggregated_dataset_stats[dataset_name] = {
                        'total_loss': dataset_loss_tensor.item(),
                        'correct': dataset_correct_tensor.item(),
                        'total': dataset_total_tensor.item(),
                        'batch_count': dataset_batch_count_tensor.item()
                    }
                    
                except Exception as e:
                    if show_progress:
                        print(f"âŒ æ•°æ®é›† {dataset_name} ç»Ÿè®¡èšåˆå¤±è´¥: {e}")
                    # ä½¿ç”¨æœ¬åœ°ç»Ÿè®¡
                    aggregated_dataset_stats[dataset_name] = stats
            
            # ä½¿ç”¨èšåˆåçš„ç»“æœ
            total_loss = total_loss_tensor.item()
            correct = correct_tensor.item()
            total = total_tensor.item()
            batch_count = batch_count_tensor.item()
            dataset_stats = aggregated_dataset_stats
            
            if show_progress:
                print("âœ… åˆ†å¸ƒå¼è¯„ä¼°ç»“æœèšåˆå®Œæˆ")
                
        except Exception as e:
            if show_progress:
                print(f"âŒ åˆ†å¸ƒå¼èšåˆè¿‡ç¨‹å‡ºé”™: {e}")
                print("âš ï¸  å°†ä½¿ç”¨æœ¬åœ°è¯„ä¼°ç»“æœ")
            # ç»§ç»­ä½¿ç”¨æœ¬åœ°ç»“æœ
    
    # è®¡ç®—ç»“æœ
    overall_avg_loss = total_loss / batch_count if batch_count > 0 else 0
    overall_accuracy = correct / total if total > 0 else 0
    
    # è®¡ç®—å„æ•°æ®é›†çš„æŒ‡æ ‡
    dataset_metrics = {}
    for dataset_name, stats in dataset_stats.items():
        if stats['total'] > 0:
            avg_loss = stats['total_loss'] / stats['batch_count'] if stats['batch_count'] > 0 else 0
            accuracy = stats['correct'] / stats['total']
            dataset_metrics[dataset_name] = {
                'loss': avg_loss,
                'accuracy': accuracy,
                'samples': stats['total'],
                'correct': stats['correct']
            }
    
    # è¾“å‡ºç»“æœï¼ˆåªåœ¨ä¸»è¿›ç¨‹è¾“å‡ºï¼‰
    if show_progress:
        print("\n" + "="*80)
        print("ğŸ“Š å¤šæ•°æ®é›†è¯„ä¼°ç»“æœ")
        if is_distributed:
            print(f"   (åˆ†å¸ƒå¼èšåˆç»“æœ, world_size={world_size})")
        print("="*80)
        print(f"ğŸ“ˆ Overall Loss:     {overall_avg_loss:.6f}")
        print(f"ğŸ¯ Overall Accuracy: {overall_accuracy:.4f} ({overall_accuracy*100:.2f}%)")
        print(f"ğŸ“Š Total Samples:    {total:,}")
        print(f"âœ… Total Correct:    {correct:,}")
        print()
        
        for dataset_name, metrics in dataset_metrics.items():
            print(f"ğŸ“‚ {dataset_name}:")
            print(f"  â€¢ Loss:     {metrics['loss']:.6f}")
            print(f"  â€¢ Accuracy: {metrics['accuracy']:.4f} ({metrics['accuracy']*100:.2f}%)")
            print(f"  â€¢ Samples:  {metrics['samples']:,} (Correct: {metrics['correct']:,})")
            
        print("="*80 + "\n")
    
    return {
        'overall_loss': overall_avg_loss,
        'overall_accuracy': overall_accuracy,
        'dataset_metrics': dataset_metrics,
        'total_samples': total,
        'total_correct': correct
    } 