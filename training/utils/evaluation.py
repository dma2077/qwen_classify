import torch
import time
from typing import Dict, Tuple
from tqdm import tqdm
from collections import defaultdict
from .distributed import safe_all_reduce, safe_barrier, batch_all_reduce

def evaluate_model(model, val_loader, device) -> Tuple[float, float]:
    """è¯„ä¼°æ¨¡å‹æ€§èƒ½ - å¢å¼ºåˆ†å¸ƒå¼æ”¯æŒï¼Œé˜²æ­¢æ­»é”"""
    import torch.distributed as dist
    import signal
    
    # æ£€æŸ¥åˆ†å¸ƒå¼çŠ¶æ€
    is_distributed = dist.is_available() and dist.is_initialized()
    if is_distributed:
        current_rank = dist.get_rank()
        world_size = dist.get_world_size()
        
        # ğŸ”¥ å¼ºåˆ¶è¯„ä¼°å¼€å§‹å‰åŒæ­¥
        try:
            dist.barrier()
            if current_rank == 0:
                print("ğŸ”„ è¯„ä¼°å¼€å§‹å‰åˆ†å¸ƒå¼åŒæ­¥å®Œæˆ")
        except Exception as e:
            print(f"âš ï¸ è¯„ä¼°å¼€å§‹å‰åŒæ­¥å¤±è´¥: {e}")
            return 999.0, 0.0
    else:
        current_rank = 0
        world_size = 1
    
    # ğŸ”¥ è®¾ç½®è¯„ä¼°è¶…æ—¶ä¿æŠ¤
    def timeout_handler(signum, frame):
        raise TimeoutError("è¯„ä¼°è¿‡ç¨‹è¶…æ—¶")
    
    timeout_set = False
    if current_rank == 0:
        try:
            signal.signal(signal.SIGALRM, timeout_handler)
            signal.alarm(600)  # 10åˆ†é’Ÿè¶…æ—¶
            timeout_set = True
        except:
            pass  # å¦‚æœè®¾ç½®è¶…æ—¶å¤±è´¥ï¼Œç»§ç»­æ‰§è¡Œ
    
    try:
        # ğŸ”¥ ç¡®ä¿æ¨¡å‹å¤„äºè¯„ä¼°æ¨¡å¼ - å…¼å®¹DeepSpeedåŒ…è£…
        model.eval()
        if hasattr(model, 'module'):
            model.module.eval()
            if current_rank == 0:
                print(f"ğŸ” è®¾ç½®DeepSpeedåŒ…è£…æ¨¡å‹ä¸ºevalæ¨¡å¼: model.training={model.training}, model.module.training={model.module.training}")
        else:
            if current_rank == 0:
                print(f"ğŸ” è®¾ç½®æ¨¡å‹ä¸ºevalæ¨¡å¼: model.training={model.training}")
        
        total_loss = 0
        correct = 0
        total = 0
        
        # åªåœ¨ä¸»è¿›ç¨‹æ˜¾ç¤ºè¿›åº¦æ¡
        show_progress = not is_distributed or current_rank == 0
        eval_pbar = tqdm(val_loader, desc="Evaluating", leave=False, disable=not show_progress)
        
        batch_count = 0
        
        with torch.no_grad():
            for batch_idx, batch in enumerate(eval_pbar):
                try:
                    batch_count += 1
                    
                    # ğŸ”¥ æ¯20ä¸ªbatchè¿›è¡ŒåŒæ­¥æ£€æŸ¥ï¼Œå‡å°‘åŒæ­¥é¢‘ç‡
                    if is_distributed and batch_idx % 20 == 0:
                        try:
                            dist.barrier()
                        except Exception as sync_e:
                            if current_rank == 0:
                                print(f"âš ï¸ ç¬¬{batch_idx}æ‰¹æ¬¡åŒæ­¥å¤±è´¥: {sync_e}")
                    
                    # ç§»åŠ¨æ•°æ®åˆ°è®¾å¤‡
                    inputs = batch["input_ids"].to(device)
                    attention_mask = batch["attention_mask"].to(device)
                    pixel_values = batch["pixel_values"].to(device)
                    labels = batch["labels"].to(device)
                    
                    # å‰å‘ä¼ æ’­
                    forward_kwargs = {
                        "input_ids": inputs,
                        "attention_mask": attention_mask,
                        "pixel_values": pixel_values,
                        "labels": labels
                    }
                    
                    # æ£€æŸ¥å¹¶æ·»åŠ image_grid_thwå‚æ•°
                    if "image_grid_thw" in batch:
                        forward_kwargs["image_grid_thw"] = batch["image_grid_thw"].to(device)
                    
                    outputs = model(**forward_kwargs)
                    
                    # è®¡ç®—æŸå¤±
                    loss = outputs.loss
                    total_loss += loss.item()
                    
                    # è®¡ç®—å‡†ç¡®ç‡
                    predictions = torch.argmax(outputs.logits, dim=-1)
                    correct += (predictions == labels).sum().item()
                    total += labels.size(0)
                    
                    # æ¯10æ­¥æˆ–æœ€åä¸€æ­¥æ›´æ–°è¿›åº¦æ¡æ˜¾ç¤º
                    if show_progress and (batch_idx % 10 == 0 or batch_idx == len(val_loader) - 1):
                        current_accuracy = correct / total if total > 0 else 0
                        current_avg_loss = total_loss / batch_count
                        eval_pbar.set_postfix({
                            'loss': f'{loss.item():.4f}',
                            'avg_loss': f'{current_avg_loss:.4f}',
                            'accuracy': f'{current_accuracy:.4f}',
                            'samples': f'{total}'
                        })
                    
                except Exception as batch_e:
                    if show_progress:
                        print(f"âŒ è¯„ä¼°æ‰¹æ¬¡ {batch_idx} å‡ºé”™: {batch_e}")
                        eval_pbar.set_postfix({'error': f'batch_{batch_idx}_failed'})
                    continue
        
        # å…³é—­è¿›åº¦æ¡
        eval_pbar.close()
        
        # ğŸ”¥ å¼ºåˆ¶è¯„ä¼°ç»“æŸååŒæ­¥
        if is_distributed:
            try:
                dist.barrier()
                if current_rank == 0:
                    print("ğŸ”„ è¯„ä¼°ç»“æŸååˆ†å¸ƒå¼åŒæ­¥å®Œæˆ")
            except Exception as e:
                print(f"âš ï¸ è¯„ä¼°ç»“æŸååŒæ­¥å¤±è´¥: {e}")
        
        # åœ¨åˆ†å¸ƒå¼ç¯å¢ƒä¸‹èšåˆæ‰€æœ‰GPUçš„ç»“æœ
        if is_distributed:
            # è½¬æ¢ä¸ºtensorè¿›è¡Œèšåˆ
            total_loss_tensor = torch.tensor(total_loss, dtype=torch.float32, device=device)
            correct_tensor = torch.tensor(correct, dtype=torch.long, device=device) 
            total_tensor = torch.tensor(total, dtype=torch.long, device=device)
            batch_count_tensor = torch.tensor(batch_count, dtype=torch.long, device=device)
            
            # æ‰¹é‡èšåˆæ‰€æœ‰tensorï¼Œæé«˜æ•ˆç‡
            tensors_to_reduce = [total_loss_tensor, correct_tensor, total_tensor, batch_count_tensor]
            if not batch_all_reduce(tensors_to_reduce, op=dist.ReduceOp.SUM):
                print("âš ï¸  æ‰¹é‡èšåˆå¤±è´¥ï¼Œä½¿ç”¨æœ¬åœ°ç»“æœ")
                avg_loss = total_loss / batch_count if batch_count > 0 else 0
                accuracy = correct / total if total > 0 else 0
                return avg_loss, accuracy
            
            # è®¡ç®—å…¨å±€å¹³å‡å€¼
            global_avg_loss = total_loss_tensor.item() / batch_count_tensor.item() if batch_count_tensor.item() > 0 else 0
            global_accuracy = correct_tensor.item() / total_tensor.item() if total_tensor.item() > 0 else 0
            
            # åªåœ¨ä¸»è¿›ç¨‹æ‰“å°å…¨å±€ç»“æœ
            if current_rank == 0:
                print("\n" + "="*80)
                print("ğŸ“Š éªŒè¯é›†è¯„ä¼°ç»“æœ (å…¨å±€èšåˆ)")
                print("="*80)
                print(f"ğŸ“ˆ Average Loss:     {global_avg_loss:.6f}")
                print(f"ğŸ¯ Accuracy:         {global_accuracy:.4f} ({global_accuracy*100:.2f}%)")
                print(f"ğŸ“Š Total Samples:    {total_tensor.item():,}")
                print(f"âœ… Correct Samples:  {correct_tensor.item():,}")
                print(f"âŒ Wrong Samples:    {total_tensor.item() - correct_tensor.item():,}")
                print("="*80 + "\n")
            
            return global_avg_loss, global_accuracy
        else:
            # å•GPUæ¨¡å¼
            avg_loss = total_loss / batch_count if batch_count > 0 else 0
            accuracy = correct / total if total > 0 else 0
            print("\n" + "="*80)
            print("ğŸ“Š éªŒè¯é›†è¯„ä¼°ç»“æœ")
            print("="*80)
            print(f"ğŸ“ˆ Average Loss:     {avg_loss:.6f}")
            print(f"ğŸ¯ Accuracy:         {accuracy:.4f} ({accuracy*100:.2f}%)")
            print(f"ğŸ“Š Total Samples:    {total:,}")
            print(f"âœ… Correct Samples:  {correct:,}")
            print(f"âŒ Wrong Samples:    {total - correct:,}")
            print("="*80 + "\n")
            return avg_loss, accuracy
            
    except Exception as eval_e:
        # ğŸ”¥ è¯„ä¼°å¼‚å¸¸å¤„ç†
        if current_rank == 0:
            print(f"âŒ è¯„ä¼°è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {eval_e}")
        
        # å°è¯•åŒæ­¥æ‰€æœ‰è¿›ç¨‹ï¼Œé¿å…æ­»é”
        if is_distributed:
            try:
                dist.barrier()
                if current_rank == 0:
                    print("ğŸ”„ å¼‚å¸¸ååˆ†å¸ƒå¼åŒæ­¥å®Œæˆ")
            except:
                if current_rank == 0:
                    print("âš ï¸ å¼‚å¸¸ååŒæ­¥ä¹Ÿå¤±è´¥")
        
        # è¿”å›é”™è¯¯æ ‡è¯†
        return 999.0, 0.0
        
    finally:
        # ğŸ”¥ æ¸…ç†è¶…æ—¶è®¾ç½®
        if timeout_set and current_rank == 0:
            try:
                signal.alarm(0)
            except:
                pass


def evaluate_multi_dataset(model, val_loader, device, dataset_configs=None) -> Dict:
    """
    å¤šæ•°æ®é›†è¯„ä¼°å‡½æ•°ï¼Œæ”¯æŒæŒ‰æ•°æ®é›†åˆ†åˆ«ç»Ÿè®¡æŒ‡æ ‡ - å¢å¼ºåˆ†å¸ƒå¼æ”¯æŒ
    """
    import torch.distributed as dist
    
    # ğŸ”¥ ä¿®å¤ï¼šæ·»åŠ åˆ†å¸ƒå¼åŒæ­¥ï¼Œç¡®ä¿æ‰€æœ‰è¿›ç¨‹åŒæ—¶å¼€å§‹è¯„ä¼°
    is_distributed = dist.is_available() and dist.is_initialized()
    if is_distributed:
        current_rank = dist.get_rank()
        try:
            dist.barrier()
            if current_rank == 0:
                print("ğŸ”„ å¤šæ•°æ®é›†è¯„ä¼°å¼€å§‹å‰åˆ†å¸ƒå¼åŒæ­¥å®Œæˆ")
        except Exception as e:
            print(f"âŒ å¤šæ•°æ®é›†è¯„ä¼°å¼€å§‹å‰åŒæ­¥å¤±è´¥: {e}")
            return {}
    else:
        current_rank = 0
    
    try:
        # ğŸ”¥ ç¡®ä¿æ¨¡å‹å¤„äºè¯„ä¼°æ¨¡å¼ - å…¼å®¹DeepSpeedåŒ…è£…
        model.eval()
        
        # åªåœ¨ä¸»è¿›ç¨‹æ˜¾ç¤ºè¿›åº¦æ¡
        show_progress = not is_distributed or current_rank == 0
        eval_pbar = tqdm(val_loader, desc="Multi-Dataset Evaluation", leave=False, disable=not show_progress)
        
        # æ•´ä½“ç»Ÿè®¡
        total_loss = 0
        correct = 0
        total = 0
        batch_count = 0
        
        # æŒ‰æ•°æ®é›†ç»Ÿè®¡
        dataset_stats = defaultdict(lambda: {
            'total_loss': 0.0,
            'correct': 0,
            'total': 0,
            'batch_count': 0
        })
        
        with torch.no_grad():
            for batch_idx, batch in enumerate(eval_pbar):
                try:
                    batch_count += 1
                    
                    # ğŸ”¥ æ¯20ä¸ªbatchè¿›è¡ŒåŒæ­¥æ£€æŸ¥
                    if is_distributed and batch_idx % 20 == 0:
                        try:
                            dist.barrier()
                        except Exception as sync_e:
                            if current_rank == 0:
                                print(f"âš ï¸ å¤šæ•°æ®é›†è¯„ä¼°ç¬¬{batch_idx}æ‰¹æ¬¡åŒæ­¥å¤±è´¥: {sync_e}")
                    
                    # ç§»åŠ¨æ•°æ®åˆ°è®¾å¤‡
                    inputs = batch["input_ids"].to(device)
                    attention_mask = batch["attention_mask"].to(device)
                    pixel_values = batch["pixel_values"].to(device)
                    labels = batch["labels"].to(device)
                    
                    # è·å–æ•°æ®é›†ä¿¡æ¯
                    dataset_names = batch.get("dataset_names", [])
                    num_classes_list = batch.get("num_classes_list", [])
                    
                    # å‰å‘ä¼ æ’­
                    forward_kwargs = {
                        "input_ids": inputs,
                        "attention_mask": attention_mask,
                        "pixel_values": pixel_values,
                        "labels": labels
                    }
                    
                    # æ£€æŸ¥å¹¶æ·»åŠ image_grid_thwå‚æ•°
                    if "image_grid_thw" in batch:
                        forward_kwargs["image_grid_thw"] = batch["image_grid_thw"].to(device)
                    
                    outputs = model(**forward_kwargs)
                    
                    # è®¡ç®—æŸå¤±å’Œå‡†ç¡®ç‡
                    loss = outputs.loss
                    predictions = torch.argmax(outputs.logits, dim=-1)
                    
                    # æ•´ä½“ç»Ÿè®¡æ›´æ–°
                    total_loss += loss.item()
                    correct += (predictions == labels).sum().item()
                    total += labels.size(0)
                    
                    # æŒ‰æ•°æ®é›†æ›´æ–°ç»Ÿè®¡
                    if dataset_names:
                        batch_size = labels.size(0)
                        for i in range(batch_size):
                            if i < len(dataset_names):
                                dataset_name = dataset_names[i]
                                label_val = labels[i].item()
                                pred_val = predictions[i].item()
                                
                                dataset_stats[dataset_name]['total_loss'] += loss.item() / batch_size
                                dataset_stats[dataset_name]['total'] += 1
                                dataset_stats[dataset_name]['batch_count'] += 1 / batch_size
                                
                                if pred_val == label_val:
                                    dataset_stats[dataset_name]['correct'] += 1
                    
                    # æ›´æ–°è¿›åº¦æ¡
                    if show_progress and (batch_idx % 10 == 0 or batch_idx == len(val_loader) - 1):
                        current_accuracy = correct / total if total > 0 else 0
                        current_avg_loss = total_loss / batch_count
                        eval_pbar.set_postfix({
                            'loss': f'{current_avg_loss:.4f}',
                            'accuracy': f'{current_accuracy:.4f}',
                            'datasets': len(dataset_stats)
                        })
                
                except Exception as e:
                    if show_progress:
                        print(f"âŒ å¤šæ•°æ®é›†è¯„ä¼°æ‰¹æ¬¡ {batch_idx} å‡ºé”™: {e}")
                    continue
        
        # å…³é—­è¿›åº¦æ¡
        eval_pbar.close()
        
        # ğŸ”¥ å¼ºåˆ¶è¯„ä¼°ç»“æŸååŒæ­¥
        if is_distributed:
            try:
                dist.barrier()
                if current_rank == 0:
                    print("ğŸ”„ å¤šæ•°æ®é›†è¯„ä¼°ç»“æŸååˆ†å¸ƒå¼åŒæ­¥å®Œæˆ")
            except Exception as e:
                print(f"âš ï¸ å¤šæ•°æ®é›†è¯„ä¼°ç»“æŸååŒæ­¥å¤±è´¥: {e}")
        
        # è®¡ç®—æ•´ä½“æŒ‡æ ‡
        overall_loss = total_loss / batch_count if batch_count > 0 else 0
        overall_accuracy = correct / total if total > 0 else 0
        
        # æ„å»ºç»“æœå­—å…¸
        results = {
            'overall_loss': overall_loss,
            'overall_accuracy': overall_accuracy,
            'total_samples': total,
            'total_correct': correct,
            'dataset_metrics': {}
        }
        
        # è®¡ç®—æ¯ä¸ªæ•°æ®é›†çš„æŒ‡æ ‡
        for dataset_name, stats in dataset_stats.items():
            if stats['total'] > 0:
                dataset_loss = stats['total_loss'] / stats['batch_count'] if stats['batch_count'] > 0 else 0
                dataset_accuracy = stats['correct'] / stats['total']
                
                results['dataset_metrics'][dataset_name] = {
                    'loss': dataset_loss,
                    'accuracy': dataset_accuracy,
                    'samples': stats['total'],
                    'correct': stats['correct']
                }
        
        # åªåœ¨ä¸»è¿›ç¨‹æ‰“å°ç»“æœ
        if current_rank == 0:
            print(f"\nğŸ“Š å¤šæ•°æ®é›†è¯„ä¼°å®Œæˆ:")
            print(f"  æ•´ä½“æŸå¤±: {overall_loss:.4f}")
            print(f"  æ•´ä½“å‡†ç¡®ç‡: {overall_accuracy:.4f}")
            print(f"  æ•°æ®é›†æ•°é‡: {len(dataset_stats)}")
        
        return results
        
    except Exception as eval_e:
        # ğŸ”¥ è¯„ä¼°å¼‚å¸¸å¤„ç†
        if current_rank == 0:
            print(f"âŒ å¤šæ•°æ®é›†è¯„ä¼°è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {eval_e}")
        
        # å°è¯•åŒæ­¥æ‰€æœ‰è¿›ç¨‹ï¼Œé¿å…æ­»é”
        if is_distributed:
            try:
                dist.barrier()
                if current_rank == 0:
                    print("ğŸ”„ å¤šæ•°æ®é›†è¯„ä¼°å¼‚å¸¸ååˆ†å¸ƒå¼åŒæ­¥å®Œæˆ")
            except:
                if current_rank == 0:
                    print("âš ï¸ å¤šæ•°æ®é›†è¯„ä¼°å¼‚å¸¸ååŒæ­¥ä¹Ÿå¤±è´¥")
        
        return {}


def evaluate_single_dataset_fast(model, val_loader, device) -> Tuple[float, float]:
    """ä¼˜åŒ–çš„å•æ•°æ®é›†è¯„ä¼°å‡½æ•° - å¢å¼ºåˆ†å¸ƒå¼æ”¯æŒ"""
    import torch.distributed as dist
    import signal
    
    # æ£€æŸ¥åˆ†å¸ƒå¼çŠ¶æ€
    is_distributed = dist.is_available() and dist.is_initialized()
    if is_distributed:
        current_rank = dist.get_rank()
        # ğŸ”¥ å¼ºåˆ¶è¯„ä¼°å¼€å§‹å‰åŒæ­¥
        try:
            dist.barrier()
            if current_rank == 0:
                print("ğŸ”„ å¿«é€Ÿè¯„ä¼°å¼€å§‹å‰åˆ†å¸ƒå¼åŒæ­¥å®Œæˆ")
        except Exception as e:
            print(f"âŒ å¿«é€Ÿè¯„ä¼°å¼€å§‹å‰åŒæ­¥å¤±è´¥: {e}")
            return 999.0, 0.0
    else:
        current_rank = 0
    
    # ğŸ”¥ è®¾ç½®è¯„ä¼°è¶…æ—¶ä¿æŠ¤
    def timeout_handler(signum, frame):
        raise TimeoutError("å¿«é€Ÿè¯„ä¼°è¿‡ç¨‹è¶…æ—¶")
    
    timeout_set = False
    if current_rank == 0:
        try:
            signal.signal(signal.SIGALRM, timeout_handler)
            signal.alarm(300)  # 5åˆ†é’Ÿè¶…æ—¶
            timeout_set = True
        except:
            pass
    
    try:
        # ç¡®ä¿æ¨¡å‹å¤„äºè¯„ä¼°æ¨¡å¼
        model.eval()
        if hasattr(model, 'module'):
            model.module.eval()
        
        total_loss = 0
        correct = 0
        total = 0
        batch_count = 0
        
        # ğŸ”¥ ä¼˜åŒ–ï¼šå‡å°‘è¿›åº¦æ¡æ›´æ–°é¢‘ç‡ï¼Œåªåœ¨ä¸»è¿›ç¨‹æ˜¾ç¤º
        show_progress = not is_distributed or current_rank == 0
        eval_pbar = tqdm(val_loader, desc="Evaluating", leave=False, disable=not show_progress)
        
        with torch.no_grad():
            for batch_idx, batch in enumerate(eval_pbar):
                try:
                    batch_count += 1
                    
                    # ğŸ”¥ æ¯20ä¸ªbatchè¿›è¡ŒåŒæ­¥æ£€æŸ¥
                    if is_distributed and batch_idx % 20 == 0:
                        try:
                            dist.barrier()
                        except Exception as sync_e:
                            if current_rank == 0:
                                print(f"âš ï¸ ç¬¬{batch_idx}æ‰¹æ¬¡åŒæ­¥å¤±è´¥: {sync_e}")
                    
                    # ç§»åŠ¨æ•°æ®åˆ°è®¾å¤‡ - ä½¿ç”¨non_blockingåŠ é€Ÿ
                    inputs = batch["input_ids"].to(device, non_blocking=True)
                    attention_mask = batch["attention_mask"].to(device, non_blocking=True)
                    pixel_values = batch["pixel_values"].to(device, non_blocking=True)
                    labels = batch["labels"].to(device, non_blocking=True)
                    
                    # å‰å‘ä¼ æ’­
                    forward_kwargs = {
                        "input_ids": inputs,
                        "attention_mask": attention_mask,
                        "pixel_values": pixel_values,
                        "labels": labels
                    }
                    
                    # æ£€æŸ¥å¹¶æ·»åŠ image_grid_thwå‚æ•°
                    if "image_grid_thw" in batch:
                        forward_kwargs["image_grid_thw"] = batch["image_grid_thw"].to(device, non_blocking=True)
                    
                    outputs = model(**forward_kwargs)
                    
                    # è®¡ç®—æŸå¤±å’Œå‡†ç¡®ç‡
                    loss = outputs.loss
                    predictions = torch.argmax(outputs.logits, dim=-1)
                    
                    # æ›´æ–°ç»Ÿè®¡
                    total_loss += loss.item()
                    correct += (predictions == labels).sum().item()
                    total += labels.size(0)
                    
                    # ğŸ”¥ ä¼˜åŒ–ï¼šå¤§å¹…å‡å°‘è¿›åº¦æ¡æ›´æ–°é¢‘ç‡ï¼Œåªåœ¨å…³é”®æ­¥éª¤æ›´æ–°
                    if show_progress and (batch_idx % 100 == 0 or batch_idx == len(val_loader) - 1):
                        current_accuracy = correct / total if total > 0 else 0
                        current_avg_loss = total_loss / batch_count
                        eval_pbar.set_postfix({
                            'loss': f'{current_avg_loss:.4f}',
                            'accuracy': f'{current_accuracy:.4f}',
                            'samples': f'{total}'
                        })
                    
                except Exception as e:
                    if show_progress:
                        print(f"âŒ è¯„ä¼°æ‰¹æ¬¡ {batch_idx} å‡ºé”™: {e}")
                    continue
        
        # å…³é—­è¿›åº¦æ¡
        eval_pbar.close()
        
        # ğŸ”¥ å¼ºåˆ¶è¯„ä¼°ç»“æŸååŒæ­¥
        if is_distributed:
            try:
                dist.barrier()
                if current_rank == 0:
                    print("ğŸ”„ å¿«é€Ÿè¯„ä¼°ç»“æŸååˆ†å¸ƒå¼åŒæ­¥å®Œæˆ")
            except Exception as e:
                print(f"âš ï¸ å¿«é€Ÿè¯„ä¼°ç»“æŸååŒæ­¥å¤±è´¥: {e}")
        
        # ğŸ”¥ ä¼˜åŒ–ï¼šç®€åŒ–åˆ†å¸ƒå¼èšåˆï¼Œå‡å°‘é€šä¿¡å¼€é”€
        if is_distributed:
            # åªè¿›è¡Œä¸€æ¬¡èšåˆï¼Œé¿å…å¤šæ¬¡all_reduce
            total_loss_tensor = torch.tensor(total_loss, dtype=torch.float32, device=device)
            correct_tensor = torch.tensor(correct, dtype=torch.long, device=device) 
            total_tensor = torch.tensor(total, dtype=torch.long, device=device)
            
            # æ‰¹é‡èšåˆ
            tensors_to_reduce = [total_loss_tensor, correct_tensor, total_tensor]
            if batch_all_reduce(tensors_to_reduce, op=dist.ReduceOp.SUM):
                total_loss = total_loss_tensor.item()
                correct = correct_tensor.item()
                total = total_tensor.item()
        
        # è®¡ç®—æœ€ç»ˆç»“æœ
        avg_loss = total_loss / batch_count if batch_count > 0 else 0
        accuracy = correct / total if total > 0 else 0
        
        if current_rank == 0:
            print(f"ğŸ“Š å¿«é€Ÿè¯„ä¼°å®Œæˆ - æŸå¤±: {avg_loss:.4f}, å‡†ç¡®ç‡: {accuracy:.4f}")
        
        return avg_loss, accuracy
        
    except Exception as eval_e:
        # ğŸ”¥ è¯„ä¼°å¼‚å¸¸å¤„ç†
        if current_rank == 0:
            print(f"âŒ å¿«é€Ÿè¯„ä¼°è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {eval_e}")
        
        # å°è¯•åŒæ­¥æ‰€æœ‰è¿›ç¨‹ï¼Œé¿å…æ­»é”
        if is_distributed:
            try:
                dist.barrier()
                if current_rank == 0:
                    print("ğŸ”„ å¿«é€Ÿè¯„ä¼°å¼‚å¸¸ååˆ†å¸ƒå¼åŒæ­¥å®Œæˆ")
            except:
                if current_rank == 0:
                    print("âš ï¸ å¿«é€Ÿè¯„ä¼°å¼‚å¸¸ååŒæ­¥ä¹Ÿå¤±è´¥")
        
        # è¿”å›é”™è¯¯æ ‡è¯†
        return 999.0, 0.0
        
    finally:
        # ğŸ”¥ æ¸…ç†è¶…æ—¶è®¾ç½®
        if timeout_set and current_rank == 0:
            try:
                signal.alarm(0)
            except:
                pass 