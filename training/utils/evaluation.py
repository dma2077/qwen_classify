import torch
import time
from typing import Dict, Tuple
from tqdm import tqdm
from collections import defaultdict
from .distributed import safe_all_reduce, safe_barrier, batch_all_reduce

def evaluate_model(model, val_loader, device) -> Tuple[float, float]:
    """è¯„ä¼°æ¨¡åž‹æ€§èƒ½ - åœ¨åˆ†å¸ƒå¼çŽ¯å¢ƒä¸‹æ­£ç¡®èšåˆæ‰€æœ‰GPUçš„ç»“æžœ"""
    import torch.distributed as dist
    
    # ðŸ”¥ ç¡®ä¿æ¨¡åž‹å¤„äºŽè¯„ä¼°æ¨¡å¼ - å…¼å®¹DeepSpeedåŒ…è£…
    model.eval()
    if hasattr(model, 'module'):
        model.module.eval()
        print(f"ðŸ” è®¾ç½®DeepSpeedåŒ…è£…æ¨¡åž‹ä¸ºevalæ¨¡å¼: model.training={model.training}, model.module.training={model.module.training}")
    else:
        print(f"ðŸ” è®¾ç½®æ¨¡åž‹ä¸ºevalæ¨¡å¼: model.training={model.training}")
    
    total_loss = 0
    correct = 0
    total = 0
    
    # æ£€æŸ¥åˆ†å¸ƒå¼çŠ¶æ€
    is_distributed = dist.is_available() and dist.is_initialized()
    if is_distributed:
        current_rank = dist.get_rank()
    else:
        current_rank = 0
    
    # åªåœ¨ä¸»è¿›ç¨‹æ˜¾ç¤ºè¿›åº¦æ¡
    show_progress = not is_distributed or current_rank == 0
    eval_pbar = tqdm(val_loader, desc="Evaluating", leave=False, disable=not show_progress)
    
    batch_count = 0
    
    with torch.no_grad():
        for batch_idx, batch in enumerate(eval_pbar):
            try:
                batch_count += 1
                
                # ç§»åŠ¨æ•°æ®åˆ°è®¾å¤‡
                inputs = batch["input_ids"].to(device)
                attention_mask = batch["attention_mask"].to(device)
                pixel_values = batch["pixel_values"].to(device)
                labels = batch["labels"].to(device)
                
                # å‰å‘ä¼ æ’­
                forward_kwargs = {
                    "input_ids": inputs,
                    "attention_mask": attention_mask,
                    "pixel_values": pixel_values,
                    "labels": labels
                }
                
                # æ£€æŸ¥å¹¶æ·»åŠ image_grid_thwå‚æ•°
                if "image_grid_thw" in batch:
                    forward_kwargs["image_grid_thw"] = batch["image_grid_thw"].to(device)
                
                outputs = model(**forward_kwargs)
                
                # è®¡ç®—æŸå¤±
                loss = outputs.loss
                total_loss += loss.item()
                
                # è®¡ç®—å‡†ç¡®çŽ‡
                predictions = torch.argmax(outputs.logits, dim=-1)
                correct += (predictions == labels).sum().item()
                total += labels.size(0)
                
                # æ¯10æ­¥æˆ–æœ€åŽä¸€æ­¥æ›´æ–°è¿›åº¦æ¡æ˜¾ç¤º
                if show_progress and (batch_idx % 10 == 0 or batch_idx == len(val_loader) - 1):
                    current_accuracy = correct / total if total > 0 else 0
                    current_avg_loss = total_loss / batch_count
                    eval_pbar.set_postfix({
                        'loss': f'{loss.item():.4f}',
                        'avg_loss': f'{current_avg_loss:.4f}',
                        'accuracy': f'{current_accuracy:.4f}',
                        'samples': f'{total}'
                    })
                
            except Exception as e:
                if show_progress:
                    print(f"âŒ è¯„ä¼°æ‰¹æ¬¡ {batch_idx} å‡ºé”™: {e}")
                    eval_pbar.set_postfix({'error': f'batch_{batch_idx}_failed'})
                continue
    
    # å…³é—­è¿›åº¦æ¡
    eval_pbar.close()
    
    # åœ¨åˆ†å¸ƒå¼çŽ¯å¢ƒä¸‹èšåˆæ‰€æœ‰GPUçš„ç»“æžœ
    if is_distributed:
        # è½¬æ¢ä¸ºtensorè¿›è¡Œèšåˆ
        total_loss_tensor = torch.tensor(total_loss, dtype=torch.float32, device=device)
        correct_tensor = torch.tensor(correct, dtype=torch.long, device=device) 
        total_tensor = torch.tensor(total, dtype=torch.long, device=device)
        batch_count_tensor = torch.tensor(batch_count, dtype=torch.long, device=device)
        
        # æ‰¹é‡èšåˆæ‰€æœ‰tensorï¼Œæé«˜æ•ˆçŽ‡
        tensors_to_reduce = [total_loss_tensor, correct_tensor, total_tensor, batch_count_tensor]
        if not batch_all_reduce(tensors_to_reduce, op=dist.ReduceOp.SUM):
            print("âš ï¸  æ‰¹é‡èšåˆå¤±è´¥ï¼Œä½¿ç”¨æœ¬åœ°ç»“æžœ")
            avg_loss = total_loss / batch_count if batch_count > 0 else 0
            accuracy = correct / total if total > 0 else 0
            return avg_loss, accuracy
        
        # è®¡ç®—å…¨å±€å¹³å‡å€¼
        global_avg_loss = total_loss_tensor.item() / batch_count_tensor.item() if batch_count_tensor.item() > 0 else 0
        global_accuracy = correct_tensor.item() / total_tensor.item() if total_tensor.item() > 0 else 0
        
        # åªåœ¨ä¸»è¿›ç¨‹æ‰“å°å…¨å±€ç»“æžœ
        if current_rank == 0:
            print("\n" + "="*80)
            print("ðŸ“Š éªŒè¯é›†è¯„ä¼°ç»“æžœ (å…¨å±€èšåˆ)")
            print("="*80)
            print(f"ðŸ“ˆ Average Loss:     {global_avg_loss:.6f}")
            print(f"ðŸŽ¯ Accuracy:         {global_accuracy:.4f} ({global_accuracy*100:.2f}%)")
            print(f"ðŸ“Š Total Samples:    {total_tensor.item():,}")
            print(f"âœ… Correct Samples:  {correct_tensor.item():,}")
            print(f"âŒ Wrong Samples:    {total_tensor.item() - correct_tensor.item():,}")
            print("="*80 + "\n")
        
        return global_avg_loss, global_accuracy
    else:
        # å•GPUæ¨¡å¼
        avg_loss = total_loss / batch_count if batch_count > 0 else 0
        accuracy = correct / total if total > 0 else 0
        print("\n" + "="*80)
        print("ðŸ“Š éªŒè¯é›†è¯„ä¼°ç»“æžœ")
        print("="*80)
        print(f"ðŸ“ˆ Average Loss:     {avg_loss:.6f}")
        print(f"ðŸŽ¯ Accuracy:         {accuracy:.4f} ({accuracy*100:.2f}%)")
        print(f"ðŸ“Š Total Samples:    {total:,}")
        print(f"âœ… Correct Samples:  {correct:,}")
        print(f"âŒ Wrong Samples:    {total - correct:,}")
        print("="*80 + "\n")
        return avg_loss, accuracy

def evaluate_multi_dataset(model, val_loader, device, dataset_configs=None) -> Dict:
    """
    å¤šæ•°æ®é›†è¯„ä¼°å‡½æ•°ï¼Œæ”¯æŒæŒ‰æ•°æ®é›†åˆ†åˆ«ç»Ÿè®¡æŒ‡æ ‡
    """
    import torch.distributed as dist
    
    # ðŸ”¥ ç¡®ä¿æ¨¡åž‹å¤„äºŽè¯„ä¼°æ¨¡å¼ - å…¼å®¹DeepSpeedåŒ…è£…
    model.eval()
    # æ£€æŸ¥åˆ†å¸ƒå¼çŠ¶æ€
    is_distributed = dist.is_available() and dist.is_initialized()
    if is_distributed:
        current_rank = dist.get_rank()
        world_size = dist.get_world_size()
    else:
        current_rank = 0
        world_size = 1
    
    # åªåœ¨ä¸»è¿›ç¨‹æ˜¾ç¤ºè¿›åº¦æ¡
    show_progress = not is_distributed or current_rank == 0
    eval_pbar = tqdm(val_loader, desc="Multi-Dataset Evaluation", leave=False, disable=not show_progress)
    
    # æ•´ä½“ç»Ÿè®¡
    total_loss = 0
    correct = 0
    total = 0
    batch_count = 0
    
    # æŒ‰æ•°æ®é›†ç»Ÿè®¡
    dataset_stats = defaultdict(lambda: {
        'total_loss': 0.0,
        'correct': 0,
        'total': 0,
        'batch_count': 0
    })
    
    with torch.no_grad():
        for batch_idx, batch in enumerate(eval_pbar):
            try:
                batch_count += 1
                
                # ç§»åŠ¨æ•°æ®åˆ°è®¾å¤‡
                inputs = batch["input_ids"].to(device)
                attention_mask = batch["attention_mask"].to(device)
                pixel_values = batch["pixel_values"].to(device)
                labels = batch["labels"].to(device)
                
                # èŽ·å–æ•°æ®é›†ä¿¡æ¯
                dataset_names = batch.get("dataset_names", [])
                num_classes_list = batch.get("num_classes_list", [])
                
                # å‰å‘ä¼ æ’­
                forward_kwargs = {
                    "input_ids": inputs,
                    "attention_mask": attention_mask,
                    "pixel_values": pixel_values,
                    "labels": labels
                }
                
                # æ£€æŸ¥å¹¶æ·»åŠ image_grid_thwå‚æ•°
                if "image_grid_thw" in batch:
                    forward_kwargs["image_grid_thw"] = batch["image_grid_thw"].to(device)
                
                # æ·»åŠ å¤šæ•°æ®é›†æ”¯æŒçš„å‚æ•°
                if dataset_names:
                    forward_kwargs["dataset_names"] = dataset_names
                if num_classes_list:
                    forward_kwargs["num_classes_list"] = num_classes_list
                
                outputs = model(**forward_kwargs)
                
                # è®¡ç®—æŸå¤±å’Œé¢„æµ‹
                loss = outputs.loss
                predictions = torch.argmax(outputs.logits, dim=-1)
                
                # æ›´æ–°æ•´ä½“ç»Ÿè®¡
                total_loss += loss.item()
                correct += (predictions == labels).sum().item()
                total += labels.size(0)
                
                # æ›´æ–°å„æ•°æ®é›†ç»Ÿè®¡
                for i, dataset_name in enumerate(dataset_names):
                    if i >= len(labels) or i >= len(predictions):
                        continue
                        
                    label = labels[i].item()
                    pred = predictions[i].item()
                    
                    dataset_stats[dataset_name]['total_loss'] += loss.item() / len(dataset_names)
                    dataset_stats[dataset_name]['total'] += 1
                    dataset_stats[dataset_name]['batch_count'] += 1
                    
                    if pred == label:
                        dataset_stats[dataset_name]['correct'] += 1
                
                # æ¯10æ­¥æˆ–æœ€åŽä¸€æ­¥æ›´æ–°è¿›åº¦æ¡æ˜¾ç¤º
                if show_progress and (batch_idx % 10 == 0 or batch_idx == len(val_loader) - 1):
                    current_accuracy = correct / total if total > 0 else 0
                    current_avg_loss = total_loss / batch_count
                    eval_pbar.set_postfix({
                        'loss': f'{loss.item():.4f}',
                        'avg_loss': f'{current_avg_loss:.4f}',
                        'accuracy': f'{current_accuracy:.4f}',
                        'datasets': f'{len(dataset_stats)}'
                    })
                
            except Exception as e:
                if show_progress:
                    print(f"âŒ å¤šæ•°æ®é›†è¯„ä¼°æ‰¹æ¬¡ {batch_idx} å‡ºé”™: {e}")
                    eval_pbar.set_postfix({'error': f'batch_{batch_idx}_failed'})
                continue
    
    # å…³é—­è¿›åº¦æ¡
    eval_pbar.close()
    
    # åœ¨åˆ†å¸ƒå¼çŽ¯å¢ƒä¸‹èšåˆç»“æžœ
    if is_distributed:
        # èšåˆæ•´ä½“ç»Ÿè®¡
        total_loss_tensor = torch.tensor(total_loss, dtype=torch.float32, device=device)
        correct_tensor = torch.tensor(correct, dtype=torch.long, device=device) 
        total_tensor = torch.tensor(total, dtype=torch.long, device=device)
        batch_count_tensor = torch.tensor(batch_count, dtype=torch.long, device=device)
        
        overall_tensors = [total_loss_tensor, correct_tensor, total_tensor, batch_count_tensor]
        
        if batch_all_reduce(overall_tensors, op=dist.ReduceOp.SUM):
            # ä½¿ç”¨èšåˆåŽçš„ç»“æžœ
            total_loss = total_loss_tensor.item()
            correct = correct_tensor.item()
            total = total_tensor.item()
            batch_count = batch_count_tensor.item()
        else:
            if show_progress:
                print("âš ï¸  æ•´ä½“ç»Ÿè®¡èšåˆå¤±è´¥ï¼Œä½¿ç”¨æœ¬åœ°ç»“æžœ")
        
        # èšåˆæ•°æ®é›†ç‰¹å®šç»Ÿè®¡
        if dataset_stats:
            aggregated_dataset_stats = {}
            for dataset_name, stats in dataset_stats.items():
                # åˆ›å»ºtensorå¹¶å°è¯•èšåˆ
                dataset_tensors = [
                    torch.tensor(stats['total_loss'], dtype=torch.float32, device=device),
                    torch.tensor(stats['correct'], dtype=torch.long, device=device),
                    torch.tensor(stats['total'], dtype=torch.long, device=device),
                    torch.tensor(stats['batch_count'], dtype=torch.long, device=device)
                ]
                
                if batch_all_reduce(dataset_tensors, op=dist.ReduceOp.SUM):
                    aggregated_dataset_stats[dataset_name] = {
                        'total_loss': dataset_tensors[0].item(),
                        'correct': dataset_tensors[1].item(),
                        'total': dataset_tensors[2].item(),
                        'batch_count': dataset_tensors[3].item()
                    }
                else:
                    # èšåˆå¤±è´¥ï¼Œä½¿ç”¨æœ¬åœ°ç»Ÿè®¡
                    aggregated_dataset_stats[dataset_name] = stats
            
            dataset_stats = aggregated_dataset_stats
    
    # è®¡ç®—ç»“æžœ
    overall_avg_loss = total_loss / batch_count if batch_count > 0 else 0
    overall_accuracy = correct / total if total > 0 else 0
    
    # è®¡ç®—å„æ•°æ®é›†çš„æŒ‡æ ‡
    dataset_metrics = {}
    for dataset_name, stats in dataset_stats.items():
        if stats['total'] > 0:
            avg_loss = stats['total_loss'] / stats['batch_count'] if stats['batch_count'] > 0 else 0
            accuracy = stats['correct'] / stats['total']
            dataset_metrics[dataset_name] = {
                'loss': avg_loss,
                'accuracy': accuracy,
                'samples': stats['total'],
                'correct': stats['correct']
            }
    
    # è¾“å‡ºç»“æžœï¼ˆåªåœ¨ä¸»è¿›ç¨‹è¾“å‡ºï¼‰
    if show_progress:
        print("\n" + "="*80)
        print("ðŸ“Š å¤šæ•°æ®é›†è¯„ä¼°ç»“æžœ")
        if is_distributed:
            print(f"   (åˆ†å¸ƒå¼èšåˆç»“æžœ, world_size={world_size})")
        print("="*80)
        print(f"ðŸ“ˆ Overall Loss:     {overall_avg_loss:.6f}")
        print(f"ðŸŽ¯ Overall Accuracy: {overall_accuracy:.4f} ({overall_accuracy*100:.2f}%)")
        print(f"ðŸ“Š Total Samples:    {total:,}")
        print(f"âœ… Total Correct:    {correct:,}")
        print()
        
        for dataset_name, metrics in dataset_metrics.items():
            print(f"ðŸ“‚ {dataset_name}:")
            print(f"  â€¢ Loss:     {metrics['loss']:.6f}")
            print(f"  â€¢ Accuracy: {metrics['accuracy']:.4f} ({metrics['accuracy']*100:.2f}%)")
            print(f"  â€¢ Samples:  {metrics['samples']:,} (Correct: {metrics['correct']:,})")
            
        print("="*80 + "\n")
    
    return {
        'overall_loss': overall_avg_loss,
        'overall_accuracy': overall_accuracy,
        'dataset_metrics': dataset_metrics,
        'total_samples': total,
        'total_correct': correct
    } 

def evaluate_single_dataset_fast(model, val_loader, device) -> Tuple[float, float]:
    """ä¼˜åŒ–çš„å•æ•°æ®é›†è¯„ä¼°å‡½æ•° - å¤§å¹…æå‡é€Ÿåº¦"""
    import torch.distributed as dist
    
    # ç¡®ä¿æ¨¡åž‹å¤„äºŽè¯„ä¼°æ¨¡å¼
    model.eval()
    if hasattr(model, 'module'):
        model.module.eval()
    
    total_loss = 0
    correct = 0
    total = 0
    batch_count = 0
    
    # æ£€æŸ¥åˆ†å¸ƒå¼çŠ¶æ€
    is_distributed = dist.is_available() and dist.is_initialized()
    if is_distributed:
        current_rank = dist.get_rank()
    else:
        current_rank = 0
    
    # ðŸ”¥ ä¼˜åŒ–ï¼šå‡å°‘è¿›åº¦æ¡æ›´æ–°é¢‘çŽ‡ï¼Œåªåœ¨ä¸»è¿›ç¨‹æ˜¾ç¤º
    show_progress = not is_distributed or current_rank == 0
    eval_pbar = tqdm(val_loader, desc="Evaluating", leave=False, disable=not show_progress)
    
    with torch.no_grad():
        for batch_idx, batch in enumerate(eval_pbar):
            try:
                batch_count += 1
                
                # ç§»åŠ¨æ•°æ®åˆ°è®¾å¤‡ - ä½¿ç”¨non_blockingåŠ é€Ÿ
                inputs = batch["input_ids"].to(device, non_blocking=True)
                attention_mask = batch["attention_mask"].to(device, non_blocking=True)
                pixel_values = batch["pixel_values"].to(device, non_blocking=True)
                labels = batch["labels"].to(device, non_blocking=True)
                
                # å‰å‘ä¼ æ’­
                forward_kwargs = {
                    "input_ids": inputs,
                    "attention_mask": attention_mask,
                    "pixel_values": pixel_values,
                    "labels": labels
                }
                
                # æ£€æŸ¥å¹¶æ·»åŠ image_grid_thwå‚æ•°
                if "image_grid_thw" in batch:
                    forward_kwargs["image_grid_thw"] = batch["image_grid_thw"].to(device, non_blocking=True)
                
                outputs = model(**forward_kwargs)
                
                # è®¡ç®—æŸå¤±å’Œå‡†ç¡®çŽ‡
                loss = outputs.loss
                predictions = torch.argmax(outputs.logits, dim=-1)
                
                # æ›´æ–°ç»Ÿè®¡
                total_loss += loss.item()
                correct += (predictions == labels).sum().item()
                total += labels.size(0)
                
                # ðŸ”¥ ä¼˜åŒ–ï¼šå¤§å¹…å‡å°‘è¿›åº¦æ¡æ›´æ–°é¢‘çŽ‡ï¼Œåªåœ¨å…³é”®æ­¥éª¤æ›´æ–°
                if show_progress and (batch_idx % 100 == 0 or batch_idx == len(val_loader) - 1):
                    current_accuracy = correct / total if total > 0 else 0
                    current_avg_loss = total_loss / batch_count
                    eval_pbar.set_postfix({
                        'loss': f'{current_avg_loss:.4f}',
                        'accuracy': f'{current_accuracy:.4f}',
                        'samples': f'{total}'
                    })
                
            except Exception as e:
                if show_progress:
                    print(f"âŒ è¯„ä¼°æ‰¹æ¬¡ {batch_idx} å‡ºé”™: {e}")
                continue
    
    # å…³é—­è¿›åº¦æ¡
    eval_pbar.close()
    
    # ðŸ”¥ ä¼˜åŒ–ï¼šç®€åŒ–åˆ†å¸ƒå¼èšåˆï¼Œå‡å°‘é€šä¿¡å¼€é”€
    if is_distributed:
        # åªè¿›è¡Œä¸€æ¬¡èšåˆï¼Œé¿å…å¤šæ¬¡all_reduce
        total_loss_tensor = torch.tensor(total_loss, dtype=torch.float32, device=device)
        correct_tensor = torch.tensor(correct, dtype=torch.long, device=device) 
        total_tensor = torch.tensor(total, dtype=torch.long, device=device)
        
        # æ‰¹é‡èšåˆ
        tensors_to_reduce = [total_loss_tensor, correct_tensor, total_tensor]
        if batch_all_reduce(tensors_to_reduce, op=dist.ReduceOp.SUM):
            total_loss = total_loss_tensor.item()
            correct = correct_tensor.item()
            total = total_tensor.item()
        
        # åªåœ¨ä¸»è¿›ç¨‹è¾“å‡ºç»“æžœ
        if current_rank == 0:
            avg_loss = total_loss / batch_count if batch_count > 0 else 0
            accuracy = correct / total if total > 0 else 0
            print(f"\nðŸ“Š è¯„ä¼°ç»“æžœ: Loss={avg_loss:.4f}, Accuracy={accuracy:.4f} ({accuracy*100:.2f}%)")
        
        return total_loss / batch_count if batch_count > 0 else 0, correct / total if total > 0 else 0
    else:
        # å•GPUæ¨¡å¼
        avg_loss = total_loss / batch_count if batch_count > 0 else 0
        accuracy = correct / total if total > 0 else 0
        print(f"\nðŸ“Š è¯„ä¼°ç»“æžœ: Loss={avg_loss:.4f}, Accuracy={accuracy:.4f} ({accuracy*100:.2f}%)")
        return avg_loss, accuracy 