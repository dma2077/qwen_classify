import os
import time
import json
import torch
import deepspeed
from tqdm import tqdm
from transformers import AutoProcessor
from collections import defaultdict
from .utils.model_utils import save_hf_model
from .utils.distributed import DistributedContext
from .utils.evaluation import evaluate_multi_dataset
from .utils.monitor import TrainingMonitor, make_json_serializable
from data.dataloader import create_full_eval_dataloader

# æ–°å¢å¯¼å…¥
from .utils.flops_calculate import MFUStats

class DeepSpeedTrainer:
    def __init__(self, config):
        # å‡è®¾é…ç½®å·²ç»é€šè¿‡prepare_configå¤„ç†è¿‡
        self.config = config
        
        # ğŸ”¥ ä¿®å¤ï¼šè®¾ç½®ç«¯å£é…ç½®ï¼Œé¿å…ç«¯å£å†²çª
        import os
        if 'MASTER_PORT' not in os.environ:
            os.environ['MASTER_PORT'] = '29501'  # ä½¿ç”¨29501ç«¯å£ï¼Œé¿å…29500å†²çª
        if 'MASTER_ADDR' not in os.environ:
            os.environ['MASTER_ADDR'] = 'localhost'
        
        self.dist_ctx = DistributedContext()
        
        # è®¾ç½®NCCLè¶…æ—¶ä¿æŠ¤ï¼ˆåœ¨åˆ†å¸ƒå¼è®­ç»ƒæ—¶ï¼‰
        if self.dist_ctx.world_size > 1:
            from .utils.distributed import setup_nccl_timeout_env
            setup_nccl_timeout_env()
            if self.dist_ctx.is_main_process:
                print("âœ… å·²è®¾ç½®NCCLè¶…æ—¶ä¿æŠ¤")
        
        # å†…å­˜ä¼˜åŒ–é…ç½®
        self.enable_gradient_checkpointing = config.get('training', {}).get('gradient_checkpointing', True)
        
        # åªåœ¨ä¸»è¿›ç¨‹åˆ›å»ºå®Œæ•´çš„TrainingMonitorï¼Œéä¸»è¿›ç¨‹ä½¿ç”¨DummyMonitor
        if self.dist_ctx.is_main_process:
            from training.utils.monitor import TrainingMonitor
            # ä¸å†ç¡¬ç¼–ç flops_profile_freqï¼Œè®©TrainingMonitorä»é…ç½®æ–‡ä»¶ä¸­è¯»å–
            self.monitor = TrainingMonitor(self.config['output_dir'], config)
        else:
            from training.utils.monitor import DummyMonitor  
            self.monitor = DummyMonitor(self.config['output_dir'], config)
        
        self.model = None
        self.train_loader = None
        self.val_loader = None
        self.optimizer = None
        self.lr_scheduler = None
        self.current_step = 0
        self.current_epoch = 0
        
        # å¤šæ•°æ®é›†æ”¯æŒ
        self.dataset_configs = self.config.get('datasets', {}).get('dataset_configs', {})
        self.enable_dataset_metrics = self.config.get('wandb', {}).get('log_dataset_metrics', True)
        
        # ç”¨äºè·Ÿè¸ªå„æ•°æ®é›†çš„æŒ‡æ ‡
        self.dataset_metrics = defaultdict(lambda: {
            'total_loss': 0.0,
            'total_samples': 0,
            'correct_samples': 0,
            'step_count': 0
        })
        
        # æœ€ä½³æ¨¡å‹è¿½è¸ª
        self.best_model_config = self.config.get('training', {}).get('best_model_tracking', {})
        self.best_model_enabled = self.best_model_config.get('enabled', True)
        self.best_metric_name = self.best_model_config.get('metric', 'overall_accuracy')
        self.best_metric_mode = self.best_model_config.get('mode', 'max')  # 'max' or 'min'
        self.save_best_only = self.best_model_config.get('save_best_only', True)
        
        # åˆå§‹åŒ–æœ€ä½³æŒ‡æ ‡
        if self.best_metric_mode == 'max':
            self.best_metric_value = float('-inf')
        else:
            self.best_metric_value = float('inf')
        
        self.best_model_step = 0
        self.best_model_path = None
        
        # è¯„ä¼°é…ç½®
        self.eval_config = self.config.get('training', {}).get('evaluation', {})
        self.partial_eval_during_training = self.eval_config.get('partial_eval_during_training', True)
        self.full_eval_at_end = self.eval_config.get('full_eval_at_end', True)
        self.eval_best_model_only = self.eval_config.get('eval_best_model_only', True)
        
        # ç¼“å­˜MFUè®¡ç®—ç»“æœï¼Œé¿å…é‡å¤è®¡ç®—
        self._mfu_cache = {}
        
        # æ–°å¢ï¼šåˆå§‹åŒ–MFUç»Ÿè®¡å™¨ï¼Œæ›¿æ¢Profiler-basedçš„MFUè®¡ç®—
        self.mfu_stats = None  # å»¶è¿Ÿåˆå§‹åŒ–ï¼Œç­‰è·å–åˆ°æ¨¡å‹é…ç½®è·¯å¾„åå†åˆå§‹åŒ–
        
        # ğŸ”¥ æ–°å¢ï¼šæ€§èƒ½ç›‘æ§
        self.performance_stats = {
            'total_training_time': 0.0,
            'total_eval_time': 0.0,
            'memory_usage': [],
            'gpu_utilization': []
        }
        
    def setup_model(self, model, train_loader, val_loader, optimizer=None, lr_scheduler=None):
        """è®¾ç½®æ¨¡å‹å’Œç›¸å…³ç»„ä»¶"""
        self.model = model
        self.train_loader = train_loader
        self.val_loader = val_loader
        
        # ğŸ”¥ æ–°å¢ï¼šåº”ç”¨å†…å­˜ä¼˜åŒ–è®¾ç½®
        self._apply_memory_optimizations()
        
        # åˆ›å»ºä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨ï¼ˆå¦‚æœæœªæä¾›ï¼‰
        if optimizer is None:
            from optimizer.optimizer import create_optimizer
            optimizer = create_optimizer(model, self.config)
        
        if lr_scheduler is None:
            from training.lr_scheduler import create_lr_scheduler
            # è®¡ç®—steps_per_epoch - åŸºäºæ€»æ‰¹æ¬¡å¤§å°
            deepspeed_config = self._get_deepspeed_config()
            train_batch_size = deepspeed_config.get('train_batch_size', 256)
            dataset_size = len(train_loader.dataset)
            steps_per_epoch = dataset_size // train_batch_size
            if dataset_size % train_batch_size != 0:
                steps_per_epoch += 1  # å‘ä¸Šå–æ•´
            lr_scheduler = create_lr_scheduler(optimizer, self.config, steps_per_epoch)
        
        # è·å–DeepSpeedé…ç½®
        deepspeed_config = self._get_deepspeed_config()
        
        # åˆå§‹åŒ–DeepSpeed
        self.model, self.optimizer, _, self.lr_scheduler = deepspeed.initialize(
            model=model,
            optimizer=optimizer,
            lr_scheduler=lr_scheduler,
            config=deepspeed_config
        )
        
        if self.dist_ctx.is_main_process:
            print(f"âœ… æ¨¡å‹åˆå§‹åŒ–å®Œæˆ")
        
        # è®¾ç½®monitorçš„modelå¼•ç”¨ç”¨äºMFUè®¡ç®—
        self.monitor.set_model_ref(self.model)
        
    def _apply_memory_optimizations(self):
        """åº”ç”¨å†…å­˜ä¼˜åŒ–è®¾ç½®"""
        # 1. æ¢¯åº¦æ£€æŸ¥ç‚¹
        if self.enable_gradient_checkpointing:
            self.model.gradient_checkpointing_enable()
        
        # 2. æ¸…ç†GPUç¼“å­˜
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
    def _get_deepspeed_config(self):
        """è·å–DeepSpeedé…ç½®"""
        deepspeed_config_path = self.config.get('deepspeed', '')
        
        # éªŒè¯é…ç½®æ–‡ä»¶è·¯å¾„
        if not deepspeed_config_path:
            raise ValueError("DeepSpeedé…ç½®æ–‡ä»¶è·¯å¾„æœªè®¾ç½®")
        
        if not os.path.exists(deepspeed_config_path):
            raise FileNotFoundError(f"DeepSpeedé…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {deepspeed_config_path}")
        
        # åŠ è½½é…ç½®æ–‡ä»¶
        try:
            with open(deepspeed_config_path, 'r') as f:
                deepspeed_config = json.load(f)
        except Exception as e:
            raise ValueError(f"DeepSpeedé…ç½®æ–‡ä»¶è§£æå¤±è´¥: {e}")
        
        # éªŒè¯å¿…è¦å­—æ®µ
        required_fields = ['train_batch_size', 'train_micro_batch_size_per_gpu']
        missing_fields = [field for field in required_fields if field not in deepspeed_config]
        if missing_fields:
            raise ValueError(f"DeepSpeedé…ç½®æ–‡ä»¶ç¼ºå°‘å¿…è¦å­—æ®µ: {missing_fields}")
        
        # æ‰“å°é…ç½®ä¿¡æ¯ï¼ˆä»…ä¸»è¿›ç¨‹ï¼‰
        if self.dist_ctx.is_main_process:
            print(f"ğŸ”§ DeepSpeedé…ç½®: {deepspeed_config['train_micro_batch_size_per_gpu']} x {deepspeed_config.get('gradient_accumulation_steps', 1)} = {deepspeed_config['train_batch_size']}")
        
        return deepspeed_config
        
    def _calculate_training_stats(self):
        """è®¡ç®—è®­ç»ƒç»Ÿè®¡ä¿¡æ¯"""
        deepspeed_config = self._get_deepspeed_config()
        
        micro_batch_size_per_gpu = deepspeed_config.get('train_micro_batch_size_per_gpu', 1)
        gradient_accumulation_steps = deepspeed_config.get('gradient_accumulation_steps', 1)
        train_batch_size = deepspeed_config.get('train_batch_size', 32)
        
        dataset_size = len(self.train_loader.dataset)
        
        # æ­£ç¡®è®¡ç®—æ¯epochçš„æœ‰æ•ˆæ­¥æ•°ï¼šåŸºäºæ€»æ‰¹æ¬¡å¤§å°
        effective_steps_per_epoch = dataset_size // train_batch_size
        if dataset_size % train_batch_size != 0:
            effective_steps_per_epoch += 1  # å‘ä¸Šå–æ•´
        
        total_effective_steps = effective_steps_per_epoch * self.config['training']['num_epochs']
        
        # DataLoaderçš„æ­¥æ•°ï¼ˆç”¨äºè°ƒè¯•ä¿¡æ¯ï¼‰
        dataloader_steps_per_epoch = len(self.train_loader)
        samples_per_gpu = dataloader_steps_per_epoch * micro_batch_size_per_gpu
        
        return {
            'micro_batch_size_per_gpu': micro_batch_size_per_gpu,
            'gradient_accumulation_steps': gradient_accumulation_steps,
            'train_batch_size': train_batch_size,
            'dataloader_steps_per_epoch': dataloader_steps_per_epoch,
            'effective_steps_per_epoch': effective_steps_per_epoch,
            'total_effective_steps': total_effective_steps,
            'dataset_size': dataset_size,
            'samples_per_gpu': samples_per_gpu
        }
        
    def _print_training_config(self, stats):
        """æ‰“å°è®­ç»ƒé…ç½®ä¿¡æ¯"""
        if not self.dist_ctx.is_main_process:
            return
            
        print("ğŸš€ è®­ç»ƒé…ç½®:")
        print(f"  â€¢ æ•°æ®é›†: {stats['dataset_size']:,} æ ·æœ¬")
        print(f"  â€¢ æ‰¹æ¬¡: {stats['micro_batch_size_per_gpu']} x {stats['gradient_accumulation_steps']} = {stats['train_batch_size']}")
        print(f"  â€¢ æ­¥æ•°: {stats['effective_steps_per_epoch']:,} æ­¥/epoch, æ€»è®¡ {stats['total_effective_steps']:,} æ­¥")
        
    def _prepare_batch_data(self, batch):
        """å‡†å¤‡æ‰¹æ¬¡æ•°æ® - ä¼˜åŒ–ç‰ˆæœ¬"""
        # ğŸ”¥ ä¼˜åŒ–ï¼šä½¿ç”¨pin_memoryå’Œnon_blockingåŠ é€Ÿæ•°æ®ä¼ è¾“
        device = self.dist_ctx.device
        
        inputs = batch["input_ids"].to(device, non_blocking=True)
        attention_mask = batch["attention_mask"].to(device, non_blocking=True)
        pixel_values = batch["pixel_values"].to(device, non_blocking=True)
        labels = batch["labels"].to(device, non_blocking=True)
        
        forward_kwargs = {
            "input_ids": inputs,
            "attention_mask": attention_mask,
            "pixel_values": pixel_values,
            "labels": labels
        }
        
        # æ£€æŸ¥å¹¶æ·»åŠ image_grid_thwå‚æ•°
        if "image_grid_thw" in batch:
            forward_kwargs["image_grid_thw"] = batch["image_grid_thw"].to(device, non_blocking=True)
        
        # æ·»åŠ å¤šæ•°æ®é›†æ”¯æŒçš„å‚æ•°
        if "dataset_names" in batch:
            forward_kwargs["dataset_names"] = batch["dataset_names"]
        if "num_classes_list" in batch:
            forward_kwargs["num_classes_list"] = batch["num_classes_list"]
            
        return forward_kwargs, inputs, attention_mask, labels
        
    def _optimize_dataloader(self):
        """ä¼˜åŒ–æ•°æ®åŠ è½½å™¨è®¾ç½®"""
        # è®¾ç½®DataLoaderçš„ä¼˜åŒ–å‚æ•°
        if hasattr(self.train_loader, 'pin_memory'):
            self.train_loader.pin_memory = True
        
        if hasattr(self.train_loader, 'num_workers'):
            # æ ¹æ®CPUæ ¸å¿ƒæ•°ä¼˜åŒ–workeræ•°é‡
            import multiprocessing
            cpu_count = multiprocessing.cpu_count()
            optimal_workers = min(cpu_count, 16)  # æé«˜ä¸Šé™åˆ°16ä¸ªworkers
            self.train_loader.num_workers = optimal_workers
        
        # è®¾ç½®é¢„å–å› å­
        if hasattr(self.train_loader, 'prefetch_factor'):
            self.train_loader.prefetch_factor = 2
        
    def _init_mfu_stats(self):
        """åˆå§‹åŒ–MFUç»Ÿè®¡å™¨"""
        if self.mfu_stats is not None:
            return True
            
        try:
            # åˆ›å»ºargså¯¹è±¡ï¼ŒåŒ…å«MFUè®¡ç®—æ‰€éœ€çš„å‚æ•°
            import argparse
            args = argparse.Namespace()
            args.logging_per_step = self.config.get('logging_steps', 20)
            
            # æ™ºèƒ½æŸ¥æ‰¾æ¨¡å‹é…ç½®æ–‡ä»¶
            config_path = None
            possible_model_dirs = [
                self.config.get('model', {}).get('model_path', ''),
                self.config.get('model', {}).get('model_name_or_path', ''),
                self.config.get('output_dir', './output'),
                './models',
                './checkpoints',
                '.'
            ]
            
            # è¿‡æ»¤ç©ºè·¯å¾„
            possible_model_dirs = [path for path in possible_model_dirs if path]
            
            for model_dir in possible_model_dirs:
                if os.path.exists(model_dir):
                    test_config_path = os.path.join(model_dir, "config.json")
                    if os.path.exists(test_config_path):
                        config_path = test_config_path
                        args.model_dir = model_dir
                        break
            
            if config_path is None:
                if self.dist_ctx.is_main_process:
                    print(f"âš ï¸ æœªæ‰¾åˆ°æ¨¡å‹é…ç½®æ–‡ä»¶ config.json")
                    print("ğŸ“ æœç´¢è·¯å¾„:")
                    for path in possible_model_dirs:
                        if os.path.exists(path):
                            try:
                                files = os.listdir(path)
                                print(f"  - {path}: {files[:5]}{'...' if len(files) > 5 else ''}")
                            except:
                                print(f"  - {path}: æ— æ³•è®¿é—®")
                        else:
                            print(f"  - {path}: ä¸å­˜åœ¨")
                return False
            
            self.mfu_stats = MFUStats(args)
            if self.dist_ctx.is_main_process:
                print(f"âœ… MFUç»Ÿè®¡å™¨åˆå§‹åŒ–æˆåŠŸï¼Œä½¿ç”¨é…ç½®: {config_path}")
            return True
            
        except Exception as e:
            if self.dist_ctx.is_main_process:
                print(f"âŒ MFUç»Ÿè®¡å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
            return False
    
    def _collect_mfu_data(self, batch, inputs, attention_mask):
        """æ”¶é›†MFUè®¡ç®—æ‰€éœ€çš„æ•°æ®"""
        try:
            # è®¡ç®—å›¾åƒtokenæ•°é‡
            num_image_tokens = 0
            if "pixel_values" in batch and batch["pixel_values"] is not None:
                # ä¼°ç®—å›¾åƒtokenæ•°é‡ï¼Œæ ¹æ®å…·ä½“æ¨¡å‹å¯èƒ½éœ€è¦è°ƒæ•´
                pixel_values = batch["pixel_values"]
                if pixel_values.dim() >= 3:
                    # å‡è®¾æ¯å¼ å›¾åƒäº§ç”Ÿå›ºå®šæ•°é‡çš„tokenï¼Œè¿™é‡Œä½¿ç”¨å¸¸è§çš„é…ç½®
                    # å¯ä»¥æ ¹æ®å®é™…æ¨¡å‹é…ç½®è°ƒæ•´
                    batch_size = pixel_values.size(0)
                    # ä¸€èˆ¬VLMæ¨¡å‹æ¯å¼ å›¾åƒäº§ç”Ÿ256-1024ä¸ªtoken
                    tokens_per_image = 256  # è¿™ä¸ªå€¼å¯ä»¥æ ¹æ®å®é™…æ¨¡å‹è°ƒæ•´
                    num_image_tokens = batch_size * tokens_per_image
            
            # è·å–æ–‡æœ¬tokenæ•°é‡
            num_tokens = attention_mask.sum().item() if attention_mask is not None else inputs.numel()
            
            # æ ·æœ¬æ•°é‡
            num_samples = inputs.size(0)
            
            # å›¾åƒæ•°é‡
            num_images = batch.get("num_images", 0)
            if num_images == 0 and "pixel_values" in batch and batch["pixel_values"] is not None:
                num_images = batch["pixel_values"].size(0)
            
            # è°ƒç”¨MFUç»Ÿè®¡å™¨çš„setæ–¹æ³•
            self.mfu_stats.set(
                num_image_tokens=num_image_tokens,
                num_tokens=num_tokens,
                num_samples=num_samples,
                num_images=num_images
            )
            
        except Exception as e:
            if self.dist_ctx.is_main_process:
                print(f"âš ï¸ æ”¶é›†MFUæ•°æ®å¤±è´¥: {e}")
        
    def _build_training_metrics(self, effective_step, epoch, aggregated_loss, current_lr, grad_norm_value, 
                               inputs, attention_mask, step_time):
        """æ„å»ºè®­ç»ƒæŒ‡æ ‡"""
        training_data = {
            "training/loss": float(aggregated_loss),
            "training/lr": float(current_lr), 
            "training/epoch": float(epoch),
            "training/grad_norm": float(grad_norm_value),
            "step": int(effective_step)
        }
        
        # ğŸ”¥ ä¿®å¤ï¼šé™ä½æ€§èƒ½æŒ‡æ ‡è®°å½•é¢‘ç‡ï¼Œç¡®ä¿èƒ½çœ‹åˆ°perfæŒ‡æ ‡
        should_log_perf = (effective_step % 20 == 0)  # æ¯20æ­¥è®°å½•ä¸€æ¬¡æ€§èƒ½æŒ‡æ ‡
        
        if should_log_perf:
            if step_time > 0:
                training_data.update({
                    "perf/step_time": float(step_time),
                    "perf/steps_per_second": float(1.0 / step_time),
                })
                
                # ä½¿ç”¨æ–°çš„MFUè®¡ç®—æ–¹å¼
                if self.mfu_stats is not None:
                    try:
                        # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„æ•°æ®è¿›è¡ŒMFUè®¡ç®—
                        tokens_for_mfu = self.mfu_stats.tokens_for_mfu
                        has_sufficient_data = (
                            tokens_for_mfu["num_tokens"] > 0 and 
                            tokens_for_mfu["num_samples"] > 0 and
                            effective_step >= self.mfu_stats.args.logging_per_step
                        )
                        
                        if not has_sufficient_data:
                            if self.dist_ctx.is_main_process and effective_step % 50 == 0:
                                print(f"ğŸ”„ MFUæ•°æ®æ”¶é›†ä¸­ (step={effective_step}): "
                                      f"tokens={tokens_for_mfu['num_tokens']}, "
                                      f"samples={tokens_for_mfu['num_samples']}, "
                                      f"images={tokens_for_mfu['num_images']}")
                            return training_data
                        
                        # è·å–MFUæ—¥å¿—æ•°æ®
                        mfu_log_dict = self.mfu_stats.mfu(step_time, effective_step)
                        
                        # è°ƒè¯•ï¼šæ£€æŸ¥MFUæ•°æ®çš„å®Œæ•´æ€§
                        if self.dist_ctx.is_main_process and effective_step % 50 == 0:
                            print(f"ğŸ” MFUåŸå§‹æ•°æ® (step={effective_step}):")
                            for key, value in mfu_log_dict.items():
                                print(f"  {key}: {value}")
                        
                        # ç¡®ä¿æ‰€æœ‰MFUæŒ‡æ ‡éƒ½æ˜¯æœ‰æ•ˆçš„æ•°å€¼
                        valid_mfu_data = {}
                        for key, value in mfu_log_dict.items():
                            if isinstance(value, (int, float)) and not (isinstance(value, float) and (value != value or value == float('inf') or value == float('-inf'))):
                                valid_mfu_data[key] = float(value)
                            else:
                                if self.dist_ctx.is_main_process:
                                    print(f"âš ï¸ è·³è¿‡æ— æ•ˆMFUæŒ‡æ ‡: {key}={value}")
                        
                        training_data.update(valid_mfu_data)
                        
                        # æ·»åŠ é¢å¤–çš„æ€§èƒ½æŒ‡æ ‡
                        current_seq_length = attention_mask.sum(dim=1).float().mean().item() if attention_mask is not None else 0
                        actual_batch_size = inputs.size(0) * self.dist_ctx.world_size
                        
                        training_data.update({
                            "perf/tokens_per_second": float(actual_batch_size * current_seq_length / step_time),
                            "perf/samples_per_second": float(actual_batch_size / step_time),
                            "perf/actual_seq_length": float(current_seq_length),
                            "perf/actual_batch_size": float(actual_batch_size),
                        })
                        
                        if self.dist_ctx.is_main_process and effective_step % 100 == 0:
                            print(f"ğŸ“Š MFUæŒ‡æ ‡æ‘˜è¦ (step={effective_step}): "
                                  f"MFU={valid_mfu_data.get('perf/mfu_per_step_per_gpu', 0):.4f}, "
                                  f"VIT_FLOPs={valid_mfu_data.get('perf/vit_flops_per_step_per_gpu', 0):.2f}T, "
                                  f"LLM_FLOPs={valid_mfu_data.get('perf/llm_flops_per_step_per_gpu', 0):.2f}T")
                                  
                    except Exception as mfu_error:
                        if self.dist_ctx.is_main_process:
                            print(f"âš ï¸ MFUè®¡ç®—å¤±è´¥ (step={effective_step}): {mfu_error}")
                            import traceback
                            traceback.print_exc()
                else:
                    if self.dist_ctx.is_main_process and effective_step % 100 == 0:
                        print(f"âš ï¸ MFUç»Ÿè®¡å™¨æœªåˆå§‹åŒ– (step={effective_step})")
            else:
                # å¦‚æœæ­¥éª¤æ—¶é—´ä¸º0æˆ–è´Ÿæ•°ï¼Œè®°å½•è­¦å‘Š
                if self.dist_ctx.is_main_process:
                    print(f"âš ï¸ æ­¥éª¤æ—¶é—´å¼‚å¸¸ï¼Œè·³è¿‡æ€§èƒ½æŒ‡æ ‡è®°å½• (step={effective_step}, step_time={step_time})")
        else:
            # è°ƒè¯•ä¿¡æ¯ï¼šä¸ºä»€ä¹ˆè·³è¿‡æ€§èƒ½æŒ‡æ ‡
            if effective_step % 100 == 0:  # æ¯100æ­¥è¾“å‡ºä¸€æ¬¡
                print(f"â­ï¸  è·³è¿‡æ€§èƒ½æŒ‡æ ‡è®°å½• (step={effective_step}): é¢‘ç‡æ£€æŸ¥ {effective_step} % 20 != 0")
                
        # éªŒè¯MFUæŒ‡æ ‡æ˜¯å¦åŒ…å«åœ¨training_dataä¸­
        if self.dist_ctx.is_main_process and effective_step % 100 == 0:
            mfu_metrics = [k for k in training_data.keys() if 'mfu' in k.lower() or 'flops' in k.lower()]
            if mfu_metrics:
                print(f"âœ… MFUæŒ‡æ ‡å°†è®°å½•åˆ°WandB (step={effective_step}): {mfu_metrics}")
            else:
                print(f"âš ï¸ æœªæ‰¾åˆ°MFUæŒ‡æ ‡ (step={effective_step})")
                
        return training_data
        
    def _handle_effective_step(self, effective_step, epoch, batch_idx, aggregated_loss, current_lr, 
                              grad_norm_value, inputs, attention_mask, step_time, is_eval_step):
        """å¤„ç†æœ‰æ•ˆæ­¥éª¤çš„é€»è¾‘"""
        # é™ä½è¿›åº¦æ¡æ›´æ–°é¢‘ç‡ä»¥å‡å°‘å¼€é”€ï¼ˆæ¯10ä¸ªæœ‰æ•ˆæ­¥éª¤æ›´æ–°ä¸€æ¬¡ï¼‰
        if effective_step % 10 == 0:
            self._update_progress_bar(effective_step, aggregated_loss, current_lr, epoch, batch_idx)
        
        # è®°å½•è®­ç»ƒæŒ‡æ ‡åˆ°æœ¬åœ°æ—¥å¿—
        self.monitor.log_step(effective_step, epoch, aggregated_loss, grad_norm_value, current_lr, attention_mask, skip_wandb=is_eval_step)
        
        # ğŸ”¥ ä¿®å¤ï¼šç¡®ä¿æ‰€æœ‰æ­¥éª¤éƒ½è®°å½•trainingå’ŒperfæŒ‡æ ‡åˆ°WandB
        if self.dist_ctx.is_main_process:
            # æ£€æŸ¥æ˜¯å¦éœ€è¦è®°å½•trainingæŒ‡æ ‡
            should_log_training = (effective_step % self.monitor.freq['training_log_freq'] == 0)
            
            if should_log_training:
                training_data = self._build_training_metrics(effective_step, epoch, aggregated_loss, current_lr, 
                                                           grad_norm_value, inputs, attention_mask, step_time)
                
                # ğŸ”¥ ä¿®å¤ï¼šç®€åŒ–è®°å½•é€»è¾‘ï¼Œæ¯ä¸ªstepéƒ½è®°å½•å¹¶commit
                self.monitor.log_metrics(training_data, effective_step, commit=True)
                
                # æ·»åŠ è°ƒè¯•è¾“å‡º
                training_metrics_list = [k for k in training_data.keys() if k.startswith('training/')]
                perf_metrics_list = [k for k in training_data.keys() if k.startswith('perf/')]
                if training_metrics_list or perf_metrics_list:
                    print(f"ğŸ“Š TrainingæŒ‡æ ‡å·²è®°å½• (step={effective_step}): "
                          f"training={len(training_metrics_list)}, perf={len(perf_metrics_list)}")
                    if training_metrics_list:
                        print(f"   ğŸ“ˆ TrainingæŒ‡æ ‡: {training_metrics_list}")
                    if perf_metrics_list:
                        print(f"   âš¡ PerfæŒ‡æ ‡: {perf_metrics_list}")
            else:
                # è°ƒè¯•è¾“å‡ºï¼šæ˜¾ç¤ºä¸ºä»€ä¹ˆè·³è¿‡è®°å½•
                if effective_step % 100 == 0:  # æ¯100æ­¥è¾“å‡ºä¸€æ¬¡ï¼Œé¿å…æ—¥å¿—è¿‡å¤š
                    print(f"â­ï¸  è·³è¿‡trainingæŒ‡æ ‡è®°å½• (step={effective_step}): "
                          f"é¢‘ç‡={self.monitor.freq['training_log_freq']}")
                
    def _update_progress_bar(self, effective_step, aggregated_loss, current_lr, epoch, batch_idx):
        """æ›´æ–°è¿›åº¦æ¡"""
        if hasattr(self, 'pbar'):
            self.pbar.update(10)  # ä¸€æ¬¡æ›´æ–°10æ­¥
            self.pbar.set_postfix({
                'loss': f'{aggregated_loss:.4f}',
                'lr': f'{current_lr:.2e}',
                'epoch': f'{epoch + batch_idx/len(self.train_loader):.2f}'
            })
            
    def _handle_evaluation_step(self, effective_step, epoch, aggregated_loss, current_lr, grad_norm_value, 
                               inputs, attention_mask, step_time):
        """å¤„ç†è¯„ä¼°æ­¥éª¤"""
        # æš‚æ—¶åˆ·æ–°è¿›åº¦æ¡ä»¥é¿å…è¾“å‡ºå†²çª
        if hasattr(self, 'pbar'):
            self.pbar.clear()
        
        print(f"ğŸ” å¼€å§‹å¤„ç†è¯„ä¼°æ­¥éª¤ (step={effective_step})")
        
        # æ·»åŠ è¯„ä¼°å¼‚å¸¸å¤„ç†ï¼Œé¿å…NCCLè¶…æ—¶å¯¼è‡´è®­ç»ƒä¸­æ–­
        try:
            print(f"ğŸ”„ è°ƒç”¨evaluateæ–¹æ³•...")
            # è·å–evalæ•°æ®ä½†ä¸è®©evaluateæ–¹æ³•è®°å½•åˆ°wandb
            eval_loss, eval_accuracy, eval_results = self.evaluate(step=effective_step, log_to_wandb=False, return_results=True)
            
            print(f"âœ… Evaluateæ–¹æ³•å®Œæˆ: eval_loss={eval_loss:.4f}, eval_accuracy={eval_accuracy:.4f}")
            
            # æ„å»ºå®Œæ•´çš„trainingæ•°æ®ï¼ˆåŒ…æ‹¬æ€§èƒ½æŒ‡æ ‡ï¼‰
            current_training_data = self._build_training_metrics(effective_step, epoch, aggregated_loss, current_lr, 
                                                               grad_norm_value, inputs, attention_mask, step_time)
            
            # å‡†å¤‡evalæ•°æ®
            eval_data = self._build_eval_metrics(eval_loss, eval_accuracy, eval_results)
            
            print(f"ğŸ“Š æ„å»ºçš„evalæ•°æ®: {list(eval_data.keys())}")
            print(f"ğŸ“Š Evalæ•°æ®è¯¦æƒ…: {eval_data}")
            
            # ğŸ”¥ ä¿®å¤ï¼šç¡®ä¿evalæŒ‡æ ‡æ­£ç¡®è®°å½•åˆ°WandB
            if self.dist_ctx.is_main_process:
                print(f"ğŸ”§ å¼€å§‹è®°å½•evalæŒ‡æ ‡åˆ°WandB...")
                # è®°å½•evalæŒ‡æ ‡ï¼Œå¼ºåˆ¶commitç¡®ä¿æ•°æ®åŒæ­¥
                self.monitor.log_metrics(eval_data, effective_step, commit=True)
                
                # è¾“å‡ºè¯¦ç»†çš„è®°å½•ä¿¡æ¯
                eval_metrics_list = [k for k in eval_data.keys() if k.startswith('eval/')]
                
                print(f"âœ… EvalæŒ‡æ ‡å·²è®°å½•åˆ°WandB (step={effective_step})")
                print(f"   ğŸ“Š è®°å½•çš„evalæŒ‡æ ‡: {eval_metrics_list}")
                print(f"   ğŸ“ˆ æ•´ä½“å‡†ç¡®ç‡: {eval_accuracy:.4f}")
                print(f"   ğŸ“‰ æ•´ä½“æŸå¤±: {eval_loss:.6f}")
                print(f"   ğŸ”¢ evalæŒ‡æ ‡æ•°é‡: {len(eval_data)}")
                
                # éªŒè¯evalæŒ‡æ ‡è®°å½•
                if eval_metrics_list:
                    print(f"   âœ… EvalæŒ‡æ ‡è®°å½•æˆåŠŸ")
                else:
                    print(f"   âš ï¸ æ²¡æœ‰æ‰¾åˆ°evalæŒ‡æ ‡")
            else:
                print(f"âš ï¸ éä¸»è¿›ç¨‹ï¼Œè·³è¿‡evalæŒ‡æ ‡è®°å½•")
                
        except Exception as eval_error:
            if self.dist_ctx.is_main_process:
                print(f"âŒ è¯„ä¼°è¿‡ç¨‹å‡ºé”™: {eval_error}")
                print(f"   effective_step: {effective_step}")
                print(f"   epoch: {epoch}")
                print(f"   aggregated_loss: {aggregated_loss}")
                print(f"   current_lr: {current_lr}")
                print("âš ï¸  è·³è¿‡æœ¬æ¬¡è¯„ä¼°ï¼Œç»§ç»­è®­ç»ƒ...")
                import traceback
                traceback.print_exc()
            # è®°å½•ä¸€ä¸ªå ä½ç¬¦çš„evalç»“æœï¼Œé¿å…wandbå›¾è¡¨ä¸­æ–­
            self._log_placeholder_eval(effective_step, aggregated_loss, current_lr)
        
        self.model.train()
        # é‡æ–°æ˜¾ç¤ºè¿›åº¦æ¡
        if hasattr(self, 'pbar'):
            self.pbar.refresh()
            
    def _build_eval_metrics(self, eval_loss, eval_accuracy, eval_results):
        """æ„å»ºè¯„ä¼°æŒ‡æ ‡ - ç¡®ä¿åŒ…å«æ‰€æœ‰å¿…è¦çš„evalæŒ‡æ ‡"""
        eval_data = {
            "eval/overall_loss": float(eval_loss),
            "eval/overall_accuracy": float(eval_accuracy),
        }
        
        # æ·»åŠ æ•´ä½“æ ·æœ¬æ•°å’Œæ­£ç¡®æ•°ï¼ˆå¦‚æœeval_resultsä¸­æœ‰ï¼‰
        if eval_results:
            overall_samples = eval_results.get('total_samples', 0)
            overall_correct = eval_results.get('total_correct', 0)
            if overall_samples > 0:
                eval_data["eval/overall_samples"] = int(overall_samples)
                eval_data["eval/overall_correct"] = int(overall_correct)
        
        # æ·»åŠ æ¯ä¸ªæ•°æ®é›†çš„è¯¦ç»†æŒ‡æ ‡ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if eval_results and 'dataset_metrics' in eval_results and eval_results['dataset_metrics']:
            for dataset_name, metrics in eval_results['dataset_metrics'].items():
                eval_data[f"eval/{dataset_name}_loss"] = float(metrics['loss'])
                eval_data[f"eval/{dataset_name}_accuracy"] = float(metrics['accuracy'])
                eval_data[f"eval/{dataset_name}_samples"] = int(metrics['samples'])
                eval_data[f"eval/{dataset_name}_correct"] = int(metrics['correct'])
                
        return eval_data
        
    def _log_placeholder_eval(self, effective_step, aggregated_loss, current_lr):
        """è®°å½•å ä½ç¬¦è¯„ä¼°ç»“æœ"""
        try:
            placeholder_eval_data = {
                "training/loss": float(aggregated_loss),
                "training/lr": float(current_lr),
                "eval/overall_loss": 999.0,  # ä½¿ç”¨æ˜æ˜¾çš„å ä½ç¬¦å€¼
                "eval/overall_accuracy": 0.0,
                "eval/evaluation_failed": 1.0,  # æ ‡è®°è¯„ä¼°å¤±è´¥
                "step": int(effective_step)
            }
            self.monitor.log_metrics(placeholder_eval_data, effective_step)
        except Exception as placeholder_error:
            print(f"âŒ è®°å½•å ä½ç¬¦evalç»“æœå¤±è´¥: {placeholder_error}")
            print(f"   effective_step: {effective_step}")
            print(f"   aggregated_loss: {aggregated_loss}")
            print(f"   current_lr: {current_lr}")
            import traceback
            traceback.print_exc()
            
    def _handle_logging_step(self, effective_step, aggregated_loss, grad_norm_value, current_lr, epoch, batch_idx, inputs, attention_mask):
        """å¤„ç†æ—¥å¿—è®°å½•æ­¥éª¤"""
        # è®°å½•å„æ•°æ®é›†çš„æŒ‡æ ‡
        self._log_dataset_metrics(effective_step, is_eval=False)
        
        # åŸºç¡€æ—¥å¿—ä¿¡æ¯
        log_message = (
            f"Step {effective_step:,} | "
            f"Loss: {aggregated_loss:.4f} | "
            f"Grad Norm: {grad_norm_value:.4f} | "
            f"LR: {current_lr:.2e} | "
            f"Epoch: {epoch + batch_idx/len(self.train_loader):.2f}"
        )
        
        # å¦‚æœè¿›è¡Œäº†å®æ—¶FLOPsæµ‹é‡ï¼Œæ·»åŠ MFUä¿¡æ¯
        if hasattr(self.monitor, 'actual_flops') and self.monitor.actual_flops:
            current_time = time.time()
            step_start_time = getattr(self.monitor, 'step_start_time', None)
            if step_start_time is not None:
                actual_step_time = current_time - step_start_time
                
                current_mfu = self._calculate_mfu(effective_step, inputs, attention_mask, actual_step_time)
                if current_mfu is not None:
                    log_message += f" | MFU: {current_mfu:.1%}"
                    log_message += " [ğŸ“Šå®æ—¶æµ‹é‡]"
        
        # æ‰“å°æ—¥å¿—ä¿¡æ¯
        if self.dist_ctx.is_main_process and hasattr(self, 'pbar'):
            self.pbar.write(log_message)
            
    def _handle_save_step(self, effective_step):
        """å¤„ç†ä¿å­˜æ­¥éª¤"""
        if not self.save_best_only:  # åªæœ‰åœ¨æœªå¯ç”¨"ä»…ä¿å­˜æœ€ä½³æ¨¡å‹"æ—¶æ‰ä¿å­˜å¸¸è§„æ£€æŸ¥ç‚¹
            if hasattr(self, 'pbar'):
                self.pbar.clear()
            self.save_checkpoint(effective_step)
            if hasattr(self, 'pbar'):
                self.pbar.refresh()
        elif self.dist_ctx.is_main_process:  # å¦‚æœå¯ç”¨äº†ä»…ä¿å­˜æœ€ä½³æ¨¡å‹ï¼Œåªæ˜¾ç¤ºä¿¡æ¯
            if hasattr(self, 'pbar'):
                self.pbar.write(f"ğŸ’¡ ä»…ä¿å­˜æœ€ä½³æ¨¡å‹æ¨¡å¼å·²å¯ç”¨ï¼Œè·³è¿‡æ­¥éª¤ {effective_step} çš„å¸¸è§„æ£€æŸ¥ç‚¹ä¿å­˜")
                
    def _train_epoch(self, epoch, stats):
        """è®­ç»ƒä¸€ä¸ªepoch - ä¼˜åŒ–ç‰ˆæœ¬"""
        self.current_epoch = epoch
        self.model.train()
        
        # ğŸ”¥ æ–°å¢ï¼šä¼˜åŒ–æ•°æ®åŠ è½½å™¨
        if epoch == 0:  # åªåœ¨ç¬¬ä¸€ä¸ªepochä¼˜åŒ–
            self._optimize_dataloader()
        
        # ä¸ºåˆ†å¸ƒå¼é‡‡æ ·å™¨è®¾ç½®epochï¼ˆç¡®ä¿æ¯ä¸ªepochçš„shuffleæ­£ç¡®ï¼‰
        if hasattr(self.train_loader.sampler, 'set_epoch'):
            self.train_loader.sampler.set_epoch(epoch)
        
        epoch_loss = 0
        epoch_start_time = time.time()
        effective_step = epoch * stats['effective_steps_per_epoch']
        
        # ğŸ”¥ æ–°å¢ï¼šæ€§èƒ½ç›‘æ§
        epoch_performance = {
            'forward_time': 0.0,
            'backward_time': 0.0,
            'optimizer_time': 0.0,
            'data_loading_time': 0.0,
            'memory_usage': []
        }
        
        for batch_idx, batch in enumerate(self.train_loader):
            batch_start_time = time.time()
            self.current_step += 1
            
            # ğŸ”¥ æ–°å¢ï¼šæ•°æ®åŠ è½½æ—¶é—´ç›‘æ§
            data_loading_time = time.time() - batch_start_time
            epoch_performance['data_loading_time'] += data_loading_time
            
            # å‡†å¤‡æ‰¹æ¬¡æ•°æ®
            forward_kwargs, inputs, attention_mask, labels = self._prepare_batch_data(batch)
            
            # ğŸ”¥ æ–°å¢ï¼šå‰å‘ä¼ æ’­æ—¶é—´ç›‘æ§
            forward_start = time.time()
            outputs = self.model(**forward_kwargs)
            loss = outputs.loss
            epoch_performance['forward_time'] += time.time() - forward_start
            
            # ğŸ”¥ æ–°å¢ï¼šåå‘ä¼ æ’­æ—¶é—´ç›‘æ§
            backward_start = time.time()
            self.model.backward(loss)
            epoch_performance['backward_time'] += time.time() - backward_start
            
            # èšåˆå¤šå¡lossï¼ˆåœ¨åˆ†å¸ƒå¼è®­ç»ƒä¸­ï¼‰
            aggregated_loss = self._aggregate_loss(loss)
            epoch_loss += aggregated_loss
            
            # ä¼˜åŒ–æ•°æ®é›†æŒ‡æ ‡æ›´æ–° - é™ä½é¢‘ç‡ä»¥å‡å°‘å¼€é”€
            if self.enable_dataset_metrics and (self.current_step % 10 == 0):
                self._update_dataset_metrics(batch, outputs, aggregated_loss)
            
            # æ”¶é›†MFUç»Ÿè®¡æ•°æ®
            if self.mfu_stats is not None:
                self._collect_mfu_data(batch, inputs, attention_mask)
            
            # ğŸ”¥ æ–°å¢ï¼šä¼˜åŒ–å™¨æ—¶é—´ç›‘æ§
            optimizer_start = time.time()
            grad_norm = self.model.get_global_grad_norm()
            self.model.step()
            epoch_performance['optimizer_time'] += time.time() - optimizer_start
            
            # å¤„ç†æ¢¯åº¦èŒƒæ•°
            grad_norm_value = self._process_grad_norm(grad_norm)
            current_lr = self.optimizer.param_groups[0]['lr']
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯æœ‰æ•ˆæ­¥éª¤ï¼ˆå®Œæˆäº†æ¢¯åº¦ç´¯ç§¯ï¼‰
            is_effective_step = self.current_step % stats['gradient_accumulation_steps'] == 0
            
            if is_effective_step:
                effective_step += 1
                
                # è®¡ç®—æ­¥éª¤æ—¶é—´ - ä¿®å¤Noneå€¼é—®é¢˜
                current_time = time.time()
                step_start_time = getattr(self.monitor, 'step_start_time', None)
                if step_start_time is not None:
                    step_time = current_time - step_start_time
                else:
                    step_time = 0.0
                
                # åˆ¤æ–­æ˜¯å¦ä¸ºè¯„ä¼°æ­¥éª¤
                is_eval_step = (effective_step % self.config['eval_steps'] == 0)
                
                # å¤„ç†æœ‰æ•ˆæ­¥éª¤
                self._handle_effective_step(effective_step, epoch, batch_idx, aggregated_loss, current_lr, 
                                          grad_norm_value, inputs, attention_mask, step_time, is_eval_step)
                
                # è¯¦ç»†æ—¥å¿—è®°å½•
                if effective_step % self.config['logging_steps'] == 0:
                    self._handle_logging_step(effective_step, aggregated_loss, grad_norm_value, current_lr, 
                                            epoch, batch_idx, inputs, attention_mask)
                
                # å®šæœŸè¯„ä¼°
                if effective_step > 0 and effective_step % self.config['eval_steps'] == 0:
                    if self.dist_ctx.is_main_process:
                        print(f"\nğŸ¯ è§¦å‘è¯„ä¼°æ­¥éª¤ (step={effective_step}, eval_steps={self.config['eval_steps']})")
                    self._handle_evaluation_step(effective_step, epoch, aggregated_loss, current_lr, 
                                               grad_norm_value, inputs, attention_mask, step_time)
                
                # å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹
                if effective_step > 0 and effective_step % self.config['save_steps'] == 0:
                    self._handle_save_step(effective_step)
            
            # ğŸ”¥ æ–°å¢ï¼šå®šæœŸå†…å­˜æ¸…ç†
            if batch_idx % 100 == 0 and torch.cuda.is_available():
                torch.cuda.empty_cache()
                
            # ğŸ”¥ æ–°å¢ï¼šè®°å½•å†…å­˜ä½¿ç”¨æƒ…å†µ
            if torch.cuda.is_available():
                memory_allocated = torch.cuda.memory_allocated() / (1024**3)  # GB
                epoch_performance['memory_usage'].append(memory_allocated)
        
        # Epochç»“æŸç»Ÿè®¡
        epoch_time = time.time() - epoch_start_time
        avg_loss = epoch_loss / len(self.train_loader)
        self.monitor.log_epoch(epoch, avg_loss, epoch_time, effective_step)
        
        # ğŸ”¥ æ–°å¢ï¼šè®°å½•æ€§èƒ½ç»Ÿè®¡
        self._log_performance_stats(epoch, epoch_performance, epoch_time)
        
        # è¾“å‡ºepochç»Ÿè®¡ä¿¡æ¯
        epoch_message = (
            f"ğŸ“Š Epoch {epoch+1}/{self.config['training']['num_epochs']} å®Œæˆ | "
            f"å¹³å‡æŸå¤±: {avg_loss:.4f} | "
            f"è€—æ—¶: {epoch_time:.2f}ç§’ | "
            f"æœ‰æ•ˆæ­¥æ•°: {effective_step:,}"
        )
        if self.dist_ctx.is_main_process and hasattr(self, 'pbar'):
            self.pbar.write(epoch_message)
            
        return effective_step
        
    def _log_performance_stats(self, epoch, performance, total_time):
        """è®°å½•æ€§èƒ½ç»Ÿè®¡ä¿¡æ¯"""
        if not self.dist_ctx.is_main_process:
            return
            
        # è®¡ç®—å¹³å‡å†…å­˜ä½¿ç”¨
        avg_memory = sum(performance['memory_usage']) / len(performance['memory_usage']) if performance['memory_usage'] else 0
        
        # è®¡ç®—å„é˜¶æ®µæ—¶é—´å æ¯”
        total_compute_time = performance['forward_time'] + performance['backward_time'] + performance['optimizer_time']
        data_loading_ratio = performance['data_loading_time'] / total_time * 100
        compute_ratio = total_compute_time / total_time * 100
        
        performance_data = {
            f"perf/epoch_{epoch}_total_time": total_time,
            f"perf/epoch_{epoch}_forward_time": performance['forward_time'],
            f"perf/epoch_{epoch}_backward_time": performance['backward_time'],
            f"perf/epoch_{epoch}_optimizer_time": performance['optimizer_time'],
            f"perf/epoch_{epoch}_data_loading_time": performance['data_loading_time'],
            f"perf/epoch_{epoch}_avg_memory_gb": avg_memory,
            f"perf/epoch_{epoch}_data_loading_ratio": data_loading_ratio,
            f"perf/epoch_{epoch}_compute_ratio": compute_ratio,
            "step": epoch * len(self.train_loader)
        }
        
        # ğŸ”¥ ä¿®å¤ï¼šæš‚æ—¶ç¦ç”¨æ€§èƒ½ç»Ÿè®¡è®°å½•ï¼Œé¿å…stepå†²çª
        # self.monitor.log_metrics(performance_data, epoch * len(self.train_loader), commit=True)
        
        if self.dist_ctx.is_main_process:
            print(f"ğŸ”§ Epoch {epoch} æ€§èƒ½ç»Ÿè®¡:")
            print(f"  â€¢ æ€»è€—æ—¶: {total_time:.2f}s")
            print(f"  â€¢ å‰å‘ä¼ æ’­: {performance['forward_time']:.2f}s")
            print(f"  â€¢ åå‘ä¼ æ’­: {performance['backward_time']:.2f}s")
            print(f"  â€¢ ä¼˜åŒ–å™¨: {performance['optimizer_time']:.2f}s")
            print(f"  â€¢ æ•°æ®åŠ è½½: {performance['data_loading_time']:.2f}s ({data_loading_ratio:.1f}%)")
            print(f"  â€¢ å¹³å‡å†…å­˜: {avg_memory:.2f}GB")
            print(f"  â€¢ è®¡ç®—å æ¯”: {compute_ratio:.1f}%")
            
    def _process_grad_norm(self, grad_norm):
        """å¤„ç†æ¢¯åº¦èŒƒæ•°"""
        if grad_norm is None:
            return 0.0
        elif hasattr(grad_norm, 'item'):
            return float(grad_norm.item())
        else:
            return float(grad_norm)
            
    def train(self):
        """è®­ç»ƒæ¨¡å‹ - ä¼˜åŒ–ç‰ˆæœ¬"""
        self.dist_ctx.print_main("å¼€å§‹è®­ç»ƒ...")
        self.monitor.start_training()
        
        # è®¡ç®—è®­ç»ƒç»Ÿè®¡ä¿¡æ¯
        stats = self._calculate_training_stats()
        
        # æ‰“å°è®­ç»ƒé…ç½®ä¿¡æ¯
        self._print_training_config(stats)
        
        # ğŸ”¥ åˆå§‹åŒ–FLOPs profilingï¼Œç¡®ä¿MFUèƒ½å¤Ÿæ­£ç¡®è®°å½•
        if self.dist_ctx.is_main_process:
            self.dist_ctx.print_main("ğŸ” åˆå§‹åŒ–FLOPs profiling...")
            try:
                # è·å–ç¬¬ä¸€ä¸ªbatchè¿›è¡ŒFLOPs profiling
                first_batch = next(iter(self.train_loader))
                forward_kwargs, inputs, attention_mask, labels = self._prepare_batch_data(first_batch)
                
                # è¿›è¡ŒFLOPs profiling
                batch_example = {
                    "input_ids": inputs,
                    "attention_mask": attention_mask,
                    "pixel_values": forward_kwargs.get("pixel_values"),
                    "labels": labels
                }
                
                self.monitor.profile_model_flops(batch_example)
                self.dist_ctx.print_main("âœ… FLOPs profilingå®Œæˆï¼ŒMFUè®¡ç®—å·²å¯ç”¨")
                
            except Exception as flops_error:
                self.dist_ctx.print_main(f"âŒ FLOPs profilingå¤±è´¥: {flops_error}")
                self.dist_ctx.print_main(f"   first_batchç±»å‹: {type(first_batch)}")
                self.dist_ctx.print_main(f"   batch_example: {batch_example}")
                self.dist_ctx.print_main("âš ï¸ MFUè®¡ç®—å°†è¢«ç¦ç”¨")
                import traceback
                traceback.print_exc()
        
        # ğŸ”¥ æ–°å¢ï¼šåˆå§‹åŒ–MFUç»Ÿè®¡å™¨
        self.dist_ctx.print_main("ğŸ”§ åˆå§‹åŒ–MFUç»Ÿè®¡å™¨...")
        mfu_init_success = self._init_mfu_stats()
        
        # åœ¨åˆ†å¸ƒå¼ç¯å¢ƒä¸­åŒæ­¥åˆå§‹åŒ–çŠ¶æ€
        if hasattr(self.dist_ctx, 'world_size') and self.dist_ctx.world_size > 1:
            import torch.distributed as dist
            # å¹¿æ’­åˆå§‹åŒ–çŠ¶æ€
            if dist.is_initialized():
                success_tensor = torch.tensor([1 if mfu_init_success else 0], dtype=torch.int, device=torch.cuda.current_device())
                dist.broadcast(success_tensor, src=0)
                mfu_init_success = bool(success_tensor.item())
        
        if mfu_init_success:
            self.dist_ctx.print_main("âœ… MFUç»Ÿè®¡å™¨åˆå§‹åŒ–æˆåŠŸ")
        else:
            self.dist_ctx.print_main("âŒ MFUç»Ÿè®¡å™¨åˆå§‹åŒ–å¤±è´¥ï¼Œå°†ä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•")
        
        # åˆ›å»ºè¿›åº¦æ¡ï¼ˆåŸºäºæœ‰æ•ˆè®­ç»ƒæ­¥æ•°ï¼‰
        self.pbar = tqdm(total=stats['total_effective_steps'], desc="Training Steps", disable=not self.dist_ctx.is_main_process)
        
        # è®­ç»ƒå¾ªç¯
        try:
            for epoch in range(self.config['training']['num_epochs']):
                effective_step = self._train_epoch(epoch, stats)
        except KeyboardInterrupt:
            self.dist_ctx.print_main("âš ï¸ è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
        except Exception as training_error:
            self.dist_ctx.print_main(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {training_error}")
            raise training_error
        finally:
            self.pbar.close()
        
        # è®­ç»ƒç»“æŸå¤„ç†
        self._finish_training(effective_step)
        


    def _finish_training(self, effective_step):
        """å®Œæˆè®­ç»ƒ"""
        # è®­ç»ƒç»“æŸå‰è¿›è¡Œæœ€ç»ˆè¯„ä¼°
        if self.dist_ctx.is_main_process:
            print("\nğŸ¯ è®­ç»ƒå³å°†å®Œæˆï¼Œè¿›è¡Œæœ€ç»ˆè¯„ä¼°...")
        eval_loss, eval_accuracy = self.evaluate(step=effective_step)
        
        # ä¿å­˜æœ€ç»ˆæ£€æŸ¥ç‚¹ï¼ˆå¦‚æœæœªå¯ç”¨ä»…ä¿å­˜æœ€ä½³æ¨¡å‹ï¼‰
        if not self.save_best_only:
            if self.dist_ctx.is_main_process:
                print(f"ğŸ’¾ ä¿å­˜æœ€ç»ˆæ£€æŸ¥ç‚¹...")
            self.save_checkpoint(effective_step)
        elif self.dist_ctx.is_main_process:
            print(f"ğŸ’¡ ä»…ä¿å­˜æœ€ä½³æ¨¡å‹æ¨¡å¼å·²å¯ç”¨ï¼Œè·³è¿‡æœ€ç»ˆæ£€æŸ¥ç‚¹ä¿å­˜")
        
        # è¿›è¡Œå®Œæ•´è¯„ä¼°ï¼ˆåœ¨æœ€ä½³æ¨¡å‹ä¸Šï¼‰
        if self.full_eval_at_end:
            self.full_evaluation_on_best_model()
        
        if self.dist_ctx.is_main_process:
            print("ğŸ‰ è®­ç»ƒå®Œæˆï¼")
            print(f"ğŸ“Š æœ€ç»ˆè¯„ä¼°ç»“æœ - æŸå¤±: {eval_loss:.4f}, å‡†ç¡®ç‡: {eval_accuracy:.4f}")
            if self.best_model_enabled:
                print(f"ğŸ† æœ€ä½³æ¨¡å‹ - {self.best_metric_name}: {self.best_metric_value:.4f} (æ­¥éª¤ {self.best_model_step})")
                print(f"ğŸ† æœ€ä½³æ¨¡å‹è·¯å¾„: {self.best_model_path}")
        
        # ç¡®ä¿æœ€ç»ˆè¯„ä¼°ç»“æœè¢«è®°å½•åˆ°WandB
        self._log_final_evaluation(effective_step, eval_loss, eval_accuracy)
        
        # è®­ç»ƒç»“æŸåè¿›è¡Œæœ€ç»ˆæ¸…ç†
        if self.save_best_only and self.dist_ctx.is_main_process:
            self.dist_ctx.print_main("ğŸ§¹ è¿›è¡Œæœ€ç»ˆæ£€æŸ¥ç‚¹æ¸…ç†...")
            self._cleanup_old_best_models()
        
        self.monitor.finish_training()
        
    def _log_final_evaluation(self, effective_step, eval_loss, eval_accuracy):
        """è®°å½•æœ€ç»ˆè¯„ä¼°ç»“æœ"""
        try:
            final_eval_data = {
                "eval/final_overall_loss": eval_loss,
                "eval/final_overall_accuracy": eval_accuracy,
                "eval/final_evaluation": 1.0  # æ ‡è®°è¿™æ˜¯æœ€ç»ˆè¯„ä¼°
            }
            self.monitor.log_metrics(final_eval_data, effective_step, commit=True)
            self.dist_ctx.print_main(f"âœ… æœ€ç»ˆè¯„ä¼°ç»“æœå·²è®°å½•åˆ°WandB")
        except Exception as final_eval_error:
            self.dist_ctx.print_main(f"âŒ æœ€ç»ˆè¯„ä¼°WandBè®°å½•å¤±è´¥: {final_eval_error}")
            self.dist_ctx.print_main(f"   effective_step: {effective_step}")
            self.dist_ctx.print_main(f"   eval_loss: {eval_loss}")
            self.dist_ctx.print_main(f"   eval_accuracy: {eval_accuracy}")
            import traceback
            traceback.print_exc()
        self.monitor.save_logs()

    def _update_best_model(self, eval_results, step):
        """æ›´æ–°æœ€ä½³æ¨¡å‹"""
        if not self.best_model_enabled:
            return False
        
        # è·å–å½“å‰æŒ‡æ ‡å€¼
        if self.best_metric_name == 'overall_accuracy':
            current_value = eval_results.get('overall_accuracy', 0.0)
        elif self.best_metric_name == 'overall_loss':
            current_value = eval_results.get('overall_loss', float('inf'))
        else:
            # æ”¯æŒæ•°æ®é›†ç‰¹å®šæŒ‡æ ‡ï¼Œå¦‚ 'food101_accuracy'
            if 'dataset_metrics' in eval_results:
                for dataset_name, metrics in eval_results['dataset_metrics'].items():
                    metric_key = self.best_metric_name.replace(f'{dataset_name}_', '')
                    if self.best_metric_name.startswith(dataset_name) and metric_key in metrics:
                        current_value = metrics[metric_key]
                        break
                else:
                    current_value = eval_results.get('overall_accuracy', 0.0)  # é»˜è®¤ä½¿ç”¨overall_accuracy
            else:
                current_value = eval_results.get('overall_accuracy', 0.0)
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯æœ€ä½³æ¨¡å‹
        if self._is_better_metric(current_value, self.best_metric_value):
            self.best_metric_value = current_value
            self.best_model_step = step
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            self.save_checkpoint(step, is_best=True)
            
            # æ¸…ç†æ—§çš„æœ€ä½³æ¨¡å‹ï¼ˆå¦‚æœå¯ç”¨äº†ä»…ä¿å­˜æœ€ä½³æ¨¡å‹ï¼‰
            if self.save_best_only:
                self._cleanup_old_best_models()
            
            # ğŸ”¥ ä¿®å¤ï¼šæš‚æ—¶ç¦ç”¨æœ€ä½³æ¨¡å‹è®°å½•ï¼Œé¿å…stepå†²çª
            # è®°å½•åˆ°wandb
            # self.monitor.log_metrics({
            #     'best_model_step': step,
            #     f'best_{self.best_metric_name}': current_value
            # }, step)
            
            self.dist_ctx.print_main(
                f"ğŸ† å‘ç°æ›´å¥½æ¨¡å‹! {self.best_metric_name}: {current_value:.4f} "
                f"(æ­¥éª¤ {step})"
            )
            return True
        
        return False
    
    def _aggregate_loss(self, loss):
        """åœ¨åˆ†å¸ƒå¼è®­ç»ƒä¸­èšåˆloss"""
        if self.dist_ctx.world_size <= 1:
            return loss.item()
        
        try:
            import torch.distributed as dist
            # å°†å½“å‰GPUçš„losså¹¿æ’­åˆ°æ‰€æœ‰è¿›ç¨‹å¹¶æ±‚å¹³å‡
            loss_tensor = torch.tensor(loss.item(), dtype=torch.float32, device=self.dist_ctx.device)
            
            # ä½¿ç”¨all_reduceæ¥è®¡ç®—æ‰€æœ‰GPUçš„å¹³å‡loss
            dist.all_reduce(loss_tensor, op=dist.ReduceOp.SUM)
            aggregated_loss = loss_tensor.item() / self.dist_ctx.world_size
            
            return aggregated_loss
            
        except Exception as e:
            # å¦‚æœèšåˆå¤±è´¥ï¼Œè¿”å›å½“å‰GPUçš„loss
            print(f"âš ï¸  Lossèšåˆå¤±è´¥ï¼Œä½¿ç”¨å½“å‰GPU loss: {e}")
            return loss.item()

    def save_checkpoint(self, step, is_best=False):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        if is_best:
            checkpoint_dir = os.path.join(self.config['output_dir'], f"best-model-step-{step}")
        else:
            checkpoint_dir = os.path.join(self.config['output_dir'], f"checkpoint-{step}")
        
        os.makedirs(checkpoint_dir, exist_ok=True)
        
        # ä¿å­˜è®­ç»ƒä¿¡æ¯
        training_info = {
            'step': step,
            'epoch': self.current_epoch,
            'config': self.config,
            'dataset_metrics': dict(self.dataset_metrics),  # ä¿å­˜æ•°æ®é›†æŒ‡æ ‡
            'is_best_model': is_best,
            'best_metric_value': self.best_metric_value if is_best else None,
            'timestamp': time.time()
        }
        
        with open(os.path.join(checkpoint_dir, 'training_info.json'), 'w') as f:
            # ä½¿ç”¨make_json_serializableç¡®ä¿æ‰€æœ‰æ•°æ®éƒ½å¯ä»¥åºåˆ—åŒ–
            json.dump(make_json_serializable(training_info), f, indent=2)
        
        # ä¿å­˜DeepSpeedæ ¼å¼ï¼ˆå¯é€‰ï¼‰
        if self.config.get('save_deepspeed_format', True):
            deepspeed_dir = os.path.join(checkpoint_dir, 'deepspeed')
            self.model.save_checkpoint(deepspeed_dir)
            if is_best:
                self.dist_ctx.print_main(f"ğŸ† æœ€ä½³æ¨¡å‹DeepSpeedæ£€æŸ¥ç‚¹ä¿å­˜åˆ°: {deepspeed_dir}")
            else:
                self.dist_ctx.print_main(f"DeepSpeedæ£€æŸ¥ç‚¹ä¿å­˜åˆ°: {deepspeed_dir}")
        
        # ä¿å­˜HuggingFaceæ ¼å¼ï¼ˆå¯é€‰ï¼‰
        if self.config.get('save_hf_format', True):
            if self.dist_ctx.is_main_process:
                hf_dir = save_hf_model(self.model, self.config, checkpoint_dir)
                if hf_dir:
                    if is_best:
                        self.dist_ctx.print_main(f"ğŸ† æœ€ä½³æ¨¡å‹HuggingFaceæ£€æŸ¥ç‚¹ä¿å­˜åˆ°: {hf_dir}")
                    else:
                        self.dist_ctx.print_main(f"HuggingFaceæ£€æŸ¥ç‚¹ä¿å­˜åˆ°: {hf_dir}")
        
        if is_best:
            self.best_model_path = checkpoint_dir
        
        self.dist_ctx.barrier()
        return checkpoint_dir
    
    def _is_better_metric(self, current_value, best_value):
        """åˆ¤æ–­å½“å‰æŒ‡æ ‡æ˜¯å¦æ›´å¥½"""
        if self.best_metric_mode == 'max':
            return current_value > best_value
        else:
            return current_value < best_value
    
    def _cleanup_old_best_models(self):
        """æ¸…ç†æ‰€æœ‰æ£€æŸ¥ç‚¹ï¼Œåªä¿ç•™æœ€æ–°çš„æœ€ä½³æ¨¡å‹"""
        if not self.save_best_only:
            return
            
        try:
            import glob
            import shutil
            
            # æŸ¥æ‰¾æ‰€æœ‰æ£€æŸ¥ç‚¹ç›®å½•
            best_model_pattern = os.path.join(self.config['output_dir'], "best-model-step-*")
            checkpoint_pattern = os.path.join(self.config['output_dir'], "checkpoint-*")
            
            best_model_dirs = glob.glob(best_model_pattern)
            checkpoint_dirs = glob.glob(checkpoint_pattern)
            
            dirs_to_remove = []
            
            # 1. åˆ é™¤æ‰€æœ‰å¸¸è§„æ£€æŸ¥ç‚¹ï¼ˆcheckpoint-*ï¼‰
            dirs_to_remove.extend(checkpoint_dirs)
            
            # 2. åˆ é™¤é™¤æœ€æ–°ä¹‹å¤–çš„æ‰€æœ‰æœ€ä½³æ¨¡å‹æ£€æŸ¥ç‚¹
            if len(best_model_dirs) > 1:
                def extract_step(path):
                    try:
                        return int(os.path.basename(path).split('-')[-1])
                    except:
                        return 0
                
                best_model_dirs.sort(key=extract_step)
                dirs_to_remove.extend(best_model_dirs[:-1])  # ä¿ç•™æœ€åä¸€ä¸ªï¼ˆæœ€æ–°çš„ï¼‰
            
            # æ‰§è¡Œæ¸…ç†
            total_removed = 0
            for dir_path in dirs_to_remove:
                if os.path.exists(dir_path):
                    dir_name = os.path.basename(dir_path)
                    self.dist_ctx.print_main(f"ğŸ—‘ï¸  åˆ é™¤æ£€æŸ¥ç‚¹: {dir_name}")
                    shutil.rmtree(dir_path)
                    total_removed += 1
            
            # æ˜¾ç¤ºæ¸…ç†ç»“æœ
            if total_removed > 0:
                self.dist_ctx.print_main(f"âœ… æ¸…ç†å®Œæˆï¼Œåˆ é™¤äº† {total_removed} ä¸ªæ£€æŸ¥ç‚¹")
                
                # æ˜¾ç¤ºä¿ç•™çš„æœ€ä½³æ¨¡å‹
                remaining_best = glob.glob(best_model_pattern)
                if remaining_best:
                    remaining_best.sort(key=lambda x: int(os.path.basename(x).split('-')[-1]))
                    self.dist_ctx.print_main(f"ğŸ† ä¿ç•™æœ€ä½³æ¨¡å‹: {os.path.basename(remaining_best[-1])}")
            else:
                self.dist_ctx.print_main("âœ… æ— éœ€æ¸…ç†ï¼Œç›®å½•å·²ç»å¾ˆå¹²å‡€")
                
        except Exception as e:
            self.dist_ctx.print_main(f"âš ï¸  æ¸…ç†æ£€æŸ¥ç‚¹æ—¶å‡ºé”™: {e}")

    def _update_dataset_metrics(self, batch, outputs, aggregated_loss):
        """æ›´æ–°å„æ•°æ®é›†çš„æŒ‡æ ‡ - ä¼˜åŒ–ç‰ˆæœ¬ï¼Œå‡å°‘è®¡ç®—å¼€é”€"""
        if not self.enable_dataset_metrics:
            return
            
        dataset_names = batch.get("dataset_names", [])
        labels = batch.get("labels")
        
        if not dataset_names or labels is None or outputs.logits is None:
            return
        
        # åªåœ¨å¿…è¦æ—¶è®¡ç®—é¢„æµ‹ç»“æœï¼ˆé¿å…æ¯æ¬¡éƒ½è®¡ç®—ï¼‰
        predictions = None
        
        # æŒ‰æ•°æ®é›†ç»Ÿè®¡æŒ‡æ ‡ - ç®€åŒ–å¾ªç¯å’Œè®¡ç®—
        dataset_count = len(dataset_names)
        if dataset_count == 0:
            return
            
        # æ‰¹é‡æ›´æ–°åŸºç¡€æŒ‡æ ‡ï¼Œé¿å…é€ä¸ªæ›´æ–°
        avg_loss_per_sample = aggregated_loss / dataset_count
        
        for i, dataset_name in enumerate(dataset_names):
            if i >= len(labels):
                continue
            
            # å»¶è¿Ÿè®¡ç®—é¢„æµ‹ç»“æœï¼Œåªåœ¨éœ€è¦æ—¶è®¡ç®—
            if predictions is None:
                predictions = torch.argmax(outputs.logits, dim=-1)
            
            if i >= len(predictions):
                continue
                
            # ç®€åŒ–æŒ‡æ ‡æ›´æ–°ï¼Œå‡å°‘é‡å¤è®¡ç®—
            metrics = self.dataset_metrics[dataset_name]
            metrics['total_loss'] += avg_loss_per_sample
            metrics['total_samples'] += 1
            metrics['step_count'] += 1
            
            # åªåœ¨éœ€è¦æ—¶è¿›è¡Œtensorè½¬æ¢
            if predictions[i].item() == labels[i].item():
                metrics['correct_samples'] += 1
    
    def _log_dataset_metrics(self, step, is_eval=False):
        """è®°å½•å„æ•°æ®é›†çš„æŒ‡æ ‡ - ä¼˜åŒ–ç‰ˆæœ¬ï¼Œå‡å°‘WandBè®°å½•é¢‘ç‡"""
        if not self.enable_dataset_metrics or not self.dataset_metrics:
            return
        
        # å¤§å¹…é™ä½æ•°æ®é›†æŒ‡æ ‡è®°å½•é¢‘ç‡ï¼Œé¿å…WandB stepå†²çª
        should_log_dataset = (step % 200 == 0)  # æ¯200æ­¥è®°å½•ä¸€æ¬¡
        if not should_log_dataset:
            return
            
        # è®¡ç®—å¹¶è¾“å‡ºå„æ•°æ®é›†çš„æŒ‡æ ‡
        dataset_log_data = {}
        overall_samples = 0
        overall_correct = 0
        
        # æ ¹æ®æ˜¯å¦ä¸ºè¯„ä¼°æ¨¡å¼é€‰æ‹©æŒ‡æ ‡ç»„
        metric_group = "eval" if is_eval else "training"
        
        for dataset_name, metrics in self.dataset_metrics.items():
            if metrics['total_samples'] == 0:
                continue
                
            avg_loss = metrics['total_loss'] / metrics['step_count'] if metrics['step_count'] > 0 else 0
            accuracy = metrics['correct_samples'] / metrics['total_samples']
            
            dataset_log_data[f"{metric_group}/{dataset_name}_loss"] = avg_loss
            dataset_log_data[f"{metric_group}/{dataset_name}_accuracy"] = accuracy
            dataset_log_data[f"{metric_group}/{dataset_name}_samples"] = metrics['total_samples']
            
            # ç´¯è®¡æ•´ä½“æŒ‡æ ‡
            overall_samples += metrics['total_samples']
            overall_correct += metrics['correct_samples']
            
            # åªåœ¨ä¸»è¿›ç¨‹è¾“å‡ºè¯¦ç»†ä¿¡æ¯ï¼ˆé™ä½è¾“å‡ºé¢‘ç‡ï¼‰
            if self.dist_ctx.is_main_process and (step % 500 == 0):  # æ¯500æ­¥è¾“å‡ºä¸€æ¬¡
                prefix = "EVAL" if is_eval else "TRAIN"
                print(f"ğŸ“Š {prefix} - {dataset_name}: "
                      f"Loss={avg_loss:.4f}, Acc={accuracy:.4f} ({accuracy*100:.2f}%), "
                      f"Samples={metrics['total_samples']}")
        
        # æ·»åŠ æ•´ä½“æŒ‡æ ‡
        if overall_samples > 0:
            overall_accuracy = overall_correct / overall_samples
            dataset_log_data[f"{metric_group}/overall_accuracy"] = overall_accuracy
            dataset_log_data[f"{metric_group}/overall_samples"] = overall_samples
            dataset_log_data[f"{metric_group}/overall_correct"] = overall_correct
            
            if self.dist_ctx.is_main_process and (step % 500 == 0):  # æ¯500æ­¥è¾“å‡ºä¸€æ¬¡
                prefix = "EVAL" if is_eval else "TRAIN"
                print(f"ğŸ“Š {prefix} - OVERALL: "
                      f"Acc={overall_accuracy:.4f} ({overall_accuracy*100:.2f}%), "
                      f"Samples={overall_samples}")
        
        # ğŸ”¥ ä¿®å¤ï¼šæš‚æ—¶ç¦ç”¨æ•°æ®é›†æŒ‡æ ‡è®°å½•ï¼Œé¿å…stepå†²çª
        # è®°å½•åˆ°wandbæ—¶ä½¿ç”¨commit=Trueï¼Œç¡®ä¿æ•°æ®åŒæ­¥
        # if dataset_log_data:
        #     self.monitor.log_metrics(dataset_log_data, step, commit=True)
            
        # å¦‚æœä¸æ˜¯evalæ¨¡å¼ï¼Œé‡ç½®è®­ç»ƒæŒ‡æ ‡
        if not is_eval:
            self.dataset_metrics.clear()
    

        
    def evaluate(self, step=None, log_to_wandb=True, return_results=False):
        """è¯„ä¼°æ¨¡å‹ï¼Œæ ¹æ®æ•°æ®é›†æ•°é‡é€‰æ‹©æœ€ä¼˜è¯„ä¼°ç­–ç•¥
        
        Args:
            step: å½“å‰æ­¥æ•°ï¼Œå¦‚æœæä¾›åˆ™ç”¨äºæœ€ä½³æ¨¡å‹ä¿å­˜ï¼›å¦åˆ™ä½¿ç”¨self.current_step
            log_to_wandb: æ˜¯å¦è®°å½•åˆ°WandBï¼Œé»˜è®¤ä¸ºTrue
            return_results: æ˜¯å¦è¿”å›è¯¦ç»†çš„è¯„ä¼°ç»“æœï¼Œé»˜è®¤ä¸ºFalse
        """
        current_step = step if step is not None else self.current_step
        
        try:
            self.dist_ctx.print_main("ğŸ” å¼€å§‹è¯„ä¼°...")
            
            # æ·»åŠ è¯„ä¼°å‰çš„barrierï¼Œç¡®ä¿æ‰€æœ‰è¿›ç¨‹åŒæ­¥
            from .utils.distributed import safe_barrier
            if not safe_barrier():
                self.dist_ctx.print_main("âš ï¸  è¯„ä¼°å‰åŒæ­¥å¤±è´¥ï¼Œè·³è¿‡æœ¬æ¬¡è¯„ä¼°")
                return 0.0, 0.0
            
            # ğŸ”¥ ä¼˜åŒ–ï¼šæ ¹æ®æ•°æ®é›†æ•°é‡é€‰æ‹©è¯„ä¼°ç­–ç•¥
            dataset_count = len(self.dataset_configs) if self.dataset_configs else 0
            
            if dataset_count <= 1:
                # å•æ•°æ®é›†ï¼šä½¿ç”¨å¿«é€Ÿè¯„ä¼°å‡½æ•°
                self.dist_ctx.print_main("ğŸš€ ä½¿ç”¨å¿«é€Ÿå•æ•°æ®é›†è¯„ä¼°")
                from .utils.evaluation import evaluate_single_dataset_fast
                eval_loss, eval_accuracy = evaluate_single_dataset_fast(self.model, self.val_loader, self.dist_ctx.device)
                
                # æ„é€ å…¼å®¹çš„ç»“æœæ ¼å¼
                eval_results = {
                    'overall_loss': eval_loss,
                    'overall_accuracy': eval_accuracy,
                    'dataset_metrics': {},
                    'total_samples': len(self.val_loader.dataset),
                    'total_correct': int(eval_accuracy * len(self.val_loader.dataset))
                }
            else:
                # å¤šæ•°æ®é›†ï¼šä½¿ç”¨å®Œæ•´çš„å¤šæ•°æ®é›†è¯„ä¼°å‡½æ•°
                self.dist_ctx.print_main("ğŸ“Š ä½¿ç”¨å¤šæ•°æ®é›†è¯„ä¼°")
                eval_results = evaluate_multi_dataset(self.model, self.val_loader, self.dist_ctx.device, self.dataset_configs)
            
            # æ£€æŸ¥è¯„ä¼°ç»“æœæ˜¯å¦æœ‰æ•ˆ
            if eval_results is None or not eval_results:
                self.dist_ctx.print_main("âš ï¸  è¯„ä¼°ç»“æœä¸ºç©ºï¼Œè·³è¿‡æœ¬æ¬¡è¯„ä¼°")
                return 0.0, 0.0
            
            # å‡†å¤‡wandbè®°å½•æ•°æ®
            eval_log_data = {}
            overall_samples = 0
            overall_correct = 0
            
            # å¤„ç†æ•°æ®é›†æŒ‡æ ‡ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if eval_results and 'dataset_metrics' in eval_results and eval_results['dataset_metrics']:
                self.dist_ctx.print_main(f"ğŸ“Š æ£€æµ‹åˆ°å¤šæ•°æ®é›†è¯„ä¼°ç»“æœ:")
                # å¤šæ•°æ®é›†æƒ…å†µï¼šè®°å½•æ¯ä¸ªæ•°æ®é›†çš„æŒ‡æ ‡
                for dataset_name, metrics in eval_results['dataset_metrics'].items():
                    eval_log_data[f"eval/{dataset_name}_loss"] = metrics['loss']
                    eval_log_data[f"eval/{dataset_name}_accuracy"] = metrics['accuracy']
                    eval_log_data[f"eval/{dataset_name}_samples"] = metrics['samples']
                    
                    overall_samples += metrics['samples']
                    overall_correct += metrics['correct']
                    
                    # æ‰“å°æ¯ä¸ªæ•°æ®é›†çš„è¯¦ç»†ç»“æœ
                    self.dist_ctx.print_main(f"  ğŸ“‚ {dataset_name}:")
                    self.dist_ctx.print_main(f"     Loss: {metrics['loss']:.6f}")
                    self.dist_ctx.print_main(f"     Accuracy: {metrics['accuracy']:.4f} ({metrics['accuracy']*100:.2f}%)")
                    self.dist_ctx.print_main(f"     Samples: {metrics['samples']:,} (Correct: {metrics['correct']:,})")
            else:
                # å•æ•°æ®é›†æƒ…å†µï¼šä½¿ç”¨æ•´ä½“æŒ‡æ ‡
                self.dist_ctx.print_main(f"ğŸ“Š æ£€æµ‹åˆ°å•æ•°æ®é›†è¯„ä¼°ç»“æœ")
                overall_samples = eval_results.get('total_samples', 0)
                overall_correct = eval_results.get('total_correct', 0)
            
            # è®¡ç®—æ•´ä½“æŒ‡æ ‡
            overall_accuracy = overall_correct / overall_samples if overall_samples > 0 else 0
            overall_loss = eval_results.get('overall_loss', 0)
            
            # æ·»åŠ æ•´ä½“æŒ‡æ ‡åˆ°wandbæ•°æ®
            eval_log_data["eval/overall_loss"] = overall_loss
            eval_log_data["eval/overall_accuracy"] = overall_accuracy
            eval_log_data["eval/overall_samples"] = overall_samples
            eval_log_data["eval/overall_correct"] = overall_correct
            
            # è¾“å‡ºæ•´ä½“ç»“æœ
            self.dist_ctx.print_main("=" * 80)
            self.dist_ctx.print_main(f"ğŸ¯ æ•´ä½“å‡†ç¡®ç‡: {overall_accuracy:.4f} ({overall_accuracy*100:.2f}%)")
            self.dist_ctx.print_main(f"ğŸ“ˆ æ•´ä½“æŸå¤±:   {overall_loss:.6f}")
            self.dist_ctx.print_main(f"ğŸ“Š æ€»æ ·æœ¬æ•°:   {overall_samples:,}")
            self.dist_ctx.print_main(f"âœ… æ­£ç¡®æ ·æœ¬:   {overall_correct:,}")
            self.dist_ctx.print_main("=" * 80)
            
            # è®°å½•åˆ°WandB - ğŸ”¥ ä¿®å¤ï¼šç¡®ä¿evalæŒ‡æ ‡æ­£ç¡®è®°å½•
            if current_step is not None and log_to_wandb:
                try:
                    # ç¡®ä¿æ‰€æœ‰evalæŒ‡æ ‡éƒ½æœ‰æ­£ç¡®çš„stepå­—æ®µ
                    eval_log_data_with_step = eval_log_data.copy()
                    eval_log_data_with_step["step"] = current_step
                    
                    # ä¸€æ¬¡æ€§è®°å½•æ‰€æœ‰evalæŒ‡æ ‡ï¼Œé¿å…stepå†²çª
                    self.monitor.log_metrics(eval_log_data, current_step, commit=True)
                    
                    # è¾“å‡ºè¯¦ç»†çš„è®°å½•ä¿¡æ¯
                    eval_metrics_list = [k for k in eval_log_data.keys() if k.startswith('eval/')]
                    self.dist_ctx.print_main(f"âœ… è¯„ä¼°æŒ‡æ ‡å·²è®°å½•åˆ°WandB (step={current_step})")
                    self.dist_ctx.print_main(f"   ğŸ“Š è®°å½•çš„evalæŒ‡æ ‡: {eval_metrics_list}")
                    self.dist_ctx.print_main(f"   ğŸ“ˆ æ•´ä½“å‡†ç¡®ç‡: {overall_accuracy:.4f}")
                    self.dist_ctx.print_main(f"   ğŸ“‰ æ•´ä½“æŸå¤±: {overall_loss:.6f}")
                    
                except Exception as wandb_error:
                    self.dist_ctx.print_main(f"âš ï¸  WandBè®°å½•å¤±è´¥: {wandb_error}")
                    import traceback
                    traceback.print_exc()
            elif current_step is not None and not log_to_wandb:
                # é™é»˜æ¨¡å¼ï¼Œä¸è¾“å‡ºé¢å¤–ä¿¡æ¯
                pass
            else:
                self.dist_ctx.print_main(f"ğŸ“Š è¯„ä¼°å®Œæˆä½†æœªè®°å½•åˆ°WandB (step=None)")
            
            # æ›´æ–°æœ€ä½³æ¨¡å‹ - åªåœ¨stepä¸ä¸ºNoneæ—¶æ›´æ–°
            if current_step is not None:
                try:
                    eval_results_for_best = {
                        'overall_loss': overall_loss,
                        'overall_accuracy': overall_accuracy
                    }
                    self._update_best_model(eval_results_for_best, current_step)
                except Exception as best_model_error:
                    self.dist_ctx.print_main(f"âš ï¸  æœ€ä½³æ¨¡å‹æ›´æ–°å¤±è´¥: {best_model_error}")
            else:
                self.dist_ctx.print_main(f"ğŸ“Š è·³è¿‡æœ€ä½³æ¨¡å‹æ›´æ–° (step=None)")
            
            # è¿”å›æ•´ä½“æŒ‡æ ‡
            self.dist_ctx.print_main(f"âœ… è¯„ä¼°ç»“æŸ - éªŒè¯æŸå¤±: {overall_loss:.4f}, å‡†ç¡®ç‡: {overall_accuracy:.4f}")
            
            if return_results:
                return overall_loss, overall_accuracy, eval_results
            else:
                return overall_loss, overall_accuracy
            
        except Exception as eval_error:
            # ç®€åŒ–çš„é”™è¯¯å¤„ç†
            self.dist_ctx.print_main(f"âŒ è¯„ä¼°è¿‡ç¨‹å‡ºé”™: {eval_error}")
            self.dist_ctx.print_main("ğŸ”„ è·³è¿‡æœ¬æ¬¡è¯„ä¼°ï¼Œç»§ç»­è®­ç»ƒ...")
            return 0.0, 0.0
    
    def full_evaluation_on_best_model(self):
        """åœ¨æœ€ä½³æ¨¡å‹ä¸Šè¿›è¡Œå®Œæ•´è¯„ä¼°"""
        if not self.full_eval_at_end or not self.best_model_path:
            return
        
        self.dist_ctx.print_main("\n" + "="*80)
        self.dist_ctx.print_main("ğŸ” å¼€å§‹å¯¹æœ€ä½³æ¨¡å‹è¿›è¡Œå®Œæ•´è¯„ä¼°")
        self.dist_ctx.print_main("="*80)
        
        # åˆ›å»ºå®Œæ•´è¯„ä¼°æ•°æ®åŠ è½½å™¨
        # å®‰å…¨åœ°è·å–processorï¼Œé¿å…DeepSpeedåŒ…è£…å¯¼è‡´çš„å±æ€§è®¿é—®é”™è¯¯
        try:
            processor = self.model.module.processor
        except AttributeError:
            try:
                processor = self.model.processor
            except AttributeError:
                processor = None
                self.dist_ctx.print_main("âš ï¸ æ— æ³•è·å–æ¨¡å‹processorï¼Œå°†ä»é…ç½®ä¸­é‡æ–°åŠ è½½")
        
        full_eval_loader = create_full_eval_dataloader(self.config, processor)
        
        if full_eval_loader is None:
            self.dist_ctx.print_main("âš ï¸ æ— æ³•åˆ›å»ºå®Œæ•´è¯„ä¼°æ•°æ®åŠ è½½å™¨ï¼Œè·³è¿‡å®Œæ•´è¯„ä¼°")
            return
        
        # ç»Ÿä¸€ä½¿ç”¨å¤šæ•°æ®é›†è¯„ä¼°å‡½æ•°
        eval_results = evaluate_multi_dataset(self.model, full_eval_loader, self.dist_ctx.device, self.dataset_configs)
        
        # å‡†å¤‡wandbè®°å½•æ•°æ®
        eval_log_data = {}
        overall_samples = 0
        overall_correct = 0
        
        # å¤„ç†æ•°æ®é›†æŒ‡æ ‡ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if eval_results and 'dataset_metrics' in eval_results and eval_results['dataset_metrics']:
            # å¤šæ•°æ®é›†æƒ…å†µï¼šè®°å½•æ¯ä¸ªæ•°æ®é›†çš„æŒ‡æ ‡
            for dataset_name, metrics in eval_results['dataset_metrics'].items():
                eval_log_data[f"eval/final_{dataset_name}_loss"] = metrics['loss']
                eval_log_data[f"eval/final_{dataset_name}_accuracy"] = metrics['accuracy']
                eval_log_data[f"eval/final_{dataset_name}_samples"] = metrics['samples']
                
                overall_samples += metrics['samples']
                overall_correct += metrics['correct']
        else:
            # å•æ•°æ®é›†æƒ…å†µï¼šä½¿ç”¨overallæŒ‡æ ‡ä½œä¸ºä¸»è¦æŒ‡æ ‡
            eval_log_data["eval/final_loss"] = eval_results.get('overall_loss', 0)
            eval_log_data["eval/final_accuracy"] = eval_results.get('overall_accuracy', 0)
            overall_samples = eval_results.get('total_samples', 0)
            overall_correct = eval_results.get('total_correct', 0)
        
        # æ·»åŠ æ•´ä½“æŒ‡æ ‡ï¼ˆé€‚ç”¨äºå•æ•°æ®é›†å’Œå¤šæ•°æ®é›†ï¼‰
        if overall_samples > 0:
            overall_accuracy = overall_correct / overall_samples
        else:
            overall_accuracy = eval_results.get('overall_accuracy', 0)
            overall_samples = eval_results.get('total_samples', 0)
            overall_correct = eval_results.get('total_correct', 0)
        
        # æ€»æ˜¯æ·»åŠ æ•´ä½“æŒ‡æ ‡
        eval_log_data["eval/final_overall_loss"] = eval_results.get('overall_loss', 0)
        eval_log_data["eval/final_overall_accuracy"] = overall_accuracy
        eval_log_data["eval/final_overall_samples"] = overall_samples
        eval_log_data["eval/final_overall_correct"] = overall_correct
        
        # è®°å½•åˆ°wandb
        self.monitor.log_metrics(eval_log_data, self.best_model_step)
        
        # æ˜¾ç¤ºç»“æœ
        self.dist_ctx.print_main(f"\nğŸ¯ æœ€ä½³æ¨¡å‹å®Œæ•´è¯„ä¼°ç»“æœ:")
        self.dist_ctx.print_main(f"   â€¢ æ•´ä½“å‡†ç¡®ç‡: {overall_accuracy:.4f} ({overall_accuracy*100:.2f}%)")
        self.dist_ctx.print_main(f"   â€¢ æ€»æ ·æœ¬æ•°: {overall_samples:,}")
        self.dist_ctx.print_main(f"   â€¢ æ­£ç¡®æ ·æœ¬æ•°: {overall_correct:,}")
        
        self.dist_ctx.print_main("="*80)
        
        return {
            'overall_loss': eval_results.get('overall_loss', 0),
            'overall_accuracy': overall_accuracy,
            'dataset_metrics': eval_results.get('dataset_metrics', {})
        }
        
    def load_checkpoint(self, checkpoint_path):
        """åŠ è½½æ£€æŸ¥ç‚¹"""
        if os.path.exists(checkpoint_path):
            self.model.load_checkpoint(checkpoint_path)
            self.dist_ctx.print_main(f"æ£€æŸ¥ç‚¹åŠ è½½æˆåŠŸ: {checkpoint_path}")
        else:
            self.dist_ctx.print_main(f"æ£€æŸ¥ç‚¹ä¸å­˜åœ¨: {checkpoint_path}")
            
    def get_training_stats(self):
        """è·å–è®­ç»ƒç»Ÿè®¡ä¿¡æ¯"""
        return self.monitor.get_avg_metrics() 