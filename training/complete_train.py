#!/usr/bin/env python3
"""
å®Œæ•´çš„Qwen2.5-VLå›¾åƒåˆ†ç±»è®­ç»ƒè„šæœ¬
åŒ…å«FlashAttentionã€DeepSpeedã€WandBç›‘æ§ã€æ€§èƒ½ä¼˜åŒ–
"""

import os
import sys
import argparse
import yaml
import deepspeed
import torch
import numpy as np
from pathlib import Path

# ğŸ”¥ è®¾ç½®FlashAttentionç¯å¢ƒå˜é‡
os.environ["FLASH_ATTENTION_FORCE_ENABLE"] = "1"
os.environ["FLASH_ATTENTION_2"] = "1"

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from data.dataloader import create_dataloaders
from models.qwen2_5_vl_classify import Qwen2_5_VLForImageClassification
from optimizer.optimizer import create_optimizer
from training.deepspeed_trainer import DeepSpeedTrainer
from training.lr_scheduler import create_lr_scheduler
from training.utils.config_utils import prepare_config

def is_main_process():
    """æ£€æŸ¥æ˜¯å¦ä¸ºä¸»è¿›ç¨‹"""
    try:
        import torch.distributed as dist
        return not (dist.is_available() and dist.is_initialized()) or dist.get_rank() == 0
    except ImportError:
        return True

def set_random_seeds(seed=42):
    """è®¾ç½®éšæœºç§å­"""
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    np.random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)

def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description="Qwen2.5-VLå›¾åƒåˆ†ç±»å®Œæ•´è®­ç»ƒ")
    parser.add_argument("--config", type=str, required=True, help="é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--local_rank", type=int, default=-1, help="æœ¬åœ°è¿›ç¨‹æ’å")
    parser.add_argument("--resume_from", type=str, help="æ¢å¤è®­ç»ƒçš„æ£€æŸ¥ç‚¹è·¯å¾„")
    parser.add_argument("--seed", type=int, default=42, help="éšæœºç§å­")
    
    # æ”¯æŒDeepSpeedå‚æ•°ï¼ˆåŒ…æ‹¬--deepspeed_configï¼‰
    parser = deepspeed.add_config_arguments(parser)
    return parser.parse_args()

def setup_model(config):
    """è®¾ç½®æ¨¡å‹"""
    if is_main_process():
        print("ğŸ”§ è®¾ç½®æ¨¡å‹...")
    
    # è·å–æŸå¤±å‡½æ•°é…ç½®
    loss_config = config.get('loss', {'type': 'cross_entropy'})
    
    # è·å–å¤šæ•°æ®é›†é…ç½®
    dataset_configs = config.get('datasets', {}).get('dataset_configs', {})
    enable_logits_masking = config.get('datasets', {}).get('enable_logits_masking', True)
    
    # åªåœ¨ä¸»è¿›ç¨‹ä¸­æ‰“å°é…ç½®ä¿¡æ¯
    if is_main_process():
        print(f"ğŸ¯ æŸå¤±å‡½æ•°: {loss_config.get('type', 'cross_entropy')}")
        if loss_config.get('type') != 'cross_entropy':
            print(f"  æŸå¤±å‡½æ•°å‚æ•°: {loss_config}")
        
        if dataset_configs:
            print(f"ğŸ—‚ï¸ å¤šæ•°æ®é›†æ¨¡å¼:")
            print(f"  â€¢ æ•°æ®é›†æ•°é‡: {len(dataset_configs)}")
            print(f"  â€¢ Logits Masking: {'å¯ç”¨' if enable_logits_masking else 'ç¦ç”¨'}")
            for dataset_name, dataset_config in dataset_configs.items():
                num_classes = dataset_config.get('num_classes', 'N/A')
                print(f"  â€¢ {dataset_name}: {num_classes} classes")
    
    # åˆ›å»ºæ¨¡å‹
    model = Qwen2_5_VLForImageClassification(
        pretrained_model_name=config['model']['pretrained_name'],
        num_labels=config['model']['num_labels'],
        loss_config=loss_config,
        dataset_configs=dataset_configs,
        enable_logits_masking=enable_logits_masking
    )
    
    if is_main_process():
        print(f"âœ… æ¨¡å‹åˆ›å»ºå®Œæˆ: {config['model']['pretrained_name']}")
    return model

def setup_data(config):
    """è®¾ç½®æ•°æ®åŠ è½½å™¨"""
    if is_main_process():
        print("ğŸ”§ è®¾ç½®æ•°æ®åŠ è½½å™¨...")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨ - åªä¼ é€’configå‚æ•°
    train_loader, val_loader = create_dataloaders(config)
    
    # åªåœ¨ä¸»è¿›ç¨‹ä¸­æ‰“å°ä¿¡æ¯
    if is_main_process():
        # è·å–æ•°æ®é…ç½®ç”¨äºæ‰“å°ä¿¡æ¯
        data_config = config.get('data', {})
        training_config = config.get('training', {})
        
        print(f"âœ… æ•°æ®åŠ è½½å™¨åˆ›å»ºå®Œæˆ")
        print(f"  â€¢ è®­ç»ƒé›†: {len(train_loader.dataset)} æ ·æœ¬")
        print(f"  â€¢ éªŒè¯é›†: {len(val_loader.dataset)} æ ·æœ¬")
        
        # ä»DeepSpeedé…ç½®ä¸­è·å–æ‰¹æ¬¡å¤§å°
        if 'deepspeed' in config:
            if isinstance(config['deepspeed'], str):
                import json
                with open(config['deepspeed'], 'r') as f:
                    deepspeed_config = json.load(f)
            else:
                deepspeed_config = config['deepspeed']
            batch_size = deepspeed_config.get('train_micro_batch_size_per_gpu', 1)
        else:
            batch_size = training_config.get('batch_size', 8)
        
        print(f"  â€¢ æ‰¹æ¬¡å¤§å°: {batch_size}")
        print(f"  â€¢ Workeræ•°é‡: {training_config.get('num_workers', 16)}")
    
    return train_loader, val_loader

def setup_optimizer_and_scheduler(model, config):
    """è®¾ç½®ä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡è°ƒåº¦å™¨"""
    if is_main_process():
        print("ğŸ”§ è®¾ç½®ä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡è°ƒåº¦å™¨...")
    
    # åˆ›å»ºä¼˜åŒ–å™¨ - åªä¼ é€’modelå’Œconfig
    optimizer = create_optimizer(model, config)
    
    # åˆ›å»ºå­¦ä¹ ç‡è°ƒåº¦å™¨ - éœ€è¦configå’Œsteps_per_epoch
    # è¿™é‡Œå…ˆåˆ›å»ºä¸€ä¸ªä¸´æ—¶çš„steps_per_epochï¼Œåç»­ä¼šåœ¨trainerä¸­æ›´æ–°
    temp_steps_per_epoch = 1000  # ä¸´æ—¶å€¼ï¼Œä¼šåœ¨trainerä¸­æ›´æ–°
    lr_scheduler = create_lr_scheduler(optimizer, config, temp_steps_per_epoch)
    
    # åªåœ¨ä¸»è¿›ç¨‹ä¸­æ‰“å°ä¿¡æ¯
    if is_main_process():
        # è·å–é…ç½®ä¿¡æ¯ç”¨äºæ‰“å°
        training_config = config.get('training', {})
        lr_config = training_config.get('lr_scheduler', {})
        
        print(f"âœ… ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨åˆ›å»ºå®Œæˆ")
        print(f"  â€¢ å­¦ä¹ ç‡: {training_config.get('lr', 1e-5)}")
        print(f"  â€¢ æƒé‡è¡°å‡: {training_config.get('weight_decay', 0.01)}")
        print(f"  â€¢ é¢„çƒ­æ­¥æ•°: {training_config.get('warmup_steps', 100)}")
        print(f"  â€¢ è°ƒåº¦å™¨ç±»å‹: {lr_config.get('type', 'cosine')}")
    
    return optimizer, lr_scheduler

def main():
    """ä¸»è®­ç»ƒå‡½æ•°"""
    args = parse_args()
    
    # è®¾ç½®éšæœºç§å­
    set_random_seeds(args.seed)
    
    # åªåœ¨ä¸»è¿›ç¨‹ä¸­åŠ è½½å’Œå‡†å¤‡é…ç½®
    if is_main_process():
        print("ğŸ“‹ åŠ è½½é…ç½®æ–‡ä»¶...")
    
    with open(args.config, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    # éªŒè¯å¹¶è®¾ç½®DeepSpeedé…ç½®
    if is_main_process():
        print(f"ğŸ”§ ä½¿ç”¨å‘½ä»¤è¡ŒæŒ‡å®šçš„DeepSpeedé…ç½®: {args.deepspeed_config}")
    
    # éªŒè¯DeepSpeedé…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.deepspeed_config):
        raise FileNotFoundError(f"DeepSpeedé…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {args.deepspeed_config}")
    
    # å°†DeepSpeedé…ç½®æ·»åŠ åˆ°configä¸­
    config['deepspeed'] = args.deepspeed_config
    
    config = prepare_config(config)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = config.get('training', {}).get('output_dir', './outputs')
    os.makedirs(output_dir, exist_ok=True)
    
    if is_main_process():
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    
    # è®¾ç½®æ¨¡å‹
    model = setup_model(config)
    
    # è®¾ç½®æ•°æ®åŠ è½½å™¨
    train_loader, val_loader = setup_data(config)
    
    # è®¾ç½®ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨
    optimizer, lr_scheduler = setup_optimizer_and_scheduler(model, config)
    
    # åˆ›å»ºDeepSpeedè®­ç»ƒå™¨
    if is_main_process():
        print("ğŸ”§ åˆ›å»ºDeepSpeedè®­ç»ƒå™¨...")
    trainer = DeepSpeedTrainer(config)
    
    # è®¾ç½®æ¨¡å‹å’Œç›¸å…³ç»„ä»¶
    trainer.setup_model(model, train_loader, val_loader, optimizer, lr_scheduler)
    
    # å¦‚æœæŒ‡å®šäº†æ¢å¤æ£€æŸ¥ç‚¹
    if args.resume_from and is_main_process():
        print(f"ğŸ”„ ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ: {args.resume_from}")
        trainer.load_checkpoint(args.resume_from)
    
    # å¼€å§‹è®­ç»ƒ
    if is_main_process():
        print("ğŸš€ å¼€å§‹è®­ç»ƒ...")
    try:
        trainer.train()
        if is_main_process():
            print("ğŸ‰ è®­ç»ƒå®Œæˆ!")
    except KeyboardInterrupt:
        if is_main_process():
            print("âš ï¸ è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        if is_main_process():
            print(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
        raise e

if __name__ == "__main__":
    main() 