import torch

def create_collate_fn(processor):
    """
    è¿”å› collate_fnï¼šå°† batch ä¸­çš„ PIL.Image + messages è½¬ä¸ºæ¨¡å‹å‰å‘éœ€è¦çš„ tensorsã€‚
    æ”¯æŒå¤šæ•°æ®é›†åŠŸèƒ½ï¼Œå¤„ç†dataset_nameå’Œnum_classeså­—æ®µã€‚
    """
    def collate_fn(batch):
        images = [item["image"] for item in batch]
        msgs   = [item["messages"] for item in batch]
        labels = torch.tensor([item["label"] for item in batch], dtype=torch.long)
        
        # å¤„ç†æ•°æ®é›†åç§°
        dataset_names = [item.get("dataset_name", "unknown") for item in batch]
        
        # å¤„ç†ç±»åˆ«æ•°é‡ï¼Œå¦‚æœæ²¡æœ‰æä¾›åˆ™è®¾ä¸ºNone
        num_classes_list = []
        for item in batch:
            num_classes = item.get("num_classes", None)
            num_classes_list.append(num_classes)

        # 1) å…ˆæŠŠ messages è½¬æˆ chat æ–‡æœ¬æ¨¡æ¿
        text_list = []
        for i, m in enumerate(msgs):
            try:
                text = processor.apply_chat_template(
                    conversation=m,
                    tokenize=False,
                    add_generation_prompt=True
                )
                text_list.append(text)
            except Exception as e:
                print(f"Error processing message {i}: {e}")
                print(f"Message format: {m}")
                raise

        # 2) è°ƒç”¨ processor å–å¾—å¼ é‡
        try:
            # å…ˆéªŒè¯å›¾åƒ
            valid_images = []
            for i, img in enumerate(images):
                if img is None:
                    raise ValueError(f"Image {i} is None")
                if not hasattr(img, 'size'):
                    raise ValueError(f"Image {i} is not a valid PIL Image")
                valid_images.append(img)
            
            # ğŸ”¥ ä¼˜åŒ–ï¼šå‡å°‘æ–‡æœ¬é•¿åº¦æå‡å¤„ç†é€Ÿåº¦
            # å¯¹äºQwen2.5-VLï¼Œè°ƒç”¨processorå¤„ç†å¤šæ¨¡æ€è¾“å…¥
            enc = processor(
                text=text_list,
                images=valid_images,
                return_tensors="pt",
                padding=True,
                truncation=True,
                max_length=1024  # ä»2048å‡å°‘åˆ°1024æå‡é€Ÿåº¦
            )
            
            # ç¡®ä¿æ‰€æœ‰å¿…è¦çš„é”®éƒ½å­˜åœ¨
            if "image_grid_thw" not in enc:
                print("Warning: image_grid_thw not found in processor output!")
                print(f"Available keys: {list(enc.keys())}")
                # å¦‚æœæ²¡æœ‰image_grid_thwï¼Œå°è¯•ç”Ÿæˆä¸€ä¸ªé»˜è®¤å€¼
                # æ ¹æ®pixel_valuesçš„å½¢çŠ¶æ¨æ–­
                if "pixel_values" in enc and enc["pixel_values"] is not None:
                    batch_size = enc["pixel_values"].shape[0]
                    # ä¸ºæ¯ä¸ªå›¾åƒåˆ›å»ºé»˜è®¤çš„grid_thw (1, 16, 16) - è¿™æ˜¯ä¸€ä¸ªå¸¸è§çš„é»˜è®¤å€¼
                    enc["image_grid_thw"] = torch.tensor([[1, 16, 16]] * batch_size, dtype=torch.long)
                    print(f"Generated default image_grid_thw: {enc['image_grid_thw']}")
            
            # æ·»åŠ æ ‡ç­¾å’Œå¤šæ•°æ®é›†ä¿¡æ¯
            enc["labels"] = labels
            enc["dataset_names"] = dataset_names
            enc["num_classes_list"] = num_classes_list
            
            return enc
        except Exception as e:
            print(f"Error in processor: {e}")
            print(f"Text list length: {len(text_list)}")
            print(f"Images length: {len(images)}")
            if images:
                print(f"Image sizes: {[getattr(img, 'size', 'NO_SIZE') for img in images]}")
                print(f"Image types: {[type(img) for img in images]}")
            print(f"First few texts: {text_list[:2] if text_list else 'NO_TEXTS'}")
            raise

    return collate_fn
