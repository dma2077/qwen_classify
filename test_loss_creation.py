#!/usr/bin/env python3
"""
æµ‹è¯•æŸå¤±å‡½æ•°åˆ›å»ºæ˜¯å¦æ­£å¸¸å·¥ä½œ
"""
import torch
import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from training.losses import create_loss_function

def test_loss_creation():
    """æµ‹è¯•å„ç§æŸå¤±å‡½æ•°çš„åˆ›å»º"""
    
    print("ğŸ§ª æµ‹è¯•æŸå¤±å‡½æ•°åˆ›å»º...")
    
    # æµ‹è¯•é…ç½®
    test_configs = [
        {'type': 'cross_entropy'},
        {'type': 'label_smoothing', 'smoothing': 0.1, 'temperature': 1.0},
        {'type': 'focal', 'alpha': 1.0, 'gamma': 2.0},
        {'type': 'arcface', 'in_features': 768, 'out_features': 101, 's': 30.0, 'm': 0.5},
        {'type': 'supcon', 'temperature': 0.07},
        {'type': 'symmetric_ce', 'alpha': 1.0, 'beta': 1.0, 'num_classes': 101},
        {'type': 'mixup', 'alpha': 1.0},
    ]
    
    for config in test_configs:
        try:
            loss_type = config.get('type', 'cross_entropy')
            loss_kwargs = {k: v for k, v in config.items() if k != 'type'}
            
            print(f"\nğŸ“‹ åˆ›å»ºæŸå¤±å‡½æ•°: {loss_type}")
            print(f"ğŸ“‹ æŸå¤±å‡½æ•°å‚æ•°: {loss_kwargs}")
            
            loss_function = create_loss_function(loss_type, **loss_kwargs)
            print(f"âœ… æˆåŠŸåˆ›å»º {loss_type}: {type(loss_function)}")
            
            # ç®€å•æµ‹è¯•æŸå¤±å‡½æ•°æ˜¯å¦èƒ½æ­£å¸¸è°ƒç”¨
            if loss_type not in ['arcface', 'supcon']:
                # æ ‡å‡†æŸå¤±å‡½æ•°æµ‹è¯•
                logits = torch.randn(4, 101)  # batch_size=4, num_classes=101
                labels = torch.randint(0, 101, (4,))
                loss = loss_function(logits, labels)
                print(f"âœ… æµ‹è¯•è°ƒç”¨æˆåŠŸ, loss: {loss.item():.4f}")
            else:
                print(f"âœ… åˆ›å»ºæˆåŠŸ (è·³è¿‡è°ƒç”¨æµ‹è¯•)")
                
        except Exception as e:
            print(f"âŒ åˆ›å»º {config.get('type', 'unknown')} å¤±è´¥: {e}")
    
    print("\nğŸ‰ æŸå¤±å‡½æ•°åˆ›å»ºæµ‹è¯•å®Œæˆ!")

if __name__ == "__main__":
    test_loss_creation() 