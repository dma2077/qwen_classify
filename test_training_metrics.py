#!/usr/bin/env python3
"""
æµ‹è¯•trainingæŒ‡æ ‡è®°å½•åˆ°WandBçš„åŠŸèƒ½
"""

import os
import sys
import time
import yaml
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from training.utils.monitor import TrainingMonitor

def test_training_metrics():
    """æµ‹è¯•trainingæŒ‡æ ‡è®°å½•åŠŸèƒ½"""
    print("ğŸ§ª å¼€å§‹æµ‹è¯•trainingæŒ‡æ ‡è®°å½•...")
    
    # åˆ›å»ºæµ‹è¯•é…ç½®
    test_config = {
        'model': {
            'pretrained_name': 'test_model',
            'num_labels': 10
        },
        'training': {
            'num_epochs': 1,
            'learning_rate': 1e-4
        },
        'wandb': {
            'enabled': True,
            'project': 'test_training_metrics',
            'run_name': 'test_run'
        },
        'monitor': {
            'freq': {
                'training_log_freq': 1,  # æ¯æ­¥éƒ½è®°å½•
                'perf_log_freq': 2,      # æ¯2æ­¥è®°å½•æ€§èƒ½
                'eval_log_freq': 1       # æ¯æ­¥éƒ½è®°å½•eval
            }
        }
    }
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = "./test_output"
    os.makedirs(output_dir, exist_ok=True)
    
    # åˆ›å»ºç›‘æ§å™¨
    monitor = TrainingMonitor(output_dir, test_config)
    
    if not monitor.use_wandb:
        print("âŒ WandBæœªå¯ç”¨ï¼Œè·³è¿‡æµ‹è¯•")
        return
    
    print("âœ… WandBå·²å¯ç”¨ï¼Œå¼€å§‹è®°å½•æµ‹è¯•æŒ‡æ ‡...")
    
    # æµ‹è¯•trainingæŒ‡æ ‡è®°å½•
    for step in range(1, 11):
        training_data = {
            "training/loss": 0.5 - step * 0.01,
            "training/lr": 1e-4,
            "training/epoch": 0.1 * step,
            "training/grad_norm": 1.0 + step * 0.1
        }
        
        # æ¯2æ­¥æ·»åŠ æ€§èƒ½æŒ‡æ ‡
        if step % 2 == 0:
            training_data.update({
                "perf/step_time": 0.1 + step * 0.01,
                "perf/steps_per_second": 10.0 - step * 0.1,
                "perf/mfu": 0.3 + step * 0.02
            })
        
        try:
            monitor.log_metrics(training_data, step=step, commit=True)
            print(f"  âœ… Step {step}: trainingæŒ‡æ ‡è®°å½•æˆåŠŸ")
            
            # æ£€æŸ¥WandBçš„å½“å‰step
            import wandb
            if wandb.run is not None:
                current_wandb_step = getattr(wandb.run, 'step', 0)
                print(f"     ğŸ“Š WandBå½“å‰step: {current_wandb_step}")
                
                # æ£€æŸ¥stepæ˜¯å¦ä¸€è‡´
                if current_wandb_step == step:
                    print(f"     âœ… Stepä¸€è‡´")
                else:
                    print(f"     âš ï¸  Stepä¸ä¸€è‡´: æœŸæœ›{step}, å®é™…{current_wandb_step}")
            
            time.sleep(0.1)  # çŸ­æš‚å»¶è¿Ÿ
            
        except Exception as e:
            print(f"  âŒ Step {step}: è®°å½•å¤±è´¥ - {e}")
    
    print("\nğŸ“Š æµ‹è¯•evalæŒ‡æ ‡è®°å½•...")
    eval_data = {
        "eval/overall_loss": 0.3,
        "eval/overall_accuracy": 0.85,
        "eval/overall_samples": 1000,
        "eval/overall_correct": 850
    }
    
    try:
        monitor.log_metrics(eval_data, step=10, commit=True)
        print("âœ… EvalæŒ‡æ ‡è®°å½•æˆåŠŸ")
    except Exception as e:
        print(f"âŒ EvalæŒ‡æ ‡è®°å½•å¤±è´¥: {e}")
    
    print("\nğŸ‰ æµ‹è¯•å®Œæˆï¼")
    print("ğŸ“Š è¯·æ£€æŸ¥WandBç•Œé¢ï¼Œåº”è¯¥èƒ½çœ‹åˆ°:")
    print("   â€¢ TrainingæŒ‡æ ‡: loss, lr, epoch, grad_norm")
    print("   â€¢ PerfæŒ‡æ ‡: step_time, steps_per_second, mfu")
    print("   â€¢ EvalæŒ‡æ ‡: overall_loss, overall_accuracy")
    print("   â€¢ æ‰€æœ‰æŒ‡æ ‡éƒ½åº”è¯¥æœ‰æ­£ç¡®çš„stepå€¼")

if __name__ == "__main__":
    test_training_metrics() 