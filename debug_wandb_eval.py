#!/usr/bin/env python3
"""
è°ƒè¯•WandB evalæŒ‡æ ‡è®°å½•é—®é¢˜
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from training.utils.monitor import TrainingMonitor

def test_wandb_eval_logging():
    """æµ‹è¯•WandB evalæŒ‡æ ‡è®°å½•"""
    
    print("=" * 60)
    print("æµ‹è¯•WandB evalæŒ‡æ ‡è®°å½•")
    print("=" * 60)
    
    # æ¨¡æ‹Ÿè®­ç»ƒé…ç½®
    config = {
        'wandb': {
            'enabled': True,  # å¯ç”¨WandB
            'project': 'test_eval_debug',
            'run_name': 'eval_debug_test'
        },
        'datasets': {
            'dataset_configs': {
                'food101': {'num_classes': 101},
                'test_dataset': {'num_classes': 50}
            }
        }
    }
    
    print("\n1. åˆ›å»ºTrainingMonitor...")
    monitor = TrainingMonitor("./test_output", config=config)
    
    if not monitor.use_wandb:
        print("âŒ WandBæœªå¯ç”¨ï¼Œè·³è¿‡æµ‹è¯•")
        return
    
    print("\n2. æµ‹è¯•evalæŒ‡æ ‡è®°å½•...")
    
    # æµ‹è¯•åŸºç¡€evalæŒ‡æ ‡
    eval_data_1 = {
        "eval/overall_loss": 0.5,
        "eval/overall_accuracy": 0.85,
        "eval/overall_samples": 1000,
        "eval/overall_correct": 850,
    }
    
    print("\n   æµ‹è¯•åŸºç¡€evalæŒ‡æ ‡...")
    monitor.log_metrics(eval_data_1, step=10, commit=True)
    
    # æµ‹è¯•å¤šæ•°æ®é›†evalæŒ‡æ ‡
    eval_data_2 = {
        "eval/overall_loss": 0.4,
        "eval/overall_accuracy": 0.88,
        "eval/food101_loss": 0.42,
        "eval/food101_accuracy": 0.86,
        "eval/test_dataset_loss": 0.38,
        "eval/test_dataset_accuracy": 0.90,
    }
    
    print("\n   æµ‹è¯•å¤šæ•°æ®é›†evalæŒ‡æ ‡...")
    monitor.log_metrics(eval_data_2, step=20, commit=True)
    
    # æµ‹è¯•æœ€ç»ˆevalæŒ‡æ ‡
    eval_data_3 = {
        "eval/final_overall_loss": 0.35,
        "eval/final_overall_accuracy": 0.92,
        "eval/final_evaluation": 1.0,
    }
    
    print("\n   æµ‹è¯•æœ€ç»ˆevalæŒ‡æ ‡...")
    monitor.log_metrics(eval_data_3, step=30, commit=True)
    
    print("\n3. å®Œæˆæµ‹è¯•")
    
    try:
        import wandb
        if wandb.run is not None:
            print(f"\nğŸ”— æŸ¥çœ‹ç»“æœ: {wandb.run.url}")
            print("ğŸ“Š è¯·æ£€æŸ¥WandBç•Œé¢ä¸­æ˜¯å¦æ˜¾ç¤ºevalç»„æŒ‡æ ‡")
        
        # å®Œæˆwandbè®°å½•
        monitor.finish_training()
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
    
    print("\n" + "=" * 60)
    print("è°ƒè¯•æµ‹è¯•å®Œæˆ")
    print("=" * 60)

if __name__ == "__main__":
    test_wandb_eval_logging() 