#!/usr/bin/env python3
"""
è®­ç»ƒé€Ÿåº¦æµ‹è¯•è„šæœ¬
"""

import os
import sys
import time
import yaml
import torch

# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ['NCCL_NTHREADS'] = '64'

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.dirname(os.path.abspath(__file__))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

def test_training_speed():
    """æµ‹è¯•è®­ç»ƒé€Ÿåº¦"""
    print("ğŸš€ æµ‹è¯•è®­ç»ƒé€Ÿåº¦...")
    
    # åŠ è½½é…ç½®
    config_file = "configs/fast_eval_config.yaml"
    with open(config_file, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    # å‡å°‘è®­ç»ƒæ­¥æ•°ä»¥å¿«é€Ÿæµ‹è¯•
    config['train']['num_epochs'] = 1
    config['eval']['eval_steps'] = 100  # å¢åŠ è¯„ä¼°é—´éš”
    config['train']['save_steps'] = 1000  # å¢åŠ ä¿å­˜é—´éš”
    config['train']['logging_steps'] = 50  # å¢åŠ æ—¥å¿—é—´éš”
    
    print(f"ğŸ”§ æµ‹è¯•é…ç½®: eval_steps={config['eval']['eval_steps']}, save_steps={config['train']['save_steps']}")
    
    # å‡†å¤‡é…ç½®
    from training.utils.config_utils import prepare_config
    config = prepare_config(config)
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    from data.dataloader import create_dataloaders
    
    start_time = time.time()
    train_loader, val_loader = create_dataloaders(config)
    loader_time = time.time() - start_time
    
    print(f"âœ… æ•°æ®åŠ è½½å™¨åˆ›å»º: {loader_time:.2f}s")
    print(f"ğŸ“Š è®­ç»ƒæ•°æ®é›†å¤§å°: {len(train_loader.dataset)}")
    print(f"ğŸ“Š è®­ç»ƒæ‰¹æ¬¡æ•°: {len(train_loader)}")
    
    # æµ‹è¯•å•ä¸ªbatchçš„å¤„ç†æ—¶é—´
    print("ğŸ”¥ æµ‹è¯•å•ä¸ªbatchå¤„ç†æ—¶é—´...")
    
    # åˆ›å»ºæ¨¡å‹
    from models.qwen2_5_vl_classify import Qwen25VLClassify
    model = Qwen25VLClassify(config['model'])
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = model.to(device)
    
    # æµ‹è¯•å‰å‘ä¼ æ’­æ—¶é—´
    model.train()
    batch_times = []
    
    for i, batch in enumerate(train_loader):
        if i >= 5:  # åªæµ‹è¯•å‰5ä¸ªbatch
            break
        
        batch_start = time.time()
        
        # æ¨¡æ‹Ÿtrainerçš„æ•°æ®å‡†å¤‡
        inputs = batch["input_ids"].to(device, non_blocking=True)
        attention_mask = batch["attention_mask"].to(device, non_blocking=True)
        pixel_values = batch["pixel_values"].to(device, non_blocking=True)
        labels = batch["labels"].to(device, non_blocking=True)
        
        forward_kwargs = {
            "input_ids": inputs,
            "attention_mask": attention_mask,
            "pixel_values": pixel_values,
            "labels": labels
        }
        
        if "image_grid_thw" in batch:
            forward_kwargs["image_grid_thw"] = batch["image_grid_thw"].to(device, non_blocking=True)
        
        # å‰å‘ä¼ æ’­
        with torch.no_grad():  # åªæµ‹è¯•å‰å‘ä¼ æ’­æ—¶é—´
            outputs = model(**forward_kwargs)
            loss = outputs.loss
        
        batch_time = time.time() - batch_start
        batch_times.append(batch_time)
        
        print(f"  Batch {i+1}: {batch_time:.3f}s (loss: {loss.item():.4f})")
    
    avg_batch_time = sum(batch_times) / len(batch_times)
    print(f"ğŸ“Š å¹³å‡batchå‰å‘ä¼ æ’­æ—¶é—´: {avg_batch_time:.3f}s")
    
    # é¢„ä¼°è®­ç»ƒæ—¶é—´
    estimated_step_time = avg_batch_time * 1.5  # è€ƒè™‘åå‘ä¼ æ’­ç­‰é¢å¤–å¼€é”€
    print(f"ğŸ“Š é¢„ä¼°å®Œæ•´è®­ç»ƒæ­¥éª¤æ—¶é—´: {estimated_step_time:.1f}s")
    
    if estimated_step_time > 20:
        print("âŒ è®­ç»ƒé€Ÿåº¦ä»ç„¶å¾ˆæ…¢ï¼Œéœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")
        return False
    elif estimated_step_time > 10:
        print("âš ï¸ è®­ç»ƒé€Ÿåº¦ä¸€èˆ¬ï¼Œå»ºè®®ç»§ç»­ä¼˜åŒ–")
        return True
    else:
        print("âœ… è®­ç»ƒé€Ÿåº¦è‰¯å¥½")
        return True

def test_data_loading_speed():
    """æµ‹è¯•æ•°æ®åŠ è½½é€Ÿåº¦"""
    print("\nğŸ”¥ æµ‹è¯•æ•°æ®åŠ è½½é€Ÿåº¦...")
    
    # åŠ è½½é…ç½®
    config_file = "configs/fast_eval_config.yaml"
    with open(config_file, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    # å‡†å¤‡é…ç½®
    from training.utils.config_utils import prepare_config
    config = prepare_config(config)
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    from data.dataloader import create_dataloaders
    train_loader, val_loader = create_dataloaders(config)
    
    # æµ‹è¯•æ•°æ®åŠ è½½é€Ÿåº¦
    print("æµ‹è¯•æ•°æ®è¿­ä»£é€Ÿåº¦...")
    
    data_times = []
    total_start = time.time()
    
    for i, batch in enumerate(train_loader):
        if i >= 10:  # åªæµ‹è¯•å‰10ä¸ªbatch
            break
        
        data_start = time.time()
        # ç®€å•è®¿é—®æ•°æ®
        _ = batch["input_ids"].shape
        _ = batch["pixel_values"].shape
        _ = batch["labels"].shape
        data_time = time.time() - data_start
        data_times.append(data_time)
        
        if i < 5:
            print(f"  Data batch {i+1}: {data_time:.3f}s")
    
    total_time = time.time() - total_start
    avg_data_time = sum(data_times) / len(data_times)
    
    print(f"ğŸ“Š å¹³å‡æ•°æ®åŠ è½½æ—¶é—´: {avg_data_time:.3f}s")
    print(f"ğŸ“Š æ€»æ—¶é—´ (10 batch): {total_time:.1f}s")
    
    if avg_data_time > 1.0:
        print("âš ï¸ æ•°æ®åŠ è½½å¯èƒ½å­˜åœ¨ç“¶é¢ˆ")
        return False
    else:
        print("âœ… æ•°æ®åŠ è½½é€Ÿåº¦æ­£å¸¸")
        return True

if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹è®­ç»ƒé€Ÿåº¦æµ‹è¯•")
    print("=" * 50)
    
    # æµ‹è¯•1: æ•°æ®åŠ è½½é€Ÿåº¦
    data_ok = test_data_loading_speed()
    
    # æµ‹è¯•2: è®­ç»ƒé€Ÿåº¦
    training_ok = test_training_speed()
    
    print("\n" + "=" * 50)
    print("ğŸ“Š é€Ÿåº¦æµ‹è¯•ç»“æœæ€»ç»“:")
    print(f"  â€¢ æ•°æ®åŠ è½½é€Ÿåº¦: {'âœ… æ­£å¸¸' if data_ok else 'âš ï¸ éœ€è¦ä¼˜åŒ–'}")
    print(f"  â€¢ è®­ç»ƒé€Ÿåº¦: {'âœ… è‰¯å¥½' if training_ok else 'âŒ éœ€è¦ä¼˜åŒ–'}")
    
    if training_ok and data_ok:
        print("ğŸ‰ è®­ç»ƒé€Ÿåº¦æµ‹è¯•é€šè¿‡ï¼")
    else:
        print("âŒ è®­ç»ƒé€Ÿåº¦éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–") 